<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>泮</title>
 <link href="/atom.xml" rel="self"/>
 <link href=""/>
 <updated>2017-11-23T21:01:31+08:00</updated>
 <id>/</id>
 <author>
   <name></name>
 </author>

 
 <entry>
   <title>MySQL网络协议分析</title>
   <link href="/2017/11/10/mysql-protocol.html"/>
   <updated>2017-11-10T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbgbds2a4fge</id>
   <content type="html">&lt;p&gt;MySQL对大家来说，都应该很熟悉了，从大学里的课程到实际工作中数据的存储查询，很多时候都需要用到数据库，很多人也写过与数据库交互的程序，在Java中你可能一开始会使用原生mysql-connector-java来进行操作，后来你会接触到Hibernate，Mybatis等ORM框架，其实它们底层也是基于mysql-connector-java，但很多时候我们并不清楚程序是怎么跟数据库具体交互的，比如执行一个SQL查询，程序是如何从MySQL中获取数据的呢？今天就让我们来看看最基础的MySQL网络协议分析。&lt;/p&gt;

&lt;h1&gt;引言&lt;/h1&gt;

&lt;p&gt;阅读本文之前你需要对网络协议需要有基本的了解，比如两台机子之间的数据是如何通信的，硬件层可以暂时不需了解，但网络层和传输层的协议要有一定的理解，比如IP数据包，TCP/IP协议，UDP协议等相关概念，有了这些基础，有利于你阅读本文。&lt;/p&gt;

&lt;h1&gt;背景&lt;/h1&gt;

&lt;p&gt;在历史悠久的时代，数据库只作为单机存储，也不怎么需要与程序进行交互的时候的首，它的网络通信并不是那么重要，但随着时代的发展，数据库不再只是单纯的作为一个数据的仓库了，它需要提供与外界的交互，比如远程连接，程序操作数据库等，这时候一份规范的网络通信的协议就非常重要了，比如它是如何校验权限，如何解析SQL语句，如何返回执行结果都需要用到相应的协议，很多时候我们并不需要接触这些内容，因为它太底层了，我们直接使用把它们封装好的第三方包就可以了，为什么还要去学习它的网络协议呢？确实对于一开始学习编程的人来说，这有点操之过急，反而有时候会适得其反，但当你对这一方面有了一定的了解之后，你便会迫不及待得想去探索更深层的奥秘，去了解并学习我们平常用的第三方类库是怎么去实现，明白它的底层原理，甚至对一些莫名其妙的bug也不会再害怕。&lt;/p&gt;

&lt;h1&gt;MySQL连接方式&lt;/h1&gt;

&lt;p&gt;分析协议，我们首先要了解如何与数据库连接，说到MySQL连接方式，大家突然可能有点懵，其实它一直伴随着我们，比如我们第一次装数据库完成后执行的第一次登录，比如你没有设置密码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql -uroot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是最基本的一种数据库连接方式，那么MySQL连接方式到底有几种呢？到MySQL5.7为止，总共有五种，分别是TCP/IP，TLS/SSL，Unix Sockets，Shared Memory，Named pipes，下面我们就来看看这五种的区别：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方式&lt;/th&gt;
&lt;th&gt;默认开启&lt;/th&gt;
&lt;th&gt;支持系统&lt;/th&gt;
&lt;th&gt;只支持本机&lt;/th&gt;
&lt;th&gt;如何开启&lt;/th&gt;
&lt;th&gt;参数配置&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TCP/IP &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 所有系统 &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt;--skip-networking=yes/no. &lt;/td&gt;
&lt;td&gt; --port&lt;br&gt;--bind-address&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TLS/SSL &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 所有系统（基于TCP/IP)之上 &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt;--ssl=yes/no. &lt;/td&gt;
&lt;td&gt; --ssl-* options&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Unix Sockets &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 类Unix系统 &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 设置--socket=&amp;lt;empty&gt; 来关闭. &lt;/td&gt;
&lt;td&gt; --socket=socket path&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Shared Memory &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt; Windows系统 &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt;--shared-memory=on/off. &lt;/td&gt;
&lt;td&gt; --shared-memory-base-name=&amp;lt;name&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Named pipes &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt; Windows系统 &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt;--enable-named-pipe=on/off. &lt;/td&gt;
&lt;td&gt;  --socket=&amp;lt;name&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;从上表中我们可以清晰看出每种连接方式的区别，接下里我会具体说明几种连接是怎么操作的，由于我的机子是Mac OS系统，这里只模拟非Windows系统下的三种方式,因为这三种方式都是默认开启的，我们不需要进行任何配置：&lt;/p&gt;

&lt;h2&gt;1.Unix Sockets：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql -uroot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;若你在本机使用这种方式连接MySQL数据库的话，它默认会使用Unix Sockets。&lt;/p&gt;

&lt;h2&gt;2.TCP/IP：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql --protocol=tcp -uroot
mysql -P3306 -h127.0.0.1 -uroot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;连接的时候我们指定连接协议，或者指定相应的IP及端口，我们的连接方式就变成了TCP/IP方式。&lt;/p&gt;

&lt;h2&gt;3.TLS/SSL：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql --protocol=tcp -uroot --ssl=on
mysql -P3306 -h127.0.0.1 -uroot --ssl=on
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上表说过，TLS/SSL是基于TCP/IP的，所以我们只需再指定打开ssl配置即可。&lt;/p&gt;

&lt;p&gt;然后我们可以通过以下语句来查询目前数据库的连接情况：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT DISTINCT connection_type from performance_schema.threads where connection_type is not null
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么我们如何选择连接方式呢？个人总结了以下几个原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;若是你能确定程序和数据库在同一台机子(类Unix系统)上，推荐使用Unix Sockets，因为它效率更高；&lt;/li&gt;
&lt;li&gt;若数据库分布在不同的机子上，且能确保连接安全或者安全性要求不是那么高，推荐使用TCP/IP，反之使用TLS/SSL；&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;MySQL数据包&lt;/h1&gt;

&lt;p&gt;通信中最重要的就是数据，那么程序是如何和MySQL Server进行通信，并交互数据的呢？比如如何验证账户，发送查询语句，返回执行结果等，我先画一个流程图来模拟一下整个过程，帮助大家理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/mysql-process.png&quot; alt=&quot;mysql-process&quot; /&gt;&lt;/p&gt;

&lt;p&gt;整个过程相对来说还是比较清晰的，我们对连接请求和断开请求不需要过分关心，只需要了解这一点就可以了，重要的是其他几点，那么在这几步中，数据是怎么进行交互的呢？&lt;/p&gt;

&lt;p&gt;其实主要就是两步，&lt;strong&gt;Client将执行命令编码成Server要求的格式传输给Server端执行，Server端将执行结果传输给Client端，Client端再根据相应的数据包格式解析获得所需的数据&lt;/strong&gt;。&lt;/p&gt;

&lt;h2&gt;1.基本数据类型&lt;/h2&gt;

&lt;p&gt;虽然网络中的数据是用字节传输的，但它背后的数据源都是有类型的数据，MySQL协议也有基本的数据类型，好比Java中的8种基本数据类型，但MySQL协议中简单的多，它只有两种基本数据类型，分别为Integer(整型)，String(字符串)，下面我们就来看看这两种类型。&lt;/p&gt;

&lt;h3&gt;Integer(整型)&lt;/h3&gt;

&lt;p&gt;首先Integer在MySQL协议中有两种编码方式，分别为FixedLengthInteger和LengthEncodedInteger
,其中前者用于存储无符号定长整数，实际中使用的不多，这里着重讲一下后者。&lt;/p&gt;

&lt;p&gt;使用LengthEncodedInteger编码的整数可能会使用1, 3, 4, 或者9 个字节，具体使用字节取决于数值的大小，下表是不同的数据长度的整数所使用的字节数：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;最小值（包含）&lt;/th&gt;
&lt;th&gt;最大值（不包含）&lt;/th&gt;
&lt;th&gt;存储方式&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt;251&lt;/td&gt;
&lt;td&gt; 1个字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;251 &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 3个字节(0xFC + 2个字节具体数据)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 4个字节(0xFD + 3个字节具体数据)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;64&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 9个字节(0xFE + 8个字节具体数据)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;举个简单的例子，比如1024的编码为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0xFC 0x00 0x04
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中0x代表16进制，实际数据传输中并没有该标识，第一位代表这是一个251~2&lt;sup&gt;16&lt;/sup&gt;之间的数值，所以后面两位为数值具体的值，这里使用的是小端字节序，MySQL默认使用的也是这种编码次序，所以这里1024是0x00 0x04，字节序相关知识可以参考：&lt;a href=&quot;http://www.ruanyifeng.com/blog/2016/11/byte-order.html&quot;&gt;理解字节序&lt;/a&gt;，到这里大家应该对这种编码格式有了一定的了解了，下面我们就来看看String。&lt;/p&gt;

&lt;h3&gt;String(字符串)&lt;/h3&gt;

&lt;p&gt;String的编码格式相对Integer来说会复杂一点，主要有以下几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;FixedLengthString（定长方式）：需先知道String的长度，MySQL中的一个例子就是ERR_Packet包（后续会讲到）就使用了这种编码方式，因为它的长度固定，用5个字节存储所有数据。&lt;/li&gt;
&lt;li&gt;NullTerminatedString（Null结尾方式）: 字符串以遇到Null作为结束标志，相应的字节为00。&lt;/li&gt;
&lt;li&gt;VariableLengthString（动态计算字符串长度方式）: 字符串的长度取决于其他变量计算而定，比如一个字符串由Integer + Value组成，我们通过计算Integer的值来获取Value的具体的长度。&lt;/li&gt;
&lt;li&gt;LengthEncodedString（指定字符串长度方式）： 与VariableLengthString原理相似，是它的一种特殊情况，具体例子就是我上条举的这个例子。&lt;/li&gt;
&lt;li&gt;RestOfPacketString（包末端字符串方式）：一个包末端的字符串，可根据包的总长度金和当前位置得到字符串的长度，实际中并不常用。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说String的编码格式种类相对比较多，不同方式之间的区别也比较大，若要深刻理解还需从实际的例子里去学习，后续文章中我会写几个demo带大家一起去探索。&lt;/p&gt;

&lt;h2&gt;2.基本数据包格式&lt;/h2&gt;

&lt;p&gt;数据包格式也主要分为两种，一种是Server端向Client端发送的数据包格式，另一种则是Client向Server端发送的数据包。&lt;/p&gt;

&lt;h3&gt;Server to Client&lt;/h3&gt;

&lt;p&gt;Server向Client发送的数据包有两个原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个数据包大小不能超过2&lt;sup&gt;24&lt;/sup&gt;字节(16MB);&lt;/li&gt;
&lt;li&gt;每个数据包前都需要加上数据包信息；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;每个包的基本格式：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type &lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;int&lt;3&gt; &lt;/td&gt;
&lt;td&gt;payload_length(包数据长度)&lt;/td&gt;
&lt;td&gt; 具体数据包的内容长度，从出去头部四个字节后开始的内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;int&lt;1&gt; &lt;/td&gt;
&lt;td&gt;sequence_id(包序列id)&lt;/td&gt;
&lt;td&gt; 每个包的序列id，总数据内容大于16MB时需要用，从0开始，依次增加，新的命令执行会重载为0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;string &lt;/td&gt;
&lt;td&gt;payload(具体数据)&lt;/td&gt;
&lt;td&gt; 包中除去头部后的具体数据内容&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;举个列子：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;例子 &lt;/th&gt;
&lt;th&gt;解释&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;01 00 00 00 01&lt;/td&gt;
&lt;td&gt; &lt;li&gt;payload_length: 1&lt;/li&gt; &lt;li&gt;sequence_id: 0x00&lt;/li&gt;&lt;li&gt;payload: 0x01&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;若是数据内容大于或者等于2&lt;sup&gt;24&lt;/sup&gt;-1个字节，将会拆分发送，举个例子，比如发送16 777 215 (2&lt;sup&gt;24&lt;/sup&gt;-1) 字节的内容，则会按一下这种方式发送&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ff ff ff 00 ...
00 00 00 01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个数据包满载，第二个数据包是一个空数据包（一种临界情况）。&lt;/p&gt;

&lt;h3&gt;Client to Server&lt;/h3&gt;

&lt;p&gt;Client向Server端发送的格式相对来说就简单一点了&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type &lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;int&lt;1&gt; &lt;/td&gt;
&lt;td&gt;执行命令&lt;/td&gt;
&lt;td&gt; 执行的操作，比如切换数据库，查询表等操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;string &lt;/td&gt;
&lt;td&gt;参数&lt;/td&gt;
&lt;td&gt; 命令相应的参数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;命令列表（摘抄自胡桃夹子的博客）：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类型值 &lt;/th&gt;
&lt;th&gt;命令&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0x00&lt;/td&gt;
&lt;td&gt;    COM_SLEEP&lt;/td&gt;
&lt;td&gt;   （内部线程状态)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x01&lt;/td&gt;
&lt;td&gt;    COM_QUIT &lt;/td&gt;
&lt;td&gt;   关闭连接&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x02&lt;/td&gt;
&lt;td&gt;    COM_INIT_DB &lt;/td&gt;
&lt;td&gt; 切换数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x03&lt;/td&gt;
&lt;td&gt;    COM_QUERY   &lt;/td&gt;
&lt;td&gt;SQL查询请求&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x04&lt;/td&gt;
&lt;td&gt;   COM_FIELD_LIST&lt;/td&gt;
&lt;td&gt;  获取数据表字段信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x05&lt;/td&gt;
&lt;td&gt;    COM_CREATE_DB &lt;/td&gt;
&lt;td&gt;  创建数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x06&lt;/td&gt;
&lt;td&gt;    COM_DROP_DB&lt;/td&gt;
&lt;td&gt; 删除数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x07&lt;/td&gt;
&lt;td&gt;    COM_REFRESH&lt;/td&gt;
&lt;td&gt; 清除缓存&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x08&lt;/td&gt;
&lt;td&gt;   COM_SHUTDOWN &lt;/td&gt;
&lt;td&gt;   停止服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x09&lt;/td&gt;
&lt;td&gt;    COM_STATISTICS&lt;/td&gt;
&lt;td&gt;  获取服务器统计信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0A&lt;/td&gt;
&lt;td&gt;    COM_PROCESS_INFO&lt;/td&gt;
&lt;td&gt;    获取当前连接的列表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0B&lt;/td&gt;
&lt;td&gt;    COM_CONNECT&lt;/td&gt;
&lt;td&gt; （内部线程状态)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0C&lt;/td&gt;
&lt;td&gt;    COM_PROCESS_KILL&lt;/td&gt;
&lt;td&gt;    中断某个连接&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0D&lt;/td&gt;
&lt;td&gt;    COM_DEBUG&lt;/td&gt;
&lt;td&gt;   保存服务器调试信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0E&lt;/td&gt;
&lt;td&gt;    COM_PING&lt;/td&gt;
&lt;td&gt;    测试连通性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0F&lt;/td&gt;
&lt;td&gt;    COM_TIME&lt;/td&gt;
&lt;td&gt;    （内部线程状态）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x10&lt;/td&gt;
&lt;td&gt;    COM_DELAYED_INSERT&lt;/td&gt;
&lt;td&gt;  （内部线程状态）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x11&lt;/td&gt;
&lt;td&gt;    COM_CHANGE_USER&lt;/td&gt;
&lt;td&gt; 重新登陆（不断连接）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x12&lt;/td&gt;
&lt;td&gt;    COM_BINLOG_DUMP&lt;/td&gt;
&lt;td&gt; 获取二进制日志信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x13&lt;/td&gt;
&lt;td&gt;    COM_TABLE_DUMP&lt;/td&gt;
&lt;td&gt;  获取数据表结构信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x14&lt;/td&gt;
&lt;td&gt;    COM_CONNECT_OUT&lt;/td&gt;
&lt;td&gt; （内部线程状态)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x15&lt;/td&gt;
&lt;td&gt;    COM_REGISTER_SLAVE&lt;/td&gt;
&lt;td&gt;  从服务器向主服务器进行注册&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x16&lt;/td&gt;
&lt;td&gt;    COM_STMT_PREPARE&lt;/td&gt;
&lt;td&gt;    预处理SQL语句&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x17&lt;/td&gt;
&lt;td&gt;    COM_STMT_EXECUTE&lt;/td&gt;
&lt;td&gt;    执行预处理语句&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x18&lt;/td&gt;
&lt;td&gt;    COM_STMT_SEND_LONG_DATA&lt;/td&gt;
&lt;td&gt; 发送BLOB类型的数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x19&lt;/td&gt;
&lt;td&gt;    COM_STMT_CLOSE&lt;/td&gt;
&lt;td&gt;  销毁预处理语句&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1A&lt;/td&gt;
&lt;td&gt;    COM_STMT_RESET&lt;/td&gt;
&lt;td&gt;  清除预处理语句参数缓存&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1B&lt;/td&gt;
&lt;td&gt;    COM_SET_OPTION&lt;/td&gt;
&lt;td&gt;  设置语句选项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1C&lt;/td&gt;
&lt;td&gt;    COM_STMT_FETCH&lt;/td&gt;
&lt;td&gt;  获取预处理语句的执行结果&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这里距一个常见的的例子，比如切换数据库：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;mysql&quot;&gt;use godpan
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相应的报文格式则为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0x02 0x67 0x6f 0x64 0x70 0x61 0x6e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中0x02代表切换数据库命令，后面的字节则为godpan的16进制表达。&lt;/p&gt;

&lt;h2&gt;数据包类型&lt;/h2&gt;

&lt;p&gt;有了以上的基础，我们基本知道的与MySQL通信之间的方式以及数据格式，那么与其通信间到底有哪几种数据包呢？接下去的内容是建立在MySQL4.1版本以后，之前版本的数据包类型这里不再论述。&lt;/p&gt;

&lt;p&gt;这里主要分为两个阶段，第一个阶段是数据库账户认证阶段，第二个阶段则是执行具体命令阶段，我们先来看看前者。&lt;/p&gt;

&lt;h3&gt;数据库账户认证阶段&lt;/h3&gt;

&lt;p&gt;这个阶段就是我们平常所说的登录，主要步骤如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.Client与Server进行连接&lt;/li&gt;
&lt;li&gt;2.Server向Client发送Handshake packet&lt;/li&gt;
&lt;li&gt;3.Client与Server发送Auth packet&lt;/li&gt;
&lt;li&gt;4.Server向Client发送OK packet或者ERR packet&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这里我们来看一看上面的Handshake packet和Auth packet，OK packet和ERR packet放在另一个阶段写。&lt;/p&gt;

&lt;h4&gt;Handshake packet&lt;/h4&gt;

&lt;p&gt;Handshake packet是由Server向Client发送的初始化包，因为所有从Server向Client端发送的包都是一样的格式，所以前面的四个字节是包头，前三位代表Handshake packet具体内容的数据，另外包序列号为0，很显然这个包内容小于16MB，下面是Handshake packet具体内容的格式：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 协议版本 &lt;/td&gt;
&lt;td&gt;协议版本的版本号，通常为10（0x0A）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; len = strlen (server_version) + 1 &lt;/td&gt;
&lt;td&gt; 数据库版本 &lt;/td&gt;
&lt;td&gt; 使用前面的NullTerminatedString格式编码，长度为数据库版本字符串的长度加上标示结束的的一个字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 1 &lt;/td&gt;
&lt;td&gt; 4 &lt;/td&gt;
&lt;td&gt; 线程ID &lt;/td&gt;
&lt;td&gt;此次连接MySQL Server启动的线程ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 5 &lt;/td&gt;
&lt;td&gt; 8 + 1（0x00表示结束) &lt;/td&gt;
&lt;td&gt; 挑战随机数（第一部分） &lt;/td&gt;
&lt;td&gt;用于后续账户密码验证&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 14 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 协议协商 &lt;/td&gt;
&lt;td&gt; 用于与客户端协商通讯方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 16 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 编码格式 &lt;/td&gt;
&lt;td&gt;标识数据库目前的编码方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 17 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 服务器状态 &lt;/td&gt;
&lt;td&gt;用于表示服务器状态，比如是否是事务模式或者自动提交模式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 19 &lt;/td&gt;
&lt;td&gt; 13 &lt;/td&gt;
&lt;td&gt; 保留字节 &lt;/td&gt;
&lt;td&gt;未来可能会用到，预留字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 32 &lt;/td&gt;
&lt;td&gt; 12 + 1（0x00表示结束) &lt;/td&gt;
&lt;td&gt; 挑战随机数（第二部分） &lt;/td&gt;
&lt;td&gt;用于后续账户密码验证&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;上表就是整个Handshake packet的这个包结构，属性的含义以及规范都有相应的说明，下面是我本机解析的某次连接数据库的Handshake packet包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{protocolVersion=10, serverVersion='5.7.13', threadId=4055, scramble=[49, 97, 80, 3, 35, 118, 45, 15, 5, 118, 9, 11, 124, 93, 93, 5, 31, 47, 111, 109, 0, 0, 0, 0, 0], serverCapabilities=65535, serverLanguage=33, serverStatus=2}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Auth packet&lt;/h4&gt;

&lt;p&gt;Auth packet是由Client向Server发送的认证包，用于验证数据库账户登录，相应内容的格式：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 4 &lt;/td&gt;
&lt;td&gt; 协议协商 &lt;/td&gt;
&lt;td&gt; 用于与服务端协商通讯方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 4 &lt;/td&gt;
&lt;td&gt; 消息最长长度 &lt;/td&gt;
&lt;td&gt; 客户端可以发送或接收的最长长度，0表示不做任何限制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 字符编码 &lt;/td&gt;
&lt;td&gt; 客服端字符编码方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9 &lt;/td&gt;
&lt;td&gt; 23 &lt;/td&gt;
&lt;td&gt; 保留字节 &lt;/td&gt;
&lt;td&gt; 未来可能会用到，预留字节，用0代替&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32 &lt;/td&gt;
&lt;td&gt;不定&lt;/td&gt;
&lt;td&gt; 认证字符串 &lt;/td&gt;
&lt;td&gt; 主要有三部分内容&lt;br&gt; &lt;li&gt;用户名：NullTerminatedString格式编码&lt;/li&gt;&lt;li&gt;加密后的密码：LengthEncodedString格式编码&lt;/li&gt;&lt;li&gt;数据库名称（可选）：NullTerminatedString格式编码&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这部分内容是由客户端自己生成，所以说如果我们如果要写一个程序连接数据库，那么这个包就得按照这个格式，不然服务端将会无法识别。&lt;/p&gt;

&lt;h3&gt;命令执行阶段&lt;/h3&gt;

&lt;p&gt;在我们正确连接数据库后，我们就要执行相应的命令了，比如切换数据库，执行CRUD操作等，这个阶段主要分为两步，Client发送命令（上文已经给出，下面不再讨论），Server端接收命令执行相应的操作，我们主要关心Server端向我们发送数据包，可分为4类和一个最基础的报文结构Data Field：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data Field：包数据的一个基础结构；&lt;/li&gt;
&lt;li&gt;OK包(包括PREPARE_OK)：Server端发送正确处理信息的包，包头标识为0x00；&lt;/li&gt;
&lt;li&gt;Error包： Server端发送错误信息的包，包头标识为0xFF；&lt;/li&gt;
&lt;li&gt;EOF包：用于Server向Client发送结束包，包头标识为0xFE；&lt;/li&gt;
&lt;li&gt;Result Set包：用于Server向Client发送的查询结果包；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Data Field&lt;/h4&gt;

&lt;p&gt;Data Field是Server回应包里的一个核心，主要是数据的一种编码结构，跟我之前讲的LengthEncodedInteger和LengthEncodedString很类似，也主要分为三个部分&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;最小数据长度（包含）&lt;/th&gt;
&lt;th&gt;最大数据长度（不包含）&lt;/th&gt;
&lt;th&gt;数据长度&lt;/th&gt;
&lt;th&gt;格式&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt;251&lt;/td&gt;
&lt;td&gt; 1个字节&lt;/td&gt;
&lt;td&gt;1字节 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;251 &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 2个字节 &lt;/td&gt;
&lt;td&gt; 0xFC + 2个字节数据长度 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 4个字节 &lt;/td&gt;
&lt;td&gt; 0xFD + 4个字节数据长度 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;64&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 8个字节 &lt;/td&gt;
&lt;td&gt; 0xFE + 8个字节数据长度 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NULL &lt;/td&gt;
&lt;td&gt; NULL &lt;/td&gt;
&lt;td&gt; 0个字节 &lt;/td&gt;
&lt;td&gt; 0xFB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;要注意的一点是如果出现0xFB（251）开头说明这个数据对应的是MySQL中的NULL。&lt;/p&gt;

&lt;h4&gt;OK 包&lt;/h4&gt;

&lt;p&gt;普通的OK包（PREPARE_OK包后面会讲到）会在以下几种情况下产生，由Server发送给相应的接收方：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;COM_PING: 连接或者测试数据库&lt;/li&gt;
&lt;li&gt;COM_QUERY： 不需要查询结果集的操作，比如INSERT, UPDATE, or ALTER TABLE&lt;/li&gt;
&lt;li&gt;COM_REFRESH： 数据刷新&lt;/li&gt;
&lt;li&gt;COM_REGISTER_SLAVE： 注册从服务器&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;OK 包的主要结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0x00 代表这是一个OK 包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; rows_len &lt;/td&gt;
&lt;td&gt; 影响行数 &lt;/td&gt;
&lt;td&gt; 相应操作影响的行数，比如一个Update操作的记录是5条，那么这个值就为5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 + rows_len &lt;/td&gt;
&lt;td&gt; id_len &lt;/td&gt;
&lt;td&gt; 自增id &lt;/td&gt;
&lt;td&gt;插入一条记录时，如果是自增id的话，返回的id值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 + rows_len + id_len &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 服务器状态 &lt;/td&gt;
&lt;td&gt;用于表示服务器状态，比如是否是事务模式或者自动提交模式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 + rows_len + id_len &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 警告数 &lt;/td&gt;
&lt;td&gt;上次命令引起的警告数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5 + rows_len + id_len &lt;/td&gt;
&lt;td&gt; msg_len &lt;/td&gt;
&lt;td&gt; 额外信息 &lt;/td&gt;
&lt;td&gt;此次操作的一些额外信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;下面是我本机解析的某次正确连接数据库后的OK packet包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OK{affectedRows=0, insertId=0, serverStatus=2, message='....'}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Error 包&lt;/h4&gt;

&lt;p&gt;顾名思义Error 包就是当出现错误的时候返回的信息，比如账户验证不通过，查询命令不合法，非空字段未指定值等相关操作，Server端都会向Client端发送Error 包。&lt;/p&gt;

&lt;p&gt;Error 包的主要结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0xFF 代表这是一个Error 包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 错误代码 &lt;/td&gt;
&lt;td&gt;该错误的相应错误代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 标识位 &lt;/td&gt;
&lt;td&gt;SQL执行状态标识位，用'#'进行标识&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 5 &lt;/td&gt;
&lt;td&gt; 执行状态 &lt;/td&gt;
&lt;td&gt;SQL的具体执行状态&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9 &lt;/td&gt;
&lt;td&gt; msg_len &lt;/td&gt;
&lt;td&gt; 错误信息 &lt;/td&gt;
&lt;td&gt;具体的错误信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;比如我们现在已经连接了数据库，执行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;use test_database;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是我们数据库中并没有test_database这个数据库，我们将会得到相应的错误信息，下面是我本机解析的Error packet包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error{errno=1046, sqlState='3D000', message='No database selected'}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;EOF Packet&lt;/h4&gt;

&lt;p&gt;EOF Packet是用于标识某个阶段数据结束的标志包，会在一下几种情况中产生：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;结果集中字段信息结束的时候；&lt;/li&gt;
&lt;li&gt;结果集中列信息结束的时候；&lt;/li&gt;
&lt;li&gt;服务器确认停止服务的时候；&lt;/li&gt;
&lt;li&gt;客户端发送COM_SET_OPTION and COM_DEBUG命令后，服务器回应的时候；&lt;/li&gt;
&lt;li&gt;服务器请求使用MySQL4.1版本之前的认证方式的时候；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;EOF 包的主要结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0xFE 代表这是一个EOF 包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 警告数 &lt;/td&gt;
&lt;td&gt;上次命令引起的警告数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 服务器状态&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这里要注意的一点，我们上面分析了Data Field的结构，发现它是用0xFE作为长度需要8个字节编码值得标识头，所以我们在判断一个包是否是EOF 包的时候，需要下面两个条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;标识头（第一个字节）为0xFE；&lt;/li&gt;
&lt;li&gt;包的总长度小于9个字节；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Result Set包&lt;/h4&gt;

&lt;p&gt;Result Set包产生于我们每次数据库执行需要返回结果集的时候，Server端发送给我们的包，比如平常的SELECT,SHOW等命令，Result Set包相对比较复杂，主要包含以下五个方面：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内容 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Result Set Header &lt;/td&gt;
&lt;td&gt; 返回数据的列数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Field &lt;/td&gt;
&lt;td&gt; 返回数据的列信息（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF   &lt;/td&gt;
&lt;td&gt; 列结束&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Row Data &lt;/td&gt;
&lt;td&gt; 行数据（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF &lt;/td&gt;
&lt;td&gt; 数据结束&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;我们逐个来分析，首先我们来看Result Set Header。&lt;/p&gt;

&lt;h5&gt;Result Set Header&lt;/h5&gt;

&lt;p&gt;Result Set Header表示返回数据的列数量以及一些额外的信息，其主要结构为：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1-9字节 &lt;/td&gt;
&lt;td&gt; 数据的列数量（LengthEncodedInteger编码格式）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1-9字节 &lt;/td&gt;
&lt;td&gt; 额外信息（LengthEncodedInteger编码格式）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;h5&gt;Field&lt;/h5&gt;

&lt;p&gt;Field表示Result Set中数据列的具体信息，可出现多次，具体次数取决于Result Set Header中数据的列数量，它的主要结构为：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 通常为ASCIIz字符串def&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 数据库名称（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 假如查询指定了表别名，就是表别名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 原始的表名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 假如查询指定了列别名，就是列别名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 原始的列名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 标识位，通常为12，表示接下去的12个字节是具体的field内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; field的编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; field的长度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; field的类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; field的标识&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; field值的的小数点精度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; 预留字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 可选元素，如果存在，则表示该field的默认值&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;其中field的类型与标识具体定义和对应变量含义可参考这篇文章：&lt;a href=&quot;http://hutaow.com/blog/2013/11/06/mysql-protocol-analysis/#428-com_shutdown&quot;&gt;MySQL协议分析&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;EOF 包&lt;/h5&gt;

&lt;p&gt;这里的EOF包是标识这列信息的结束，具体结构信息参考上面的EOF包解释。&lt;/p&gt;

&lt;h5&gt;Row Data&lt;/h5&gt;

&lt;p&gt;Row Data含着的是我们需要获取的数据，一个Result Set包里面包含着多个Row Data结构(得到的数据可能多行)，每个Row Data中包含着多个字段值，它们之间没有间隔，比如我们现在查询到的数据为（id: 1, name: godpan) 那么Row Data内容为（1，godpan),这两个值是连在一起的，对应的值都用LengthEncodedString编码。&lt;/p&gt;

&lt;h5&gt;EOF 包&lt;/h5&gt;

&lt;p&gt;等待Row Data发送完之后，Server最后会向Client端发送一个EOF包，标识所有的行数据已经发送完毕。&lt;/p&gt;

&lt;h4&gt;PREPARE_OK包&lt;/h4&gt;

&lt;p&gt;PREPARE_OK包产生在Client端向Server发送预处理SQL语句，Server进行正确回应的时候，大家写写Java的时候肯定用过PreparedStatement，这里PreparedStatement的功能就是进行SQL的预处理，预处理的优点比较多，比如效率高，防SQL注入等，有兴趣的同学可以自己去学习下。下面是PREPARE_OK包的结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 0x00（标识是一个OK包）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; statement_handler_id（预处理语句id）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; number of columns in result set（结果集中列的数量）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; number of parameters in query（查询语句中参数的数量）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 0x00 (填充值)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; 警告数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;比如我现在执执行下面的语句：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;PreparedStatement ps = connection.prepareStatement(&quot;SELECT * FROM `godpan_fans` where id=?&quot;);
ps.setInteger(1, 1);
ps.executeQuery();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;得到下面的PREPARE_OK包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PSOK{statementId=1, columns=5, parameters=1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果上面的columns大于0，以及parameters大于0，则将有额外的两个包传输，分别是columns的信息以及parameters的信息，对应信息结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内容 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Field &lt;/td&gt;
&lt;td&gt; columns信息（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF   &lt;/td&gt;
&lt;td&gt; columns信息结束&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Field &lt;/td&gt;
&lt;td&gt; parameters（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF &lt;/td&gt;
&lt;td&gt; parameters结束&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;到此整个PREPARE_OK包发送完毕。&lt;/p&gt;

&lt;h4&gt;Row Data Binary&lt;/h4&gt;

&lt;p&gt;这个包跟上面提到的Row Data包有什么差别呢？主要有两点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;用不同的方式定义NULL；&lt;/li&gt;
&lt;li&gt;数据编码不再单纯的使用LengthEncodedString，而是根据数据类型的不同进行相应的编码；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;后面我会分别解释这两点，我们先来看看它的结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0x00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; (col_count+7+2)/8 &lt;/td&gt;
&lt;td&gt; Null Bit Map &lt;/td&gt;
&lt;td&gt; 前两位为预留字节，主要用于区别与其他的几种包（OK，ERROR，EOF），在MySQL 5之后这两个字节都为0X00，其中col_count为列的数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;(col_count+7+2)/8 + 1 &lt;/td&gt;
&lt;td&gt; n &lt;/td&gt;
&lt;td&gt; column values &lt;/td&gt;
&lt;td&gt; 具体的列值，重复多次，根据值类型编码&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;现在我们来看一下它的两个特点，首先我们来看它是如何来定义NULL的，首先我们看到他的结构中有一个Null Bit Map，除去两个标识位，真正用于标识数据信息的就是(col_count+7)/8位字节，这里我先给出结论，后面再给大家具体分析：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数个数 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;具体值范围&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1-8 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; -1, 2&lt;sup&gt;n&lt;/sup&gt;组合 &lt;/td&gt;
&lt;td&gt; 1 = 2&lt;sup&gt;0&lt;/sup&gt;表示第一个参数为NULL，3 = 2&lt;sup&gt;0&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt;表示第一个和第二参数为NULL...&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;上面给出了标识NULL的基本算法，原则是哪个参数（次序为n)为NULL，则Null Bit Map相应的值加上2&lt;sup&gt;n&lt;/sup&gt;,8个参数为一个周期，以此类推。&lt;/p&gt;

&lt;p&gt;接着我们来看一下第二点，是如何用具体值类型来对相应的值进行编码的，这里主要分为三类，基本数据类型，时间类型，字符串类型；&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;基本数据类型：比如TINYINT使用一个字节编码，FLOAT使用四个字节，DOUBLE使用8个字节等；&lt;/li&gt;
&lt;li&gt;时间类型：使用类似LengthEncodedString的编码方式编码，具体可参考&lt;a href=&quot;https://dev.mysql.com/doc/dev/mysql-server/latest/PAGE_PROTOCOL.html&quot;&gt;MySQL_PROTOCOL&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;字符串类：不属于上面两类的都属于字符串类型，使用普通的LengthEncodedString；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Execute包&lt;/h4&gt;

&lt;p&gt;Execute包顾名思义是一个执行包，它是由Client端发送到Server端的，但它和普通的命令又有点不同，它主要是用来执行预处理语句，并会携带相应参数，具体结构如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; COM_EXECUTE（标识是一个Execute包）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 预处理语句id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 游标类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 预留字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 接下去的内容只有在有参数的情况下&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;(param_count+7)/8 &lt;/td&gt;
&lt;td&gt; null_bit_map（描述参数中NULL的情况）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 参数绑定情况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n*2 &lt;/td&gt;
&lt;td&gt; 参数类型（依次存储）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 参数具体值（非NULL）（依次存储，使用Row Data Binary方式编码）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;Execute包从Client端发送到Server端后可能会得到以下几个结果：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OK包&lt;/li&gt;
&lt;li&gt;ERROR包&lt;/li&gt;
&lt;li&gt;Result Set包（可能多个）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;我们需要根据包的不同类型来进行不同的处理。&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;本篇文章主要讲述了MySQL的连接方式，通信过程及协议，以及传输包的基本格式和相关传输包的类型，内容相对来说，比较多也比较复杂，我也是将近三周才写完，但总体按照我自学的思路走，不会太绕，有些点可能需要细心思考下，写的有误的地方也希望大家能指正，希望对大家有所帮助，后面可能会写几个实例和大家一起学习。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Java IO之NIO</title>
   <link href="/2017/11/05/java-nio.html"/>
   <updated>2017-11-05T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;上篇说了最基础的五种IO模型，相信大家对IO相关的概念应该有了一定的了解，这篇文章主要讲讲基于多路复用IO的Java NIO。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;Java诞生至今，有好多种IO模型，从最早的Java IO到后来的Java NIO以及最新的Java AIO，每种IO模型都有它自己的特点，详情请看我的上篇文章&lt;a href=&quot;&quot;&gt;Java IO初探&lt;/a&gt;，而其中的的Java NIO应用非常广泛，尤其是在高并发领域，比如我们常见的Netty，Mina等框架，都是基于它实现的，相信大家都有所了解，下面让我们来看看Java NIO的具体架构。&lt;/p&gt;

&lt;h3&gt;Java NIO架构&lt;/h3&gt;

&lt;p&gt;其实Java NIO模型相对来说也还是比较简单的，它的核心主要有三个，分别是：Selector、Channel和Buffer,我们先来看看它们之间的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/java-nio.png&quot; alt=&quot;java-nio&quot; /&gt;&lt;/p&gt;

&lt;p&gt;它们之间的关系很清晰，一个线程对应着一个Selector，一个Selector对应着多个Channel，一个Channel对应着一个Buffer，当然这只是通常的做法，一个Channel也可以对应多个Selector，一个Channel对应着多个Buffer。&lt;/p&gt;

&lt;h4&gt;Selector&lt;/h4&gt;

&lt;p&gt;个人认为Selector是Java NIO的最大特点，之前我们说过，传统的Java IO在面对大量IO请求的时候有心无力，因为每个维护每一个IO请求都需要一个线程，这带来的问题就是，系统资源被极度消耗，吞吐量直线下降，引起系统相关问题，那么Java NIO是如何解决这个问题的呢？答案就是Selector，简单来说它对应着多路IO复用中的监管角色，它负责统一管理IO请求，监听相应的IO事件，并通知对应的线程进行处理，这种模式下就无需为每个IO请求单独分配一个线程，另外也减少线程大量阻塞，资源利用率下降的情况，所以说Selector是Java NIO的精髓，在Java中我们可以这么写：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;// 打开服务器套接字通道
ServerSocketChannel ssc = ServerSocketChannel.open();
// 服务器配置为非阻塞
ssc.configureBlocking(false);
// 进行服务的绑定
ssc.bind(new InetSocketAddress(&quot;localhost&quot;, 8001));

// 通过open()方法找到Selector
Selector selector = Selector.open();
// 注册到selector，等待连接
ssc.register(selector, SelectionKey.OP_ACCEPT);
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Channel&lt;/h4&gt;

&lt;p&gt;Channel本意是通道的意思，简单来说，它在Java NIO中表现的就是一个数据通道，但是这个通道有一个特点，那就是它是双向的，也就是说，我们可以从通道里接收数据，也可以向通道里写数据，不用像Java BIO那样，读数据和写数据需要不同的数据通道，比如最常见的Inputstream和Outputstream，但是它们都是单向的，Channel作为一种全新的设计，它帮助系统以相对小的代价来保持IO请求数据传输的处理，但是它并不真正存放数据，它总是结合着缓存区（Buffer）一起使用，另外Channel主要有以下四种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;FileChannel：读写文件时使用的通道&lt;/li&gt;
&lt;li&gt;DatagramChannel：传输UDP连接数据时的通道,与Java IO中的DatagramSocket对应&lt;/li&gt;
&lt;li&gt;SocketChannel：传输TCP连接数据时的通道，与Java IO中的Socket对应&lt;/li&gt;
&lt;li&gt;ServerSocketChannel: 监听套接词连接时的通道，与Java IO中的ServerSocket对应&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;当然其中最重要以及最常用的就是SocketChannel和ServerSocketChannel，也是Java NIO的精髓，ServerSocketChannel可以设置成非阻塞模式，然后结合Selector就可以实现多路复用IO，使用一个线程管理多个Socket连接，具体使用可以参数上面的代码。&lt;/p&gt;

&lt;h4&gt;Buffer&lt;/h4&gt;

&lt;p&gt;顾名思义，Buffer的含义是缓冲区，它在Java NIO中的主要作用就是作为数据的缓冲区域，Buffer对应着某一个Channel，从Channel中读取数据或者向Channel中写数据，Buffer与数组很类似，但是它提供了更多的特性，方便我们对Buffer中的数据进行操作，后面我也会主要分析它的三个属性capacity，position和limit，我们先来看一下Buffer分配时的类别（这里不是指Buffer的具体数据类型）即Direct Buffer和Heap Buffer，那么为什么要有这两种类别的Buffer呢？我们先来看看它们的特性：&lt;/p&gt;

&lt;p&gt;Direct Buffer：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;直接分配在系统内存中；&lt;/li&gt;
&lt;li&gt;不需要花费将数据库从内存拷贝到Java内存中的成本；&lt;/li&gt;
&lt;li&gt;虽然Direct Buffer是直接分配中系统内存中的，但当它被重复利用时，只有真正需要数据的那一页数据会被装载到真是的内存中，其它的还存在在虚拟内存中，不会造成实际内存的资源浪费；&lt;/li&gt;
&lt;li&gt;可以结合特定的机器码，一次可以有顺序的读取多字节单元；&lt;/li&gt;
&lt;li&gt;因为直接分配在系统内存中，所以它不受Java GC管理，不会自动回收；&lt;/li&gt;
&lt;li&gt;创建以及销毁的成本比较高；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Heap Buffer：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分配在Java Heap，受Java GC管理生命周期，不需要额外维护；&lt;/li&gt;
&lt;li&gt;创建成本相对较低；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;根据它们的特性，我们可以大致总结出它们的适用场景：&lt;/p&gt;

&lt;p&gt;如果这个Buffer可以重复利用，而且你也想多个字节操作，亦或者你对性能要求很高，可以选择使用Direct Buffer，但其编码相对来说会比较复杂，需要注意的点也更多，反之则用Heap Buffer，Buffer的相应创建方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;//创建Heap Buffer
ByteBuffer heapBuffer = ByteBuffer.allocate(1024);

//创建Direct Buffer
ByteBuffer directBuffer = ByteBuffer.allocateDirect(1024);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们来看看它的三个属性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Capacity：顾名思义它的含义是容量，代表着Buffer的最大容量，与数组的Size很类似，初始化不可更改，除非你改变的Buffer的结构；&lt;/li&gt;
&lt;li&gt;Limit：顾名思义它的含义是界限，代表着Buffer的目前可使用的最大限制，写模式下，一般Limit等于Capacity，读模式下需要你自己控制它的值结合position读取想要的数据；&lt;/li&gt;
&lt;li&gt;Position：顾名思义它的含义是位置，代表着Buffer目前操作的位置，通俗来说，就是你下次对Buffer进行操作的起始位置；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;接下来我会用一个图解的列子帮助大家理解,现在我们假设有一个容量为10的Buffer，我们先往里面写入一定字节的数据，然后再根据编码规则从其中读取我们需要的数据：&lt;/p&gt;

&lt;p&gt;1.初始Buffer：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;ByteBuffer buffer = ByteBuffer.allocate(10);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/init-buffer.png&quot; alt=&quot;init-buffer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.向Buffer中写入两个字节：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;buffer.put(&quot;my&quot;.getBytes());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/write-buffer-1.png&quot; alt=&quot;write-buffer-1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.再Buffer中写入四个字节：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;buffer.put(&quot;blog&quot;.getBytes());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/write-buffer-2.png&quot; alt=&quot;write-buffer-2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4.现在我们需要从Buffer中获取数据，首先我们先将写模式转换为读模式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;  buffer.flip();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看看flip()方法到底做了什么事？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public final Buffer flip() {
    limit = position;
    position = 0;
    mark = -1;
    return this;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从源码中可以看出，flip方法根据Buffer目前的相应属性来修改对应的属性，所以flip()方法之后，Buffer目前的状态：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/read-buffer.png&quot; alt=&quot;read-buffer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5.接着我们从Buffer中读取数据&lt;/p&gt;

&lt;p&gt;从Buffer中读取数据有多种方式，比如get(),get(byte [])等，相关的具体方法使用可以参考Buffer的官方API文档，这里我们用最简单的get()来获取数据:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;  byte a = buffer.get();
  byte b = buffer.get();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时Buffer的状态如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/read-buffer-2.png&quot; alt=&quot;read-buffer-2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以按照这种方式读取完我们所需数据，最终调用clear()方法将Buffer置为初始状态。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;这篇文章主要讲解了Java NIO中重要的三个组成部分，在实际使用过程也是比较重要的，掌握它们之间的关系，可以让你对Java NIO的整个架构更加熟悉，理解相对来说也会更加深刻，并分析了这种模式是如何与多路复用IO模型的映射，了解Java NIO在高并发场景下优势的原因。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Java IO初探</title>
   <link href="/2017/10/21/java-io.html"/>
   <updated>2017-10-21T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;Java IO对大多数Java程序员来说是熟悉又陌生，熟悉的是感觉到处都有它的身影，小到简单的读取文件，大到各种服务器的应用，陌生的是Java IO背后到底是一个怎样的机制，今天就让我们去了解一下这位老朋友吧。本文不讲解Java IO如何具体使用，有这方面需求的同学可以自己查下。&lt;/p&gt;

&lt;h3&gt;IO模型&lt;/h3&gt;

&lt;p&gt;要说IO，就不得不说IO模型，IO模型大家都有所了解，同步异步，阻塞非阻塞什么的，总的来说IO模型可分为以下五种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;阻塞IO&lt;/li&gt;
&lt;li&gt;非阻塞IO&lt;/li&gt;
&lt;li&gt;多路复用IO&lt;/li&gt;
&lt;li&gt;信号驱动IO&lt;/li&gt;
&lt;li&gt;异步IO&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;那么这几种IO都有什么区别呢？下面我们一一来看，每种模型我都会举一个适当的例子助于理解：&lt;/p&gt;

&lt;h4&gt;1.阻塞IO&lt;/h4&gt;

&lt;p&gt;阻塞IO相信大家都最熟悉了，线程发起一个IO请求，直到有结果返回，否则则一直阻塞等待，比如我们平常常见的阻塞数据库操作，网络IO等。&lt;/p&gt;

&lt;p&gt;小明阻塞IO吃饭：&lt;/p&gt;

&lt;p&gt;五年前一天周末，小明和朋友一起去商场的外婆家吃饭，到店后发现排队的人超多，所以他就领了一个号码，然后他和朋友就坐在旁边等候，一直等着服务员叫他们的号，也不能做其他事，过了一个多小时终于轮到他们了，然后他们进店点菜，又得等待上菜，最后他们吃饭总共花了两个小时；&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;等待座位吃饭：一直阻塞，直到有座位&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;没什么说的，反正就是一直等，反应到程序中就是一直阻塞，而一个IO请求需要一个线程，可想而知当有大量的IO请求，线程的创建和销毁，线程间的切换，线程所占用的资源等等要耗费多少时间和资源，系统的性能会有多差。&lt;/p&gt;

&lt;h4&gt;2.非阻塞IO&lt;/h4&gt;

&lt;p&gt;非阻塞IO和阻塞IO的最大区别就在于线程发起一个IO请求,不会一直堵塞直到有数据，而是不断的检查是否已有数据，若有数据则读取数据。&lt;/p&gt;

&lt;p&gt;小明非阻塞IO吃饭：&lt;/p&gt;

&lt;p&gt;有了第一次的教训，小明学乖了，他在拿到后不再傻傻的等着，而是去外婆家旁边逛了逛，每过3分钟他就会回来，然后跑到前台去询问服务员轮到他了吗？不幸的是，排队的人超多，直到过了半个多小时后才轮到他进店吃饭，期间他大概问了十几次，他们进店点菜，又得等待上菜，最后他们吃饭总共花了两个小时，基本也没做啥其他事；&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后询问是否轮到他：非阻塞，非询问期间可以做点别的事,但也不做了啥大事&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说非阻塞IO的非阻塞主要体现在不需要一直等待到有数据，当然读数据那部分操作还是阻塞的，另外这种非阻塞模式需要用户线程自己不断询问检查，其实效率也不是太高，实际编程中运用的也不多。&lt;/p&gt;

&lt;h4&gt;3.多路复用IO&lt;/h4&gt;

&lt;p&gt;既然上面我们说到非阻塞IO的缺点，那么有没有什么方式改进呢？答案是当然有，那就是多路复用IO，我理解的它的特点就是复用，首先它也是一种非阻塞IO的模型，只不过上面说到轮询的方式用了不同的方式处理了，当一个线程发起IO请求，系统会将它注册到一个单独管理IO请求的一个线程，之后该IO的相关操作的通知状态都有这个管理IO请求的线程处理，Java 1.4发布的NIO就是这种模式，我们可以大致来看一下它的流程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;// 打开服务器套接字通道
ServerSocketChannel ssc = ServerSocketChannel.open();
// 服务器配置为非阻塞
ssc.configureBlocking(false);
// 进行服务的绑定
ssc.bind(new InetSocketAddress(&quot;localhost&quot;, 8008));
// 这里的selector就相当于单独管理IO请求的线程
Selector selector = Selector.open();
// 注册到selector，等待连接
ssc.register(selector, SelectionKey.OP_ACCEPT);

while (true) {
    selector.select();  //为IO请求去轮询状态
    Set&amp;lt;SelectionKey&amp;gt; keys = selector.selectedKeys(); //多个IO请求的状态
    Iterator&amp;lt;SelectionKey&amp;gt; keyIterator = keys.iterator();
    while (keyIterator.hasNext()) { //依次处理IO请求
        SelectionKey key = keyIterator.next();
        doThing(key)
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出Java NIO的模式就是多路复用IO模型的应用。&lt;/p&gt;

&lt;p&gt;小明多路复用IO吃饭：&lt;/p&gt;

&lt;p&gt;随着生意越来越好，外婆家发现好多顾客都堵在门口等待吃饭，等待区都站不下来人了，，思来想去，外婆家准备请一个人专门来维护顾客的排队请求，这样顾客取号后，就不用堵在门口了，我们叫他小A，小明这次取号后，将自己的相关信息告诉小A，并从小A那里获得了一个GPS（用于小A能快速找到小明，假设有了GPS后，小A能秒速找到小明），然后小明就跟朋友们开心的去逛商场，看看MM，买买衣服，而小A则不断的观察店里的情况，当有空座位出现的时候，他便会按照相关信息找到具体的顾客，将其带回进行用餐，但他们进店点菜，还得等待上菜，最后他们吃饭总共花了两个小时，但是他们不再需要排队等位，而是去做一些其他的事。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后委托给小A，小A观察到有空位后带回小明：非阻塞，领号后可以安心去做自己的事，不用担心错过&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;多路复用IO可以看成普通非阻塞IO的升级版，也是目前Java编程中用到比较多的IO模型，它的优势在于可以处理大量的IO请求，用一个线程管理所有的IO请求，无需像阻塞IO和非阻塞IO一样，每个IO需要一个线程处理，提升了系统的吞吐量。&lt;/p&gt;

&lt;h4&gt;4.信号驱动IO&lt;/h4&gt;

&lt;p&gt;信号驱动IO相对于以上几种模型最大的特点就是它支持内核信号通知，线程在发起一个IO请求后，会注册一个信号函数，然后内核在确认数据可读了，便会给相应的线程发送通知，让其进行具体IO读写操作。&lt;/p&gt;

&lt;p&gt;小明信号驱动IO吃饭：&lt;/p&gt;

&lt;p&gt;又了一段时间，外婆家通过使用复用IO模式缓解了排队拥挤的情况，但是觉得还要请一个人专门维护队列，感觉不划算，那么有没有一种更好的方式呢？经过一天的苦思冥想，外婆家的经理又想出一个好办法，让每个顾客在领完号后，关注一下外婆家的公众号，然后顾客就可以去做别的事了，定时或者当排队信息发生改变时给顾客发送通知，告知他现在的排队序号或者轮到他吃饭了，顾客可以根据相应的信息做相应的行为，比如快轮到了就开始往店里走（实际程序中并不一定有这种状态，这里只是大概模拟），或者轮到自己了然后进店吃饭，他们仍然不用排队等位，而是去做一些其他的事。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后关注公众号，注册关系：非阻塞，领号后可以安心去做自己的事，不用担心错过&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;就实际来说，信号驱动IO用的并不多，因为信号驱动IO底层是使用SIGIO信号，所以它主要使用在UDP协议上，因为UDP产生SIGIO信号的时候只有两种可能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.要么数据到达&lt;/li&gt;
&lt;li&gt;2.发生错误&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;但相对TCP来说，产生SIGIO信号的地方太多了，比如请求连接，确认，断开，错误等等，所以我们很难根据SIGIO信号判断到底发生了什么。&lt;/p&gt;

&lt;h4&gt;5.异步IO&lt;/h4&gt;

&lt;p&gt;以上四种IO其实都还是同步IO，因为它们在读写数据时都是阻塞的，异步IO相较于它们最大的特点是它读写数据的时候也是非阻塞的，用户线程在发起一个IO请求的时候，除了给内核线程传递具体的IO请求外，还会给其传递数据缓冲区，回调函数通知等内容，然后用户线程就继续执行，等到内核线程发起相应通知的时候，说明数据已经准备就绪，用户线程直接使用即可，无需再阻塞从内核拷贝数据到用户线程。&lt;/p&gt;

&lt;p&gt;小明异步IO吃饭：&lt;/p&gt;

&lt;p&gt;有过了一段时间，小明又想吃外婆家了，但是这个周末他并不想出门，他突然在网上看到新闻说外婆家竟然可以叫外卖，小明高兴坏了，他马上打电话给外婆家，告诉它自己想要吃哪些菜（相当于IO请求所需要的数据），然后将自己的联系号码（相当于回调通知）和住址（相当于数据缓冲区）也告诉它，然后就挂掉电话，开心的做去打游戏了，过了半个小时后，手机响起，告知外卖已经到了，小明开门取外卖就可以直接开吃了。整个过程小明直到吃饭都没有等待阻塞。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;叫外卖并提供相应的信息：非阻塞，打完电话后做自己的事&lt;/li&gt;
&lt;li&gt;通知外卖到了：直接开门取外卖直接开吃，非阻塞&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;我们可以看出，异步IO才是真正的异步，因为它连数据拷贝这个过程都是非阻塞的，用户线程根本不用关心数据的读写等操作，只需等待内核线程通知后，直接处理数据即可，当然异步IO需要系统内核支持，比如Linux中的AIO和Windows中的IOCP，但是也可以通过多线程跟阻塞I/O模拟异步IO，比如可以在多路复用IO模型上进行相应的改变，另外也有现有的实现，比如异步I/O的库：libeio&lt;/p&gt;

&lt;p&gt;最后用一张图总体概括一下Java IO（图片来自美团技术博客）：&lt;/p&gt;

&lt;p&gt;Java IO概图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/10/java-io.jpg&quot; alt=&quot;java-io&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;多路复用IO在Linux中的实现&lt;/h3&gt;

&lt;p&gt;因为后续会讲到Java NIO，所以我们需要了解操作系统是如何支持多路复用IO的，Linux中支持支持三种多路IO复用机制，分别是select、poll和epoll，本来这里我想自己写的，但查阅了相应的一些资料后，发现自己的水平还是不够，这里我不准备班门弄斧了，因为我找到了很多写的比较好的文章，这里就给大家列一下，仅供参考：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/tennysonsky/article/details/45745887&quot;&gt;Linux系统编程——I/O多路复用select、poll、epoll的区别使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.jianshu.com/p/dfd940e7fca2&quot;&gt;聊聊IO多路复用之select、poll、epoll详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/32163005&quot;&gt;IO 多路复用是什么意思？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;这篇文章主要讲了最基础的IO模型，不过我认为最基础的往往是最重要的，只有理解了基础的原理，才能对基于它们实现的类库或者工具有更加深刻的认识，下一篇文章将会主要讲一下基于多路复用IO的Java NIO，敬请期待。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MySQL几个简单SQL的优化</title>
   <link href="/2017/10/13/mysql-sql-optimize.html"/>
   <updated>2017-10-13T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;最近在做项目的时候，遇到了一些大数据量的操作，有大批量的CRUD的操作，一开始的实现的方案经过性能测试，发现性能并不是很好，然后开始审查代码，对相关可以提升性能的操作进行了优化，这里分享给大家。&lt;/p&gt;

&lt;h3&gt;原则&lt;/h3&gt;

&lt;p&gt;首先我这里不讲索引相关的内容以及数据库相应参数的优化，这里假设你对索引已经有了相关的了解了，我总结了下我这次的优化，主要两个原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一些特定的场景，尽量用批处理处理数据，比如批量添加数据，批量修改数据；&lt;/li&gt;
&lt;li&gt;结合业务尽量减少SQL的执行次数和查询不必要的数据；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;场景实践&lt;/h3&gt;

&lt;p&gt;为模拟运行场景，我这里建了一个表，并往里面添加了300w条数据，表结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;CREATE TABLE `tb_big_data` (
 `id` int(11) NOT NULL AUTO_INCREMENT,
 `weixin_id` varchar(64) NOT NULL,
 `openid` varchar(64) NOT NULL,
 `status` int(3) NOT NULL,
 `gmt_create` datetime NOT NULL,
 `gmt_modified` datetime NOT NULL,
 PRIMARY KEY (`id`),
 KEY `weixin_id_gmt_create_openid` (`weixin_id`,`gmt_create`,`openid`)
) ENGINE=InnoDB AUTO_INCREMENT DEFAULT CHARSET=utf8
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;1.分页查询小优化&lt;/h4&gt;

&lt;p&gt;分页查询老生常谈，网上各种优化方法都很多，这里就不提及了，这里只是分享一个小技巧：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何在使用最普通的limit的时候提高性能？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;假设我们现在有一条这样的SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` where weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-10 00:00:00' order by id asc limit 800000, 100;

执行时间：100 rows in set (1.53 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假如我们现在不能进行其他优化，比如传入最小id，分表查询等策略，以及不进行SQL预热，怎么提高这条SQL的速度呢？
其实很简单我们只需要一个in操作即可：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` t1 where t1.id in ( 
    SELECT tt.id FROM ( 
        SELECT id FROM `tb_big_data` t2 where weixin_id = 'gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-10 00:00:00' order by t2.id asc limit 800100, 100
        ) as tt);

执行时间：100 rows in set (1.17 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出只需稍加修改，SQL的效率可以提高30%~40%，而且在单条数据记录越大的情况下效果越好，当然这不是最好的分页方法，这只是一个小技巧；&lt;/p&gt;

&lt;h4&gt;2.减少SQL查询&lt;/h4&gt;

&lt;p&gt;现在有一个需求我们现在有一个用户的列表（用户的唯一标识为openid）然后我们需要判断用户在当天是否有过相应的记录；&lt;/p&gt;

&lt;p&gt;这是问题其实很简单，我们首先一想到的操作就是循环这个列表一个一个判断，很简单也很好实现，但是真正测试的时候发现性能却很差，尤其在数据量大的情况下，倍数级增长，这里有有网络数据传输消耗的时间和SQL本身的执行时间；&lt;/p&gt;

&lt;p&gt;假设我们现在执行一条以下的SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid='2n6bvynihm5bzgyx';

执行时间：1 row in set (0.95 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在如果我们执行100次，不敢想象会是什么情况，庆幸自己发现了这个问题，因为在数据量少的情况下，这个问题表现的并不是那么严重，其实我们稍加改变就能以另一种高效的方式解决这个问题：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid in ('2n6bvynihm5bzgyx','1stbvdnl63de2q37','3z8552gxzfi3wy27'...);

执行时间：100 row in set (1.05 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现了没有，还是用in，而且执行时间几乎与单条查询的时间一样，可见只是单一这一部分处理就可以提升了很大的性能。&lt;/p&gt;

&lt;h4&gt;3.特定场景使用SQL的批处理&lt;/h4&gt;

&lt;p&gt;这个跟上一点有一个相似点，那就是减少SQL执行，上面只是查询而已，而当出现大批量的CUD的操作时，执行每条SQL，数据库都会进行事务处理，这将会消耗大量的时间，而且极端情况下会引起大批量SQL等待无法执行，导致业务出错，正是因为这些原因，我们在一些适当的情况下可以使用批处理来解决这个问题。&lt;/p&gt;

&lt;h5&gt;（1）批量插入&lt;/h5&gt;

&lt;p&gt;批量插入比较简单，也比较常用，这里就给一下基本语法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;INSERT INTO table_name (field1,filed2,...) values (value11,value12,...),(value21,value22,...),...
&lt;/code&gt;&lt;/pre&gt;

&lt;h5&gt;（2）批量更新&lt;/h5&gt;

&lt;p&gt;我先举个简单的例子，我们现在来根据一些条件来更新数据，具体SQL如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;update `tb_big_data` set status = 2 WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid = '2n6bvynihm5bzgyx';

Query OK, 1 row affected (2.28 sec)
Rows matched: 1  Changed: 1  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很惊讶，我们只是更新了一条记录，而且更新条件上是有复合索引的，没想到速度还那么慢，可以想象如果我们批量更新数据，那得耗时多少；&lt;/p&gt;

&lt;p&gt;但是我们看一下另一条SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;update `tb_big_data` set status = 1 WHERE id = 900098;

Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的id值为之前条件筛选出来的记录的id，是不是很惊讶，怎么这条SQL执行的时间几乎不需要什么时间，所以我们可以利用这个特点和批量查询简化批量更新，虽然这种方式不能让性能到最优，但是也能提升很大了，我进行了一个测试，根据相应条件批量更新100条数据：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方式&lt;/th&gt;
&lt;th&gt;直接批量更新&lt;/th&gt;
&lt;th&gt;先批量查主键再批量更新&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;耗时 &lt;/td&gt;
&lt;td&gt; 289.12s &lt;/td&gt;
&lt;td&gt; 1.342s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;可以看出这种方式相对对于普通方式来说，性能提升巨大，具体执行的时候我们也可以将这些SQL放在一个事务提交，减少数据库事务次数，但只这是一种在代码层面上的优化；&lt;/p&gt;

&lt;p&gt;另外我们可以利用MySQL提供的特殊语法进行批量更新，具体语法为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;#语法
INSERT INTO table_name (id,field1,field2,...) VALUES  (id1,value11,value12,...),(id1,value11,value12,...),... on duplicate key update  field = VAULES(field);

#使用例子

INSERT INTO `tb_big_data` (id,weixin_id,openid,gmt_create,status) values  (1,'gh_266a30a8a1f6','w9q8fmodytjgppsr','2017-10-13 12:00:00',3),(2,'gh_266a30a8a1f6','bu1flmch4i8eegzf','2017-10-13 12:00:00',3) on duplicate key update status = VAULES(status);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过测试这种方式在数据量小的情况下与上述方式效率差不多，但是随着数据量越来越大，性能也越来越好，缺点的话主要传输的数据量很大，不需要更新的字段也需要传输。&lt;/p&gt;

&lt;p&gt;另外也不推荐大量数据的批量更新，一次不要超过1000条为好。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;总的来说，SQL优化是一门细心的学问，需要不断去尝试，测试，找到最优方式，另外还有一点就是要结合实际情况，综合考虑选择合适的方式。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Asyncdb（一）：写一个纯函数式的Mysql异步驱动</title>
   <link href="/2017/10/04/mysql-driver-info.html"/>
   <updated>2017-10-04T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;之前的Akka系列博客接下去可能并不会经常更新了，但是后续看到一些好的点或者大家对哪些还是比较感兴趣还会继续写几篇，这里先跟大家说明一下。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;写一个纯函数式的Mysql异步驱动&lt;/strong&gt;这个构思是公司的一个大佬提的，这将会是一个开源项目，我也很有幸能够参与其中，尝试写一个自己真正意义上的开源项目，其实很多人会有疑惑，为什么我们要做一个数据库驱动，就目前JVM生态上，已经有了比较成熟的产品，我们还能做出一个怎样的数据库驱动呢？&lt;/p&gt;

&lt;p&gt;首先我们明确了一点，绝不做重复造轮子的事，做这个项目一定要有意义，即使未来可能实用性兼容性等方面不是很擅长，我们也要表达出新的设计理念，能给数据库驱动注入一股新的活力。&lt;/p&gt;

&lt;p&gt;我们在确定这个项目的时候，也对目前JVM生态中的数据库驱动进行了一定的总结，仅供参考：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;项目&lt;/th&gt;
&lt;th&gt;mysql-async&lt;/th&gt;
&lt;th&gt;HikariCP + mysql-connector/j&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;编程模型 &lt;/td&gt;
&lt;td&gt; 异步 &lt;/td&gt;
&lt;td&gt; 同步&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;网络IO &lt;/td&gt;
&lt;td&gt; NIO &lt;/td&gt;
&lt;td&gt; BIO&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;链接池 &lt;/td&gt;
&lt;td&gt; 异步实现 &lt;/td&gt;
&lt;td&gt; 同步实现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;过载防护 &lt;/td&gt;
&lt;td&gt; 通过调节队列长度实现 &lt;/td&gt;
&lt;td&gt; 需要额外实现 （例如指定线程池任务队列长度）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;可伸缩性 &lt;/td&gt;
&lt;td&gt; 只需要设置合理连接数(例如几十个) &lt;/td&gt;
&lt;td&gt; 需要测试最佳线程数和链接数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;线程数 &lt;/td&gt;
&lt;td&gt; 少 &lt;/td&gt;
&lt;td&gt; 多&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;具体相关测试及说明可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/04/mysql-async-1/&quot;&gt;MySQL 异步驱动浅析 （一）：性能分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;相信写过Java工程的同学都应该知道mysql-connector-java，但应该很多人对其的实现和相关架构设计应该不是很了解，正如我们上面对其相关功能测试，发现它的某些方面表现并不是很好，比如使用了BIO，请求时需要大量的线程等等。&lt;/p&gt;

&lt;p&gt;相信你们也注意到了mysql-async，但是应该大多数人都不是很熟悉，它也是一个基于Netty，使用Scala编写的，完全异步的数据库驱动，同时支持PostgreSQL和MySQL，其项目地址&lt;a href=&quot;https://github.com/mauricio/postgresql-async&quot;&gt;postgresql-async&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;其实我们公司项目底层用的数据库驱动也是基于mysql-async的，不过因为实际使用中遇到了一些问题，，具体相关问题分析可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/05/mysql-async-2/&quot;&gt;MySQL 异步驱动浅析 （二）：缺点分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;虽然我们使用的mysql-async内部版本对上述的许多问题都进行了修复，具体信息可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/07/mysql-async-3/&quot;&gt;MySQL 异步驱动浅析 （三）：连接池改进方案&lt;/a&gt;，但是整个项目变得混乱，架构设计也不是很完美，所以我们最终决定自己实现一个纯函数式的Mysql异步驱动，我们叫它：&lt;strong&gt;asyncdb&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;目标&lt;/h3&gt;

&lt;p&gt;那么我们到底要做一个怎样的驱动呢？我们提了以下几个主要方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.构建于cats-effect(纯函数式的关键)&lt;/li&gt;
&lt;li&gt;2.合理的数据库包解析框架&lt;/li&gt;
&lt;li&gt;3.支持简单的流处理(可选)&lt;/li&gt;
&lt;li&gt;4.基于Java NIO2，绝不阻塞&lt;/li&gt;
&lt;li&gt;5.提供对应Java8的接口&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说，除了第一点大家可能比较陌生，其他几点大家都应该能大致了解,但是第一点才是我们这个项目最重要的一点，也是用来解决我们之前遇到问题的关键，后续我会写几篇文章对于这一点进行的相关介绍，如果有兴趣的同学可以自己了解一下：&lt;a href=&quot;https://github.com/typelevel/cats-effect&quot;&gt;cats-effect&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;关注 Asyncdb&lt;/h3&gt;

&lt;p&gt;如果你对我们的项目也有兴趣，欢迎你们star我们的项目，项目地址:&lt;a href=&quot;https://github.com/asyncdb/asyncdb&quot;&gt;asyncdb&lt;/a&gt;,我们将会从头开始，你可以一步一步了解我们的架构设计和具体的实现方法，当然你有好的想法或者相关问题，也欢迎给我们提issue。&lt;/p&gt;

&lt;h3&gt;进阶学习&lt;/h3&gt;

&lt;p&gt;若是你对数据库驱动非常有兴趣，也想探究里面的奥秘，这里我提一些相应的建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.熟悉了解Java NIO，并熟练使用它&lt;/li&gt;
&lt;li&gt;2.学习MySQL数据库网络传输包协议&lt;/li&gt;
&lt;li&gt;3.掌握函数式语言中的Monad表达式，理解其的含义和使用场景&lt;/li&gt;
&lt;li&gt;4.学习Scala相关的函数库比如：&lt;a href=&quot;https://github.com/typelevel/cats&quot;&gt;cats&lt;/a&gt;,&lt;a href=&quot;https://github.com/milessabin/shapeless&quot;&gt;shapeless&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.学习IO-Monad(cats-effect)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;最后也希望大家能参与其中，帮助我们不断的完善它，共同成长！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（十）：Akka集群之Akka Cluster</title>
   <link href="/2017/09/05/learning-akka-10.html"/>
   <updated>2017-09-05T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;上一篇文章我们讲了Akka Remote，理解了Akka中的远程通信，其实Akka Cluster可以看成Akka Remote的扩展，由原来的两点变成由多点组成的通信网络，这种模式相信大家都很了解，就是集群，它的优势主要有两点：系统伸缩性高，容错性更好。&lt;/p&gt;

&lt;h3&gt;集群概念&lt;/h3&gt;

&lt;p&gt;很多人很容易把分布式和集群的概念搞错，包括我也是，我一开始也以为它们两个是一样的概念，只是叫法不同而已，但其实不然，虽然它们在实际场景中都是部署在不同的机器上，但它们所提供的功能并不是一样的。举个简单的例子来看看它们之间的不同：&lt;/p&gt;

&lt;p&gt;为了保持整个系列连续性，我又以抽奖为基础举一个例子：&lt;/p&gt;

&lt;p&gt;假定我们现在抽奖流程包括，抽奖分配奖品和用户根据链接领取指定奖品，用户先抽奖然后获取奖品链接，点击链接填写相应信息领取奖品。&lt;/p&gt;

&lt;h4&gt;1.分布式：&lt;/h4&gt;

&lt;p&gt;我们现在把抽奖分配奖品和用户根据链接领取指定奖品分别部署在两台机器上，突然有一天很不幸，抽奖活动进行到一半，抽奖分配奖品那台机子所在的区域停电了，很显然，后续的用户参与抽奖就不能进行了，因为我们只有一台抽奖分配奖品的机子，但由于我们将领取奖品的业务部署在另一台机器上，所以前面那些中奖的用户还是可以正常的领取奖品，具体相关定义可参考《分布式系统概念与设计》中对分布式系统的定义。&lt;/p&gt;

&lt;h4&gt;2.集群：&lt;/h4&gt;

&lt;p&gt;现在我们还是有两台机器，但是我们在两个机器上都部署了抽奖分配奖品和用户根据链接领取指定奖品的业务逻辑，突然有一天，有一台所在的区域停电了，但这时我们并担心，因为另一台服务器还是可以正常的运行处理用户的所有请求。&lt;/p&gt;

&lt;p&gt;它们的各自特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分布式：是指在多台不同的服务器中部署不同的服务模块，通过远程调用协同工作，对外提供服务；&lt;/li&gt;
&lt;li&gt;集群：是指在多台不同的服务器中部署相同应用或服务模块，构成一个集群，通过负载均衡设备对外提供服务；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说： 分布式是以分离任务缩短时间来提高效率，而集群是在单位时间内处理更多的任务来提高效率。&lt;/p&gt;

&lt;h3&gt;Akka Cluster&lt;/h3&gt;

&lt;p&gt;在前面的文章Akka Actor的工作方式，我们可以将一个任务分解成一个个小任务，然后分配给它的子Actor执行，其实这就可以看成一个小的分布式系统，那么在Akka中，集群又是一种怎样的概念呢？&lt;/p&gt;

&lt;p&gt;其实往简单里说，就是一些相同的ActorSystem的组合，它们具有着相同的功能，我们需要执行的任务可以随机的分配到目前可用的ActorSystem上，这点跟Nginx的负载均衡很类似，根据算法和配置将请求转发给运行正常的服务器去，Akka集群的表现形式也是这样，当然它背后的理论基础是基于gossip协议的，目前很多分布式的数据库的数据同步都采用这个协议，有兴趣的同学可以自己去研究研究，只是我也是一知半解，这里就不写了，怕误导了大家。&lt;/p&gt;

&lt;p&gt;下面我来讲讲Akka Cluster中比较重要的几个概念：&lt;/p&gt;

&lt;h4&gt;Seed Nodes&lt;/h4&gt;

&lt;p&gt;Seed Nodes可以看过是种子节点或者原始节点，它的一个主要作用用于可以自动接收新加入集群的节点的信息，并与之通信，使用方式可以用配置文件或者运行时指定，推荐使用配置文件方式，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.seed-nodes = [
  &quot;akka.tcp://ClusterSystem@host1:2552&quot;,
  &quot;akka.tcp://ClusterSystem@host2:2552&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;seed-nodes列表中的第一个节点会集群启动的时候初始化，而其他节点则是在有需要时再初始化。&lt;/p&gt;

&lt;p&gt;当然你也可以不指定seed nodes，但你可以需要手动或者在程序中写相关逻辑让相应的节点加入集群，具体使用方式可参考官方文档。&lt;/p&gt;

&lt;h4&gt;Cluster Events&lt;/h4&gt;

&lt;p&gt;Cluster Events字面意思是集群事件，那么这是什么意思呢？其实它代表着是一个节点的各种状态和操作，举个例子，假设你在打一局王者5v5的游戏，那么你可以把十个人看成一个集群，我们每个人都是一个节点，我们的任何操作和状态都能被整个系统捕获到，比如A杀了B、A超神了，A离开了游戏，A重新连接了游戏等等，这些状态和操作在Cluster Events中就相当于节点之于集群，那么它具体是怎么使用的呢？&lt;/p&gt;

&lt;p&gt;首先我们必须将节点注册到集群中，或者说节点订阅了某个集群，我们可以这么做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;cluster.subscribe(self, classOf[MemberEvent], classOf[UnreachableMember])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体代码相关的使用我会再下面写一个demo例子，来说明是如何具体使用它们的。&lt;/p&gt;

&lt;p&gt;从上面的代码我们可以看到有一个MemberEvent的概念，这个其实就是每个成员所可能拥有的events，那么一个成员在它的生命周期中有以下的events&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ClusterEvent.MemberJoined - 新的节点加入集群，此时的状态是Joining；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberUp - 新的节点加入集群，此时的状态是Up；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberExited - 节点正在离开集群，此时的状态是Exiting；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberRemoved - 节点已经离开集群，此时的状态是Removed；&lt;/li&gt;
&lt;li&gt;ClusterEvent.UnreachableMember - 节点被标记为不可触达；&lt;/li&gt;
&lt;li&gt;ClusterEvent.ReachableMember - 节点被标记为可触达；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;状态说明：
- Joining: 加入集群的瞬间状态
- Up: 正常服务状态
- Leaving / Exiting: 正常移出中状态
- Down: 被标记为停机（不再是集群决策的一部分）
- Removed: 已从集群中移除&lt;/p&gt;

&lt;h4&gt;Roles&lt;/h4&gt;

&lt;p&gt;虽然上面说到集群中的各个节点的功能是一样的，其实并不一定，比如我们将分布式和集群融合到一起，集群中的一部分节点负责接收请求，一部分用于计算，一部分用于数据存储等等，所以Akka Cluster提供了一种Roles的概念，用来表示该节点的功能特性，我们可以在配置文件中指定,比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.roles = request
akka.cluster.roles = compute
akka.cluster.roles = store
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;ClusterClient&lt;/h4&gt;

&lt;p&gt;ClusterClient是一个集群客户端，主要用于集群外部系统与集群通信，使用它非常方便，我们只需要将集群中的任意指定一个节点作为集群客户端，然后将其注册为一个该集群的接待员，最后我们就可以在外部系统直接与之通信了，使用ClusterClient需要做相应的配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.extensions = [&quot;akka.cluster.client.ClusterClientReceptionist&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假设我们现在我一个接待的Actor，叫做frontend,我们就可以这样做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sacla&quot;&gt;val frontend = system.actorOf(Props[TransformationFrontend], name = &quot;frontend&quot;)
ClusterClientReceptionist(system).registerService(frontend)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Akka Cluster例子&lt;/h3&gt;

&lt;p&gt;上面讲了集群概念和Akka Cluster中相对重要的概念，下面我们就来写一个Akka Cluster的demo，&lt;/p&gt;

&lt;p&gt;demo需求：&lt;/p&gt;

&lt;p&gt;线假设需要执行一些相同任务，频率为2s一个，现在我们需要将这些任务分配给Akka集群中的不同节点去执行，这里使用ClusterClient作为集群与外部的通信接口。&lt;/p&gt;

&lt;p&gt;首先我们先来定义一些命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
package sample.cluster.transformation

final case class TransformationJob(text: String) // 任务内容
final case class TransformationResult(text: String) // 执行任务结果
final case class JobFailed(reason: String, job: TransformationJob) //任务失败相应原因
case object BackendRegistration // 后台具体执行任务节点注册事件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们实现具体执行任务逻辑的后台节点：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationBackend extends Actor {

  val cluster = Cluster(context.system)

  override def preStart(): Unit = cluster.subscribe(self, classOf[MemberEvent])  //在启动Actor时将该节点订阅到集群中
  override def postStop(): Unit = cluster.unsubscribe(self)

  def receive = {
    case TransformationJob(text) =&amp;gt; { // 接收任务请求
      val result = text.toUpperCase // 任务执行得到结果（将字符串转换为大写）
      sender() ! TransformationResult(text.toUpperCase) // 向发送者返回结果
    }
    case state: CurrentClusterState =&amp;gt;
      state.members.filter(_.status == MemberStatus.Up) foreach register // 根据节点状态向集群客户端注册
    case MemberUp(m) =&amp;gt; register(m)  // 将刚处于Up状态的节点向集群客户端注册
  }

  def register(member: Member): Unit = {   //将节点注册到集群客户端
    context.actorSelection(RootActorPath(member.address) / &quot;user&quot; / &quot;frontend&quot;) !
      BackendRegistration
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;相应节点的配置文件信息，我这里就不贴了，请从相应的源码demo里获取。&lt;/em&gt;&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;接着我们来实现集群客户端：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationFrontend extends Actor {

  var backends = IndexedSeq.empty[ActorRef] //任务后台节点列表
  var jobCounter = 0

  def receive = {
    case job: TransformationJob if backends.isEmpty =&amp;gt;  //目前暂无执行任务节点可用
      sender() ! JobFailed(&quot;Service unavailable, try again later&quot;, job)

    case job: TransformationJob =&amp;gt; //执行相应任务
      jobCounter += 1
      implicit val timeout = Timeout(5 seconds)
      val backend = backends(jobCounter % backends.size) //根据相应算法选择执行任务的节点
      println(s&quot;the backend is ${backend} and the job is ${job}&quot;)
      val result  = (backend ? job)
        .map(x =&amp;gt; x.asInstanceOf[TransformationResult])  // 后台节点处理得到结果
      result pipeTo sender  //向外部系统发送执行结果

    case BackendRegistration if !backends.contains(sender()) =&amp;gt;  // 添加新的后台任务节点
      context watch sender() //监控相应的任务节点
      backends = backends :+ sender()

    case Terminated(a) =&amp;gt;
      backends = backends.filterNot(_ == a)  // 移除已经终止运行的节点
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt; 最后我们实现与集群客户端交互的逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class ClientJobTransformationSendingActor extends Actor {

  val initialContacts = Set(
    ActorPath.fromString(&quot;akka.tcp://ClusterSystem@127.0.0.1:2551/system/receptionist&quot;))
  val settings = ClusterClientSettings(context.system)
    .withInitialContacts(initialContacts)

  val c = context.system.actorOf(ClusterClient.props(settings), &quot;demo-client&quot;)


  def receive = {
    case TransformationResult(result) =&amp;gt; {
      println(s&quot;Client response and the result is ${result}&quot;)
    }
    case Send(counter) =&amp;gt; {
        val job = TransformationJob(&quot;hello-&quot; + counter)
        implicit val timeout = Timeout(5 seconds)
        val result = Patterns.ask(c,ClusterClient.Send(&quot;/user/frontend&quot;, job, localAffinity = true), timeout)
        result.onComplete {
          case Success(transformationResult) =&amp;gt; {
            self ! transformationResult
          }
          case Failure(t) =&amp;gt; println(&quot;An error has occured: &quot; + t.getMessage)
        }
      }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们开始运行这个domo：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object DemoClient {
  def main(args : Array[String]) {

    TransformationFrontendApp.main(Seq(&quot;2551&quot;).toArray)  //启动集群客户端
    TransformationBackendApp.main(Seq(&quot;8001&quot;).toArray)   //启动三个后台节点
    TransformationBackendApp.main(Seq(&quot;8002&quot;).toArray)
    TransformationBackendApp.main(Seq(&quot;8003&quot;).toArray)

    val system = ActorSystem(&quot;OTHERSYSTEM&quot;)
    val clientJobTransformationSendingActor =
      system.actorOf(Props[ClientJobTransformationSendingActor],
        name = &quot;clientJobTransformationSendingActor&quot;)

    val counter = new AtomicInteger
    import system.dispatcher
    system.scheduler.schedule(2.seconds, 2.seconds) {   //定时发送任务
      clientJobTransformationSendingActor ! Send(counter.incrementAndGet())
    }
    StdIn.readLine()
    system.terminate()
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/09/akka-cluster.png&quot; alt=&quot;akka-cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从结果可以看到，我们将任务根据算法分配给不同的后台节点进行执行，最终返回结果。&lt;/p&gt;

&lt;h3&gt;本文目的&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;掌握集群基本概念&lt;/li&gt;
&lt;li&gt;了解学习Akka cluster的工作方式和主要角色&lt;/li&gt;
&lt;li&gt;尝试自己写一个Akka cluster的相关例子&lt;/li&gt;
&lt;li&gt;下一步进阶了解Akka cluster的背后原理&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;本文的demo例子已上传github：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（九）：Akka分布式之Akka Remote</title>
   <link href="/2017/08/10/learning-akka-9.html"/>
   <updated>2017-08-10T00:00:00+08:00</updated>
   <id>urn:uuid:8d4f2b63-e930-3d54-8ca7-fbvbds2a4fgd</id>
   <content type="html">&lt;p&gt;Akka作为一个天生用于构建分布式应用的工具，当然提供了用于分布式组件即Akka Remote，那么我们就来看看如何用Akka Remote以及Akka Serialization来构建分布式应用。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;很多同学在程序的开发中都会遇到一个问题，当业务需求变得越来越复杂，单机服务器已经不足以承载相应的请求的时候，我们都会考虑将服务部署到不同的服务器上，但服务器之间可能需要相互调用，那么系统必须拥有相互通信的接口，用于相应的数据交互，这时候一个好的远程调用方案是一个绝对的利器，主流的远程通信有以下几种选择：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RPC（Remote Procedure Call Protocol）&lt;/li&gt;
&lt;li&gt;Web Service&lt;/li&gt;
&lt;li&gt;JMS（Java Messaging Service）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这几种方式都是被采用比较广泛的通信方案，有兴趣的同学可以自己去了解一下，这里我会讲一下Java中的RPC即RMI （Remote Method Invocation）和JMS。&lt;/p&gt;

&lt;h3&gt;JAVA远程调用&lt;/h3&gt;

&lt;p&gt;RMI和JMS相信很多写过Java程序的同学都知道，是Java程序用来远程通信的主要方式，那么RMI和JMS又有什么区别呢？&lt;/p&gt;

&lt;h4&gt;1.RMI&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;同步通信：在使用RMI调用远程方法时，线程会持续等待直到结果返回，所以它是一个同步阻塞操作；&lt;/li&gt;
&lt;li&gt;强耦合：请求的系统中需要使用的RMI服务进行接口声明，返回的数据类型有一定的约束；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;实现相对简单，方法调用形式通俗易理解，接口声明服务功能清晰。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;只局限支持JVM平台；&lt;/li&gt;
&lt;li&gt;对无法兼容Java语言的其他语言也不适用；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;2.JMS&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;异步通信：JMS发送消息进行通信，在通信过程中，线程不会被阻塞，不必等待请求回应，所以是一个异步操作；&lt;/li&gt;
&lt;li&gt;松耦合：不需要接口声明，返回的数据类型可以是各种各样，比如JSON，XML等；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.通信方式：&lt;/h5&gt;

&lt;p&gt;（1）点对点消息传送模型&lt;/p&gt;

&lt;p&gt;顾名思义，点对点可以理解为两个服务器的定点通信，发送者和接收者都能明确知道对方是谁，大致模型如下：
&lt;img src=&quot;/media/images/2017/08/jms-point-to-point.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（2）发布/订阅消息传递模型&lt;/p&gt;

&lt;p&gt;点对点模型有些场景并不是很适用，比如有一台主服务器，它产生一条消息需要让所有的从服务器都能收到，若采用点对点模型的话，那主服务器需要循环发送消息，后续若有新的从服务器增加，还要改主服务器的配置，这样就会导致不必要的麻烦，那么发布/订阅模型是怎么样的呢？其实这种模式跟设计模式中的观察者模式很相似，相信很多同学都很熟悉，它最大的特点就是较松耦合，易扩展等特点，所以发布/订阅模型的大致结构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/jms-topic.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;h5&gt;iii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;由于使用异步通信，不需要线程暂停等待，性能相对较高。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iiii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;技术实现相对复杂，并需要维护相关的消息队列；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;更通俗的说：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RMI可以看成是用打电话的方式进行信息交流，而JMS更像是发短信。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总的来说两种方式没有孰优孰劣，我们也不用比较到底哪种方式比较好，存在即合理，更重要的是哪种选择可能更适合你的系统。&lt;/p&gt;

&lt;h3&gt;RMI Example&lt;/h3&gt;

&lt;p&gt;这里我写一个RMI的例子，一方面来看一下它的使用方式，另一方面用于和后续的Akka Remote做一些比较：&lt;/p&gt;

&lt;p&gt;首先我们来编写相应的传输对象和通信接口：&lt;/p&gt;

&lt;p&gt;1.JoinRmiEvt：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class JoinRmiEvt implements Remote , Serializable{
    private static final long serialVersionUID = 1L;
    private Long id;
    private String name;

    public JoinRmiEvt(Long id, String name) {
        this.id = id;
        this.name = name;
    }

    public Long getId() {
        return id;
    }

    public void setId(Long id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.RemoteRmi:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public interface RemoteRmi extends Remote {
    public void sendNoReturn(String message) throws RemoteException, InterruptedException;
    public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在服务端对该接口进行实现：&lt;/p&gt;

&lt;p&gt;3.RemoteRmiImpl:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRmiImpl extends UnicastRemoteObject implements RemoteRmi {

    private static final long serialVersionUID = 1L;

    public  RemoteRmiImpl() throws RemoteException {};

    @Override
    public void sendNoReturn(String message) throws RemoteException, InterruptedException {
        Thread.sleep(2000);
        //throw new RemoteException(); 
    }

    @Override
    public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException {
      if (joinRmiEvt.getId() &amp;gt;= 0)
          return new StringBuilder(&quot;the&quot;).append(joinRmiEvt.getName()).append(&quot;has join&quot;).toString();
      else return null;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接着我们在Server端绑定相应端口并发布服务，然后启动：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRMIServer {
    public static void main(String[] args) throws RemoteException, AlreadyBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the RemoteRMIServer is Starting ...&quot;);
        RemoteRmiImpl remoteRmi = new RemoteRmiImpl();
        System.out.println(&quot;Binding server implementation to registry&quot;);
        LocateRegistry.createRegistry(2553);
        Naming.bind(&quot;rmi://127.0.0.1:2553/remote_rmi&quot;,remoteRmi);
        System.out.println(&quot;the RemoteRMIServer is Started&quot;);
        Thread.sleep(10000000);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们在Client端调用Server端的服务：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRmiClient {
    public static void main(String[] args) throws RemoteException, NotBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the client has started&quot;);
        String url = &quot;rmi://127.0.0.1:2553/remote_rmi&quot;;
        RemoteRmi remoteRmi = (RemoteRmi) Naming.lookup(url);
        System.out.println(&quot;the client has running&quot;);
        remoteRmi.sendNoReturn(&quot;send no return&quot;);
        System.out.println(remoteRmi.sendHasReturn(new JoinRmiEvt(1L,&quot;godpan&quot;)));
        System.out.println(&quot;the client has end&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/java-rmi-result.png&quot; alt=&quot;java-rmi-result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Java Rmi调用是一个阻塞的过程，这会导致一个问题，假如服务端的服务奔溃了，会导致客户端没有反应；&lt;/li&gt;
&lt;li&gt;Java Rmi使用的是Java默认的序列化方式,性能并不是很好，而且并不提供支持使用其他序列化的接口，在一些性能要求高的系统会有一定的瓶颈；&lt;/li&gt;
&lt;li&gt;在Rmi中使用的相应的接口和对象必须实现相应的接口，必须制定抛出相应的Exception，导致代码看起来异常的繁琐；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Remote&lt;/h3&gt;

&lt;p&gt;上面讲到JAVA中远程通信的方式，但我们之前说过Akka也是基于JVM平台的，那么它的通信方式又有什么不同呢？&lt;/p&gt;

&lt;p&gt;在我看来，Akka的远程通信方式更像是RMI和JMS的结合，但更偏向于JMS的方式，为什么这么说呢，我们先来看一个示例:&lt;/p&gt;

&lt;p&gt;我们先来创建一个远程的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class RemoteActor extends Actor {
  def receive = {
    case msg: String =&amp;gt;
      println(s&quot;RemoteActor received message '$msg'&quot;)
      sender ! &quot;Hello from the RemoteActor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们在远程服务器上启动这个Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么现在我们假如有一个系统需要向这个Actor发送消息应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们需要类似RMI发布自己的服务一样，我们需要为其他系统调用远程Actor提供消息通信的接口，在Akka中，设置非常简单，不需要代码侵入，只需简单的在配置文件里配置即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka {
  actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
  }
  remote {
    enabled-transports = [&quot;akka.remote.netty.tcp&quot;]
    netty.tcp {
      hostname = $localIp  //比如127.0.0.1
      port = $port //比如2552
    }
    log-sent-messages = on
    log-received-messages = on
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们只需配置相应的驱动，传输方式，ip，端口等属性就可简单完成Akka Remote的配置。&lt;/p&gt;

&lt;p&gt;当然本地服务器也需要配置这些信息，因为Akka之间是需要相互通信的，当然配置除了hostname有一定的区别外，其他配置信息可一致，本例子是在同一台机器上，所以这里hostname是相同的。&lt;/p&gt;

&lt;p&gt;这时候我们就可以在本地的服务器向这个Actor发送消息了，首先我们可以创建一个本地的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object Init
case object SendNoReturn

class LocalActor extends Actor{

  val path = ConfigFactory.defaultApplication().getString(&quot;remote.actor.name.test&quot;)
  implicit val timeout = Timeout(4.seconds)
  val remoteActor = context.actorSelection(path)

  def receive: Receive = {
    case Init =&amp;gt; &quot;init local actor&quot;
    case SendNoReturn =&amp;gt; remoteActor ! &quot;hello remote actor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;remote.actor.name.test&lt;/code&gt;的值为：“akka.tcp://RemoteDemoSystem@127.0.0.1:4444/user/RemoteActor”，另外我们可以看到我们使用了&lt;code&gt;context.actorSelection(path)&lt;/code&gt;来获取的是一个ActorSelection对象，若是需要获得ActorRef，我们可以调用它的resolveOne(),它返回的是是一个Future[ActorRef],这里是不是很熟悉，因为它跟本地获取Actor方式是一样的，因为Akka中Actor是位置透明的，获取本地Actor和远程Actor是一样的。&lt;/p&gt;

&lt;p&gt;最后我们首先启动远程Actor的系统：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object RemoteDemo extends App  {
  val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
  val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
  remoteActor ! &quot;The RemoteActor is alive&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们在本地系统中启动这个LocalActor，并向它发送消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object LocalDemo extends App {

  implicit val system = ActorSystem(&quot;LocalDemoSystem&quot;)
  val localActor = system.actorOf(Props[LocalActor], name = &quot;LocalActor&quot;)

  localActor ! Init
  localActor ! SendNoReturn
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到RemoteActor收到了一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-no-return.png&quot; alt=&quot;send-no-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从以上的步骤和结果看出可以看出，Akka的远程通信跟JMS的点对点模式似乎更相似一点，但是它有不需要我们维护消息队列，而是使用Actor自身的邮箱，另外我们利用context.actorSelection获取的ActorRef，可以看成远程Actor的副本，这个又和RMI相关概念类似，所以说Akka远程通信的形式上像是RMI和JMS的结合,当然底层还是通过TCP、UDP等相关网络协议进行数据传输的，从配置文件的相应内容便可以看出。&lt;/p&gt;

&lt;p&gt;上述例子演示的是sendNoReturn的模式，那么假如我们需要远程Actor给我们一个回复应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们创建一个消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object SendHasReturn

 def receive: Receive = {
    case SendHasReturn =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(&quot;hello remote actor&quot;)
      } yield r
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们重新运行LocalActor并像RemoteActor发送一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-has-return.png&quot; alt=&quot;send-has-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到LocalActor在发送消息后并收到了RemoteActor返回来的消息，另外我们这里设置了超时时间，若在规定的时间内没有得到反馈，程序就会报错。&lt;/p&gt;

&lt;h3&gt;Akka Serialization&lt;/h3&gt;

&lt;p&gt;其实这一部分本可以单独拿出来写，但是相信序列化这块大家都应该有所了解了，所以就不准备讲太多序列化的知识了，怕班门弄斧，主要讲讲Akka中的序列化。&lt;/p&gt;

&lt;p&gt;继续上面的例子，假如我们这时向RemoteActor发送一个自定义的对象，比如一个case class对象，但是我们这是是在网络中传输这个消息，那么怎么保证这个对象类型和值呢，在同一个JVM系统中我们不需要担心这个，因为对象就在堆中，我们只要传递相应的地址即可就行，但是在不同的环境中，我们并不能这么做，我们在网络中只能传输字节数据，所以我们必须将对象做特殊的处理，在传输的时候转化成特定的由一连串字节组成的数据，而且我们又可以根据这些数据恢复成一个相应的对象，这便是序列化。&lt;/p&gt;

&lt;p&gt;我们先定义一个参与的case class, 并修改一下上面发送消息的语句:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case object SendSerialization
case class JoinEvt(
    id: Long,
    name: String
)
def receive: Receive = {
    case SendSerialization =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(JoinEvt(1L,&quot;godpan&quot;))
      } yield println(r)
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时我们重新启动RemoteActor和LocalActor所在的系统，发送这条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-serialization.png&quot; alt=&quot;send-serialization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有同学可能会觉得奇怪，我们明明没有对JoinEvt进行过任何序列化的标识和处理，为什么程序还能运行成功呢？&lt;/p&gt;

&lt;p&gt;其实不然，只不过是有人替我们默认做了，不用说，肯定是贴心的Akka，它为我们提供了一个默认的序列化策略，那就是我们熟悉又纠结的java.io.Serializable，沉浸在它的易使用性上，又对它的性能深恶痛绝，尤其是当有大量对象需要传输的分布式系统，如果是小系统，当我没说，毕竟存在即合理。&lt;/p&gt;

&lt;p&gt;又有同学说，既然Akka是一个天生分布式组件，为什么还用低效的java.io.Serializable，你问我我也不知道，可能当时的作者偷了偷懒，当然Akka现在可能觉醒了，首先它支持第三方的序列化工具，当然如果你有特殊需求，你也可以自己实现一个，而且在最新的文档中说明，在Akka 2.5x之后Akka内核消息全面废弃java.io.Serializable，用户自定义的消息暂时还是支持使用java.io.Serializable的，但是不推荐用，因为它是低效的，容易被攻击，所以在这里我也推荐大家再Akka中尽量不要在使用了java.io.Serializable。&lt;/p&gt;

&lt;p&gt;那么在Akka中我们如何使用第三方的序列化工具呢？&lt;/p&gt;

&lt;p&gt;这里我推荐一个在Java社区已经久负盛名的序列化工具：kryo，有兴趣的同学可以去了解一下：&lt;a href=&quot;https://github.com/EsotericSoftware/kryo&quot;&gt;kryo&lt;/a&gt;,而且它也提供Akka使用的相关包，这里我们就使用它作为示例：&lt;/p&gt;

&lt;p&gt;这里我贴上整个项目的build.sbt, kryo的相关依赖也在里面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
import sbt._
import sbt.Keys._

lazy val AllLibraryDependencies =
  Seq(
    &quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.5.3&quot;,
    &quot;com.typesafe.akka&quot; %% &quot;akka-remote&quot; % &quot;2.5.3&quot;,
    &quot;com.twitter&quot; %% &quot;chill-akka&quot; % &quot;0.8.4&quot;
  )

lazy val commonSettings = Seq(
  name := &quot;AkkaRemoting&quot;,
  version := &quot;1.0&quot;,
  scalaVersion := &quot;2.11.11&quot;,
  libraryDependencies := AllLibraryDependencies
)

lazy val remote = (project in file(&quot;remote&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )

lazy val local = (project in file(&quot;local&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们只需将application.conf中的actor配置替换成以下的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
    serializers {
      kryo = &quot;com.twitter.chill.akka.AkkaSerializer&quot;
    }
    serialization-bindings {
      &quot;java.io.Serializable&quot; = none
      &quot;scala.Product&quot; = kryo
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实其中的&quot;java.io.Serializable&quot; = none可以省略，因为若是有其他序列化的策略则会替换掉默认的java.io.Serializable的策略，这里只是为了更加仔细的说明。&lt;/p&gt;

&lt;p&gt;至此我们就可以使用kryo了，整个过程是不是很easy，迫不及待开始写demo了，那就快快开始吧。&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Akka Remote使用内置的序列化工具，并支持配置指定的序列化方式，可以按需配置；&lt;/li&gt;
&lt;li&gt;Akka Remote使用的过程是一个异步非阻塞的过程，客户端能尽量减少对服务端的依赖；&lt;/li&gt;
&lt;li&gt;Akka Remote的代码实现相对Java Rmi实现来说简单的多，非常简洁；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;整个例子的相关的源码已经上传到akka-demo中：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_06&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（八）：Akka persistence设计理念之CQRS</title>
   <link href="/2017/07/29/learning-akka-8.html"/>
   <updated>2017-07-29T00:00:00+08:00</updated>
   <id>urn:uuid:8dcf2b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这一篇文章主要是讲解Akka persistence的核心设计理念，也是CQRS（Command Query Responsibility Segregation）架构设计的典型应用，就让我们来看看为什么Akka persistence会采用CQRS架构设计。&lt;/p&gt;

&lt;h3&gt;CQRS&lt;/h3&gt;

&lt;p&gt;很多时候我们在处理高并发的业务需求的时候，往往能把应用层的代码优化的很好，比如缓存，限流，均衡负载等，但是很难避免的一个问题就是数据的持久化，以致数据库的性能很可能就是系统性能的瓶颈，我前面的那篇文章也讲到，如果我们用数据库去保证记录的CRUD，在并发高的情况下，让数据库执行这么多的事务操作，会让很多数据库操作超时，连接池不够用的情况，导致大量请求失败，系统的错误率上升和负载性能下降。&lt;/p&gt;

&lt;p&gt;既然这样，那我们可不可借鉴一下读写分离的思想呢？假使写操作和同操作分离，甚至是对不同数据表，数据库操作，那么我们就可以大大降低数据库的瓶颈，使整个系统的性能大大提升。那么CQRS到底是做了什么呢？&lt;/p&gt;

&lt;p&gt;我们先来看看普通的方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/acid.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看出，我们对数据的请求都是通过相应的接口直接对数据库进行操作，这在并发大的时候肯定会对数据库造成很大的压力，虽然架构简单，但在面对并发高的情况下力不从心。&lt;/p&gt;

&lt;p&gt;那么CQRS的方式有什么不同呢？我们也来看看它的执行方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;乍得一看，似乎跟普通的方式没什么不同啊，不就多了一个事件和存储DB么，其实不然，小小的改动便是核心理念的转换，首先我们可以看到在CQRS架构中会多出一个Event，那它到底代表着什么含义呢？其实看过上篇文章的同学很容易理解，Event是我们系统根据请求处理得出的一个领域模型，比如一个修改余额操作事件，当然这个Event中只会保存关键性的数据。&lt;/p&gt;

&lt;p&gt;很多同学又有疑问了，这不跟普通的读写分离很像么，难道还隐藏着什么秘密？那我们就来比较一下几种方式的不同之处：&lt;/p&gt;

&lt;h5&gt;1.单数据库模式&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;写操作会产生互斥锁，导致性能降低；&lt;/li&gt;
&lt;li&gt;即使使用乐观锁，但是在大量写操作的情况下也会大量失败；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;2.读写分离&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;读写分离通过物理服务器增加，负荷增加；&lt;/li&gt;
&lt;li&gt;读写分离更适用于读操作大于写操作的场景；&lt;/li&gt;
&lt;li&gt;读写分离在面对大量写操作的情况下还是很吃力；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;3.CQRS&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;普通数据的持久化和Event持久化可以使用同一台数据库；&lt;/li&gt;
&lt;li&gt;利用架构设计可以使读和写操作尽可能的分离；&lt;/li&gt;
&lt;li&gt;能支撑大量写的操作情况；&lt;/li&gt;
&lt;li&gt;可以支持数据异步持久，确保数据最终一致性；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;从三种方式各自的特点可以看出，单数据库模式的在大量读写的情况下有很大的性能瓶颈，但简单的读写分离在面对大量写操作的时候也还是力不从心，比如最常见的库存修改查询场景：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/common-action.png&quot; alt=&quot;common-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以发现在这种模式下写数据库的压力还会很大，而且还有数据同步，数据延迟等问题。&lt;/p&gt;

&lt;p&gt;那么我们用CQRS架构设计会是怎么样呢：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-action.png&quot; alt=&quot;cqrs-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先我们可以业务模型进行分离，对不同的查询进行分离，另外避免不了的同一区间数据段进行异步持久化，在保证数据一致性的情况下提升系统的吞吐量。这种设计我们很少会遇到事务竞争，另外还可以使用内存数据库（当然如果是内存操作那就最快）来提升数据的写入。（以上的数据库都可为分布式数据库，不担心单机宕机）&lt;/p&gt;

&lt;p&gt;那么CRQS机制是怎么保证数据的一致性的呢？&lt;/p&gt;

&lt;p&gt;从上图中我们可以看出，一个写操作我们会在系统进行初步处理后生成一个领域事件，比如a用户购买了xx商品1件，b用户购买了xx商品2件等，按照普通的方式我们肯定是直接将订单操作，库存修改操作一并放在一个事务内去操作数据库，性能可想而知，而用CQRS的方式后，首先系统在持久化相应的领域事件后和修改内存中的库存（这个处理非常迅速）后便可马上向用户做出反应，真正的具体信息持久可以异步进行，当然若是当在具体信息持久化的过程中出错了怎么办，系统能恢复正确的数据么，当然可以，因为我们的领域事件事件已经持久化成功了，在系统恢复的时候，我们可以根据领域事件来恢复真正的数据，当然为了防止恢复数据是造成数据丢失，数据重复等问题我们需要制定相应的原则，比如给领域事件分配相应id等。&lt;/p&gt;

&lt;p&gt;使用CQRS会带来性能上的提升，当然它也有它的弊端：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使系统变得更复杂，做一些额外的设计；&lt;/li&gt;
&lt;li&gt;CQRS保证的是最终一致性，有可能只适用于特定的业务场景；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Persistence 中CQRS的应用&lt;/h3&gt;

&lt;p&gt;通过上面的讲解，相信大家对CQRS已经有了一定的了解，下面我们就来看看它在Akka Persistence中的具体应用，这里我就结合上一篇文章抽奖的例子，比如其中的LotteryCmd便是一个写操作命令，系统经过相应的处理后得到相应的领域事件，比如其中LuckyEvent，然后我们将LuckyEvent进行持久化，并修改内存中抽奖的余额，返回相应的结果，这里我们就可以同时将结果反馈给用户，并对结果进行异步持久化，流程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-example.png&quot; alt=&quot;cqrs-example&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出，Akka Persistence的原理完全是基于CQRS的架构设计的，另外Persistence Actor还会保存一个内存状态，相当于一个in memory数据库，可以用来提供关键数据的存储和查询，比如前面说到的库存，余额等数据，这部分的设计取决于具体的业务场景。&lt;/p&gt;

&lt;p&gt;阅读Akka Persistence相关源码，其的核心就在于PersistentActor接口中的几个持久方法，比如其中的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;def persist[A](event: A)(handler: A ⇒ Unit): Unit

def persistAll[A](events: immutable.Seq[A])(handler: A ⇒ Unit): Unit 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等方法，它们都有两个参数，一个是持久化的事件，一个是持久化后的后续处理逻辑，我们可以在后续handler中修改Actor内部状态，向外部发送消息等操作,这里的模式就是基于CQRS架构的，修改状态有事件驱动，另外Akka还可以在系统出错时，利用相应的事件恢复Actor的状态。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;总的来说，CQRS架构是一种不同于以往的CRUD的架构，所以你在享受它带来的高性能的同时可能会遇到一些奇怪的问题，当然这些都是可以解决的，重要的是思维上的改变，比如事件驱动，领域模型等概念，不过相信当你理解并掌握它之后，你便会爱上它的。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（七）：Actor持久化之Akka persistence</title>
   <link href="/2017/07/25/learning-akka-7.html"/>
   <updated>2017-07-25T00:00:00+08:00</updated>
   <id>urn:uuid:8dcf2b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这次把这部分内容提到现在写，是因为这段时间开发的项目刚好在这一块遇到了一些难点，所以准备把经验分享给大家，我们在使用Akka时，会经常遇到一些存储Actor内部状态的场景，在系统正常运行的情况下，我们不需要担心什么，但是当系统出错，比如Actor错误需要重启，或者内存溢出，亦或者整个系统崩溃，如果我们不采取一定的方案的话，在系统重启时Actor的状态就会丢失，这会导致我们丢失一些关键的数据，造成系统数据不一致的问题。Akka作为一款成熟的生产环境应用，为我们提供了相应的解决方案就是Akka persistence。&lt;/p&gt;

&lt;h3&gt;为什么需要持久化的Actor？&lt;/h3&gt;

&lt;p&gt;万变不离其宗，数据的一致性是永恒的主题，一个性能再好的系统，不能保证数据的正确，也称不上是一个好的系统，一个系统在运行的时候难免会出错，如何保证系统在出错后能正确的恢复数据，不让数据出现混乱是一个难题。使用Actor模型的时候，我们会有这么一个想法，就是能不对数据库操作就尽量不对数据库操作（这里我们假定我们的数据库是安全，可靠的，能保证数据的正确性和一致性，比如使用国内某云的云数据库），一方面如果大量的数据操作会使数据库面临的巨大的压力，导致崩溃，另一方面即使数据库能处理的过来，比如一些count，update的大表操作也会消耗很多的时间，远没有内存中直接操作来的快，大大影响性能。但是又有人说内存操作这么快，为什么不把数据都放内存中呢？答案显而易见，当出现机器死机，或者内存溢出等问题时，数据很有可能就丢失了导致无法恢复。在这种背景下，我们是不是有一种比较好的解决方案，既能满足需求又能用最小的性能消耗，答案就是上面我们的说的Akka persistence。&lt;/p&gt;

&lt;h3&gt;Akka persistence的核心架构&lt;/h3&gt;

&lt;p&gt;在具体深入Akka persistence之前，我们可以先了解一下它的核心设计理念，其实简单来说，我们可以利用一些thing来恢复Actor的状态，这里的thing可以是日志、数据库中的数据，亦或者是文件，所以说它的本质非常容易理解，在Actor处理的时候我们会保存一些数据，Actor在恢复的时候能根据这些数据恢复其自身的状态。&lt;/p&gt;

&lt;p&gt;所以Akka persistence 有以下几个关键部分组成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PersistentActor：任何一个需要持久化的Actor都必须继承它，并必须定义或者实现其中的三个关键属性：&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt; def persistenceId = &quot;example&quot; //作为持久化Actor的唯一表示，用于持久化或者查询时使用

 def receiveCommand: Receive = ??? //Actor正常运行时处理处理消息逻辑，可在这部分内容里持久化自己想要的消息

 def receiveRecover: Receive = ??? //Actor重启恢复是执行的逻辑
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比普通的Actor，除receiveCommand相似以外，还必须实现另外两个属性。
另外在持久化Actor中还有另外两个关键的的概念就是&lt;em&gt;Journal&lt;/em&gt;和&lt;em&gt;Snapshot&lt;/em&gt;，前者用于持久化事件，后者用于保存Actor的快照，两者在Actor恢复状态的时候都起到了至关重要的作用。&lt;/p&gt;

&lt;h3&gt;Akka persistence的demo实战&lt;/h3&gt;

&lt;p&gt;这里我首先会用一个demo让大家能对Akka persistence的使用有一定了解的，并能大致明白它的工作原理，后面再继续讲解一些实战可能会遇到的问题。&lt;/p&gt;

&lt;p&gt;假定现在有这么一个场景，现在假设有一个1w元的大红包，瞬间可能会很多人同时来抢，每个人抢的金额也可能不一样，场景很简单，实现方式也有很多种，但前提是保证数据的正确性，比如最普通的使用数据库保证，但对这方面有所了解的同学都知道这并不是一个很好的方案，因为需要锁，并需要大量的数据库操作，导致性能不高，那么我们是否可以用Actor来实现这个需求么？答案是当然可以。&lt;/p&gt;

&lt;p&gt;我们首先来定义一个抽奖命令，
&lt;code&gt;scala
case class LotteryCmd(
  userId: Long, // 参与用户Id
  username: String, //参与用户名
  email: String // 参与用户邮箱
)
&lt;/code&gt;
然后我们实现一个抽奖Actor，并继承PersistentActor作出相应的实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case class LuckyEvent(  //抽奖成功事件
    userId: Long,
    luckyMoney: Int
)
case class FailureEvent(  //抽奖失败事件
    userId: Long,
    reason: String
)
case class Lottery(
    totalAmount: Int,  //红包总金额
    remainAmount: Int  //剩余红包金额
) {
  def update(luckyMoney: Int) = {
    copy(
      remainAmount = remainAmount - luckyMoney
    )
  }
}
class LotteryActor(initState: Lottery) extends PersistentActor with ActorLogging{
  override def persistenceId: String = &quot;lottery-actor-1&quot;

  var state = initState  //初始化Actor的状态

  override def receiveRecover: Receive = {
    case event: LuckyEvent =&amp;gt;
      updateState(event)  //恢复Actor时根据持久化的事件恢复Actor状态
    case SnapshotOffer(_, snapshot: Lottery) =&amp;gt;
      log.info(s&quot;Recover actor state from snapshot and the snapshot is ${snapshot}&quot;)
      state = snapshot //利用快照恢复Actor的状态
    case RecoveryCompleted =&amp;gt; log.info(&quot;the actor recover completed&quot;)
  }

  def updateState(le: LuckyEvent) =
    state = state.update(le.luckyMoney)  //更新自身状态

  override def receiveCommand: Receive = {
    case lc: LotteryCmd =&amp;gt;
      doLottery(lc) match {     //进行抽奖，并得到抽奖结果，根据结果做出不同的处理
        case le: LuckyEvent =&amp;gt;  //抽到随机红包
          persist(le) { event =&amp;gt;
            updateState(event)
            increaseEvtCountAndSnapshot()
            sender() ! event
          }
        case fe: FailureEvent =&amp;gt;  //红包已经抽完
          sender() ! fe
      }
    case &quot;saveSnapshot&quot; =&amp;gt;  // 接收存储快照命令执行存储快照操作
      saveSnapshot(state)
    case SaveSnapshotSuccess(metadata) =&amp;gt;  ???  //你可以在快照存储成功后做一些操作，比如删除之前的快照等
  }

  private def increaseEvtCountAndSnapshot() = {
    val snapShotInterval = 5
    if (lastSequenceNr % snapShotInterval == 0 &amp;amp;&amp;amp; lastSequenceNr != 0) {  //当有持久化5个事件后我们便存储一次当前Actor状态的快照
      self ! &quot;saveSnapshot&quot;
    }
  }

  def doLottery(lc: LotteryCmd) = {  //抽奖逻辑具体实现
    if (state.remainAmount &amp;gt; 0) {
      val luckyMoney = scala.util.Random.nextInt(state.remainAmount) + 1
      LuckyEvent(lc.userId, luckyMoney)
    }
    else {
      FailureEvent(lc.userId, &quot;下次早点来，红包已被抽完咯！&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;程序很简单，关键位置我也给了注释，相信大家对Actor有所了解的话很容易理解，当然要是有些疑惑，可以看看我之前写的文章，下面我们就对刚才写的抽红包Actor进行测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object PersistenceTest extends App {
  val lottery = Lottery(10000,10000)
  val system = ActorSystem(&quot;example-05&quot;)
  val lotteryActor = system.actorOf(Props(new LotteryActor(lottery)), &quot;LotteryActor-1&quot;)  //创建抽奖Actor
  val pool: ExecutorService = Executors.newFixedThreadPool(10)
  val r = (1 to 100).map(i =&amp;gt;
    new LotteryRun(lotteryActor, LotteryCmd(i.toLong,&quot;godpan&quot;,&quot;xx@gmail.com&quot;))  //创建100个抽奖请求
  )
  r.map(pool.execute(_))  //使用线程池来发起抽奖请求，模拟同时多人参加
  Thread.sleep(5000)
  pool.shutdown()
  system.terminate()
}

class LotteryRun(lotteryActor: ActorRef, lotteryCmd: LotteryCmd) extends Runnable { //抽奖请求
  implicit val timeout = Timeout(3.seconds)
  def run: Unit = {
    for {
      fut &amp;lt;- lotteryActor ? lotteryCmd
    } yield fut match {  //根据不同事件显示不同的抽奖结果
      case le: LuckyEvent =&amp;gt; println(s&quot;恭喜用户${le.userId}抽到了${le.luckyMoney}元红包&quot;)
      case fe: FailureEvent =&amp;gt;  println(fe.reason)
      case _ =&amp;gt; println(&quot;系统错误，请重新抽取&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行程序,我们可能看到以下的结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/result-persistence-demo.png&quot; alt=&quot;result persistence demo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面我会把persistence actor在整个运行过程的步骤给出，帮助大家理解它的原理：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.初始化Persistence Actor&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.1若是第一次初始化，则与正常的Actor的初始化一致。&lt;/li&gt;
&lt;li&gt;1.2若是重启恢复Actor，这根据Actor之前持久的数据恢复。

&lt;ul&gt;
&lt;li&gt;1.2.1从快照恢复，可快速恢复Actor，但并非每次持久化事件都会保存快照，在快照完整的情况下，Actor优先从快照恢复自身状态。&lt;/li&gt;
&lt;li&gt;1.2.2从事件（日志，数据库记录等）恢复，通过重放持久化事件恢复Actor状态，比较关键。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2.接收命令进行处理，转化为需要持久化的事件（持久化的事件尽量只包含关键性的数据）使用Persistence Actor的持久化方法进行持久化（上述例子中的persist，后面我会讲一下批量持久化），并处理持久化成功后的逻辑处理，比如修改Actor状态，向外部Actor发送消息等。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;3.若是我们需要存储快照，那么可以主动指定存储快照的频率，比如持久化事件100次我们就存储一次快照，这个频率应该要考虑实际的业务场景，在存储快照成功后我们也可以执行一些操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说Persistence Actor运行时的大致操作就是以上这些，当然它是r如何持久化事件，恢复时的机制是怎么样的等有兴趣的可以看一下Akka源码。&lt;/p&gt;

&lt;h3&gt;使用Akka persistence的相关配置&lt;/h3&gt;

&lt;p&gt;首先我们必须加载相应的依赖包，在&lt;code&gt;bulid.sbt&lt;/code&gt;中加入以下依赖：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(
&quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.4.16&quot;,  //Akka actor 核心依赖
  &quot;com.typesafe.akka&quot; %% &quot;akka-persistence&quot; % &quot;2.4.16&quot;, //Akka persistence 依赖
  &quot;org.iq80.leveldb&quot;            % &quot;leveldb&quot;          % &quot;0.7&quot;, //leveldb java版本依赖
  &quot;org.fusesource.leveldbjni&quot;   % &quot;leveldbjni-all&quot;   % &quot;1.8&quot;, //leveldb java版本依赖
  &quot;com.twitter&quot;              %% &quot;chill-akka&quot;                  % &quot;0.8.0&quot; //事件序列化依赖
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外我们还需在&lt;code&gt;application.conf&lt;/code&gt;加入以下配置:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;akka.persistence.journal.plugin = &quot;akka.persistence.journal.leveldb&quot;
akka.persistence.snapshot-store.plugin = &quot;akka.persistence.snapshot-store.local&quot;

akka.persistence.journal.leveldb.dir = &quot;log/journal&quot;
akka.persistence.snapshot-store.local.dir = &quot;log/snapshots&quot;

# DO NOT USE THIS IN PRODUCTION !!!
# See also https://github.com/typesafehub/activator/issues/287
akka.persistence.journal.leveldb.native = false  //因为我们本地并没有安装leveldb，所以这个属性置为false，但是生产环境并不推荐使用

akka.actor.serializers {
  kryo = &quot;com.twitter.chill.akka.AkkaSerializer&quot;
}

akka.actor.serialization-bindings {
  &quot;scala.Product&quot; = kryo
  &quot;akka.persistence.PersistentRepr&quot; = kryo
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此为止我们整个Akka persistence demo已经搭建好了，可以正常运行了，有兴趣的同学可以下载源码。&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_05&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Akka persistence进阶&lt;/h3&gt;

&lt;h4&gt;1.持久化插件&lt;/h4&gt;

&lt;p&gt;有同学可能会问，我对leveldb不是很熟悉亦或者觉得单机存储并不是安全，有没有支持分布式数据存储的插件呢，比如某爸的云数据库？答案当然是有咯，良心的我当然是帮你们都找好咯。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.akka-persistence-sql-async: 支持MySQL和PostgreSQL，另外使用了全异步的数据库驱动，提供异步非阻塞的API，我司用的就是它的变种版，6的飞起。&lt;a href=&quot;https://github.com/okumin/akka-persistence-sql-async&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2.akka-persistence-cassandra: 官方推荐的插件，使用写性能very very very fast的cassandra数据库，是几个插件中比较流行的一个，另外它还支持persistence query。&lt;a href=&quot;https://github.com/krasserm/akka-persistence-cassandra&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;3.akka-persistence-redis: redis应该也很符合Akka persistence的场景，熟悉redis的同学可以使用看看。&lt;a href=&quot;https://github.com/hootsuite/akka-persistence-redis&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;4.akka-persistence-jdbc: 怎么能少了jdbc呢？不然怎么对的起java爸爸呢，支持scala和java哦。&lt;a href=&quot;https://github.com/dnvriend/akka-persistence-jdbc&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;相应的插件的具体使用可以看该项目的具体介绍使用，我看了下相对来说都是比较容易的。&lt;/p&gt;

&lt;h4&gt;2.批量持久化&lt;/h4&gt;

&lt;p&gt;上面说到我司用的是akka-persistence-sql-async插件，所以我们是将事件和快照持久化到数据库的，一开始我也是像上面demo一样，每次事件都会持久化到数据库，但是后来在性能测试的时候，因为本身业务场景对数据库的压力也比较大，在当数据库到达每秒1000+的读写量后，另外说明一下使用的是某云数据库，性能中配以上，发现每次持久化的时间将近要15ms，这样换算一下的话Actor每秒只能处理60~70个需要持久化的事件，而实际业务场景要求Actor必须在3秒内返回处理结果，这种情况下导致大量消息处理超时得不到反馈，另外还有大量的消息得不到处理，导致系统错误暴增，用户体验下降，既然我们发现了问题，那么我们能不能进行优化呢?事实上当然是可以，既然单个插入慢，那么我们能不能批量插入呢，Akka persistence为我们提供了persistAll方法，下面我就对上面的demo进行一下改造，让其变成批量持久化：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class LotteryActorN(initState: Lottery) extends PersistentActor with ActorLogging{
  override def persistenceId: String = &quot;lottery-actor-2&quot;

  var state = initState  //初始化Actor的状态

  override def receiveRecover: Receive = {
    case event: LuckyEvent =&amp;gt;
      updateState(event)  //恢复Actor时根据持久化的事件恢复Actor状态
    case SnapshotOffer(_, snapshot: Lottery) =&amp;gt;
      log.info(s&quot;Recover actor state from snapshot and the snapshot is ${snapshot}&quot;)
      state = snapshot //利用快照恢复Actor的状态
    case RecoveryCompleted =&amp;gt; log.info(&quot;the actor recover completed&quot;)
  }

  def updateState(le: LuckyEvent) =
    state = state.update(le.luckyMoney)  //更新自身状态

  var lotteryQueue : ArrayBuffer[(LotteryCmd, ActorRef)] = ArrayBuffer()

  context.system.scheduler  //定时器，定时触发抽奖逻辑
    .schedule(
      0.milliseconds,
      100.milliseconds,
      new Runnable {
        def run = {
          self ! &quot;doLottery&quot;
        }
      }
    )

  override def receiveCommand: Receive = {
    case lc: LotteryCmd =&amp;gt;
      lotteryQueue = lotteryQueue :+ (lc, sender())  //参与信息加入抽奖队列
      println(s&quot;the lotteryQueue size is ${lotteryQueue.size}&quot;)
      if (lotteryQueue.size &amp;gt; 5)  //当参与人数有5个时触发抽奖
        joinN(lotteryQueue)
    case &quot;doLottery&quot; =&amp;gt;
      if (lotteryQueue.size &amp;gt; 0)
        joinN(lotteryQueue)
    case &quot;saveSnapshot&quot; =&amp;gt;  // 接收存储快照命令执行存储快照操作
      saveSnapshot(state)
    case SaveSnapshotSuccess(metadata) =&amp;gt;  ???  //你可以在快照存储成功后做一些操作，比如删除之前的快照等
  }

  private def joinN(lotteryQueue: ArrayBuffer[(LotteryCmd, ActorRef)]) = {  //批量处理抽奖结果
    val rs = doLotteryN(lotteryQueue)
    val success = rs.collect {  //得到其中中奖的相应信息
      case (event: LuckyEvent, ref: ActorRef) =&amp;gt;
        event -&amp;gt; ref
    }.toMap
    val failure = rs.collect {  //得到其中未中奖的相应信息
      case (event: FailureEvent, ref: ActorRef) =&amp;gt; event -&amp;gt; ref
    }
    persistAll(success.keys.toIndexedSeq) {  //批量持久化中奖用户事件
      case event =&amp;gt;  println(event)
        updateState(event)
        increaseEvtCountAndSnapshot()
        success(event) ! event
    }
    failure.foreach {
      case (event, ref) =&amp;gt; ref ! event
    }
    this.lotteryQueue.clear()  //清空参与队列
  }


  private def increaseEvtCountAndSnapshot() = {
    val snapShotInterval = 5
    if (lastSequenceNr % snapShotInterval == 0 &amp;amp;&amp;amp; lastSequenceNr != 0) {  //当有持久化5个事件后我们便存储一次当前Actor状态的快照
      self ! &quot;saveSnapshot&quot;
    }
  }

  private def doLotteryN(lotteryQueue: ArrayBuffer[(LotteryCmd, ActorRef)]) = {  //抽奖逻辑具体实现
    var remainAmount = state.remainAmount
    lotteryQueue.map(lq =&amp;gt;
      if (remainAmount &amp;gt; 0) {
        val luckyMoney = scala.util.Random.nextInt(remainAmount) + 1
        remainAmount = remainAmount - luckyMoney
        (LuckyEvent(lq._1.userId, luckyMoney),lq._2)
      }
      else {
        (FailureEvent(lq._1.userId, &quot;下次早点来，红包已被抽完咯！&quot;),lq._2)
      }
    )
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是改造后的参与Actor，实现了批量持久的功能，当然这里为了给发送者返回消息，处理逻辑稍微复杂了一点，不过真实场景可能会更复杂，相关源码也在刚才的项目上。&lt;/p&gt;

&lt;h4&gt;3.Persistence Query&lt;/h4&gt;

&lt;p&gt;另外Akka Persistence还提供了Query接口，用于需要查询持久化事件的需求，这部分内容可能要根据实际业务场景考虑是否需要应用，我就不展开讲了，另外我也写了一个小demo在项目中，想要尝试的同学也可以试试。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（六）：Actor解决了什么问题？</title>
   <link href="/2017/07/10/learning-akka-6.html"/>
   <updated>2017-07-10T00:00:00+08:00</updated>
   <id>urn:uuid:85cf4b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这段时间由于忙毕业前前后后的事情，拖更了很久，表示非常抱歉，回归后的第一篇文章主要是看到了Akka最新文档中写的&lt;a href=&quot;http://doc.akka.io/docs/akka/current/scala/guide/actors-intro.html&quot;&gt;What problems does the actor model solve?&lt;/a&gt;,阅读完后觉得还是蛮不错，能简洁清晰的阐述目前并发领域遇到的问题，并为何利用Actor模型可以解决这些问题，本文主要是利用自己的理解将这篇文章进行翻译，有不足之处还请指出。&lt;/p&gt;

&lt;h2&gt;Actor解决了什么问题？&lt;/h2&gt;

&lt;p&gt;Akka使用Actor模型来克服传统面向对象编程模型的局限性，并应对高并发分布式系统所带来的挑战。 充分理解Actor模型是必需的，它有助于我们认识到传统的编程方法在并发和分布式计算的领域上的不足之处。&lt;/p&gt;

&lt;h3&gt;封装的弊端&lt;/h3&gt;

&lt;p&gt;面向对象编程（OOP）是一种广泛采用的，熟悉的编程模型，它的一个核心理念就是封装，并规定对象封装的内部数据不能从外部直接访问，只允许相关的属性方法进行数据操作，比如我们熟悉的Javabean中的getX，setX等方法，对象为封装的内部数据提供安全的数据操作。&lt;/p&gt;

&lt;p&gt;举个例子，有序二叉树必须保证树节点数据的分布规则，若你想利用有序二叉树进行查询相关数据，就必须要依赖这个约束。&lt;/p&gt;

&lt;p&gt;当我们在分析面向对象编程在运行时的行为时，我们可能会绘制一个消息序列图，用来显示方法调用时的交互，如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart.png&quot; alt=&quot;seq chart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但上述图表并不能准确地表示实例在执行过程中的生命线。实际上，一个线程执行所有这些调用，并且变量的操作也在调用该方法的同一线程上。为刚才的序列图加上执行线程，看起来像这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart-thread.png&quot; alt=&quot;seq chart thread&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但当在面对多线程的情况下，会发现此前的图越来越混乱和变得不清晰，现在我们模拟多个线程访问同一个示例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart-multi-thread.png&quot; alt=&quot;seq chart multi thread&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在上面的这种情况中，两个线程调用同一个方法，但别调用的对象并不能保证其封装的数据发生了什么，两个调用的方法指令可以任意方式的交织，无法保证共享变量的一致性，现在，想象一下在更多线程下这个问题会更加严重。&lt;/p&gt;

&lt;p&gt;解决这个问题最通常的方法就是在该方法上加锁。通过加锁可以保证同一时刻只有一个线程能进入该方法，但这是一个代价非常昂贵的方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;锁非常严重的限制并发，它在现在的CPU架构上代价是非常大的，它需要操作系统暂停和重启线程。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;调用者的线程会被阻塞，以致于它不能去做其他有意义的任务，举个例子我们希望桌面程序在后台运行的时候，操作UI界面也能得到响应。在后台，，线程阻塞完全是浪费的，有人可能会说可以通过启动新线程进行补偿，但线程也是一种非常昂贵的资源。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用锁会导致一个新的问题：死锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这些现实存在的问题让我们只能两者选一：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;不使用锁，但会导致状态混乱。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用大量的锁，但是会降低性能并很容易导致死锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;另外，锁只能在本地更好的利用，当我们的程序部署在不同的机器上时，我们只能选择使用分布式锁，但不幸的是，分布式锁的效率可能比本地锁低好几个量级，对后续的扩展也会有很大的限制，分布式锁的协议要求多台机器在网络上进行相互通信，因此延迟可能会变得非常高。&lt;/p&gt;

&lt;p&gt;在面向对象语言中，我们很少会去考虑线程或者它的执行路径，我们通常将系统想象成许多实例对象连接成的网络，通过方法调用，修改实例对象内部的状态，然后通过实例对象之前的方法调用驱动整个程序进行交互：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/object-graph.png&quot; alt=&quot;object graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后，在多线程分布式环境中，实际上线程是通过方法调用遍历这个对象实例网络。因此，线程是方法调用驱动执行的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/object-graph-snakes.png&quot; alt=&quot;object graph snakes&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对象只能保证在单一线程中封装数据的正确性，在多线程环境下可能会导致状态混乱，在同一个代码段，两个竞争的线程可能导致变量的不一致。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用锁看起来可以在多线程环境下保证封装数据的正确性，但实际上它在程序真是运行时是低效的并且很容易导致死锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁在单机工作可能还不错，但是在分布式的环境表现的很不理想，扩展性很差。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;共享内存在现代计算机架构上的弊端&lt;/h3&gt;

&lt;p&gt;在80-90年代的编程模型概念中，写一个变量相当于直接把它写入内存，但是在现代的计算机架构中，我们做了一些改变，写入相应的缓存中而不是直接写入内存，大多数缓存都是CPU核心的本地缓存，但是由一个CPU写入的缓存对其他CPU是不可见的。为了让本地缓存的变化对其他CPU或者线程可见的话，缓存必须进行交互。&lt;/p&gt;

&lt;p&gt;在JVM上，我们必须使用volatile标识或者Atomic包装类来保证内存对跨线程的共享，否则，我们只能用锁来保证共享内存的正确性。那么我们为什么不在所有的变量上都加volatile标识呢？因为在缓存间交互信息是一个代价非常昂贵的操作，而且这个操作会隐式的阻止CPU核心不能去做其他的工作，并且会导致缓存一致性协议（缓存一致性协议是指CPU用于在主内存和其他CPU之间传输缓存）的瓶颈。&lt;/p&gt;

&lt;p&gt;即使开发者认识到这些问题，弄清楚哪些内存位置需要使用volatile标识或者Atomic包装类，但这并非是一种很好的解决方案，可能到程序后期，你都不清楚自己做了什么。&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;没有真正的共享内存了，CPU核心就像网络上的计算机一样，将数据块（高速缓存行）明确地传递给彼此。CPU间的通信和网络通信有更多的共同点。 现在通过CPU或网络计算机传递消息是标准的。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用共享内存标识或者Atomic数据结构来代替隐藏消息传递，其实有一种更加规范的方法就是将共享状态保存在并发实体内，并明确并发实体间通过消息来传递事件和数据。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;调用堆栈的弊端&lt;/h3&gt;

&lt;p&gt;今天，我们还经常调用堆栈来进行任务执行，但是它是在并发并不那么重要的时代发明的，因为当时多核的CPU系统并不常见。调用堆栈不能跨线程，所以不能进行异步调用。&lt;/p&gt;

&lt;p&gt;线程在将任务委托后台执行会出现一个问题，实际中，是将任务委托给另一个线程执行，这不是简单的方法调用，而是有本地的线程直接调用执行，通常来说，一个调用者线程将任务添加到一个内存位置中，具体的工作线程可以不断的从中选取任务进行执行，这样的话，调用者线程不必阻塞可以去做一些其他的任务了。&lt;/p&gt;

&lt;p&gt;但是这里有几个问题，第一个就是调用者如何受到任务完成的通知？还有一个更重要的问题是当任务发生异常出现错误后，异常会被谁处理？异常将会被具体执行任务的工作线程所处理并不会关心是哪个调用者调用的任务：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/exception-prop.png&quot; alt=&quot;exception prop&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是一个很严重的问题，具体执行任务的线程是怎么处理这种状况的？具体执行任务去处理这个问题并不是一个好的方案，因为它并不清楚该任务执行的真正目的，而且调用者应该被通知发生了什么，但是实际上并没有这样的结构去解决这个问题。假如并不能正确的通知，调用者线程将不会的到任何错误的信息甚至任务都会丢失。这就好比在网络上你的请求失败或者消息丢失却得不到任何的通知。&lt;/p&gt;

&lt;p&gt;在某些情况，这个问题可能会变得更糟糕，工作线程发生了错误但是其自身却无法恢复。比如一个由bug引起的内部错误导致了线程的关闭，那么会导致一个问题，到底应该由谁来重启线程并且保存线程之前的状态呢？表面上看，这个问题是可以解决的，但又会有一个新的意外可能发生，当工作线程正在执行任务的时候，它便不能共享任务队列，而事实上，当一个异常发生后，并逐级上传，最终可能导致整个任务队列的状态全部丢失。所以说即使我们在本地交互也可能存在消息丢失的情况。&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;实现任何一个高并发且高效性能的系统，线程必须将任务有效率的委托给别的线程执行以至不会阻塞，这种任务委托的并发方式在分布式的环境也适用，但是需要引入错误处理和失败通知等机制。失败成为这种领域模型的一部分。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;并发系统适用任务委托机制需要去处理服务故障也就意味需要在发生故障后去恢复服务，但实际情况下，重启服务可能会丢失消息，即使没有发生这种情况，调用者得到的回应也可能因为队列等待，垃圾回收等影响而延迟，所以，在真正的环境中，我们需要设置请求回复的超时时间，就像在网络系统亦或者分布式系统。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;为什么在高并发，分布式系统需要Actor模型？&lt;/h2&gt;

&lt;p&gt;综上所述，通常的编程模型并不适用现代的高并发分布式系统，幸运的是，我们可以不必抛弃我们了解的知识，另外，Actor用很好的方式帮我们克服了这些问题，它让我们以一种更好的模型去实现我们的系统。&lt;/p&gt;

&lt;p&gt;我们重点需求的是以下几个方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用封装，但是不使用锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;构建一种实体能够处理消息，更改状态，发送消息用来推动整个程序运行。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;不必担心程序执行与真实环境的不匹配。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Actor模型能帮我们实现这些目标，以下是具体描述。&lt;/p&gt;

&lt;h3&gt;使用消息机制避免使用锁以防止阻塞&lt;/h3&gt;

&lt;p&gt;不同于方法调用，Actor模型使用消息进行交互。发送消息的方式不会将发送消息方的执行线程转换为具体的任务执行线程。Actor可以不断的发送和接收消息但不会阻塞。因此它可以做更多的工作，比如发送消息和接收消息。&lt;/p&gt;

&lt;p&gt;在面对对象编程上，直到一个方法返回后，才会释放对调用者线程的控制。在这这一方面上，Actor模型跟面对对象模型类似，它对消息做出处理，并在消息处理完成后返回执行。我们可以模拟这种执行模式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/actor-graph.png&quot; alt=&quot;actor graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是这种方式与方法调用方式最大的区别就是没有返回值。通过发送消息，Actor将任务委托给另一Actor执行。就想我们之前说的堆栈调用一样，加入你需要一个返回值，那么发送Actor需要阻塞或者与具体执行任务的Actor在同一个线程中。另外，接收Actor以消息的方式返回结果。&lt;/p&gt;

&lt;p&gt;第二个关键的变化是继续保持封装。Actor对消息处理就就跟调用方法一样，但是不同的是，Actor在多线程的情况下能保证自身内部的状态和变量不会被破坏，Actor的执行独立于发送消息的Actor，并且同一个Actor在同一个时刻只处理一个消息。每个Actor有序的处理接收的消息，所以一个Actor系统中多个Actor可以并发的处理自己的消息，充分的利用多核CPU。因为一个Actor同一时刻最多处理一个消息，所以它不需要同步机制保障变量的一致性。所以说它并不需要锁：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/serialized-timeline-invariants.png&quot; alt=&quot;serialized timeline invariants&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总而言之，Actor执行的时候会发生以下行为：&lt;/p&gt;

&lt;p&gt;1.Actor将消息加入到消息队列的尾部。
2.假如一个Actor并未被调度执行，则将其标记为可执行。
3.一个（对外部不可见）调度器对Actor的执行进行调度。
4.Actor从消息队列头部选择一个消息进行处理。
5.Actor在处理过程中修改自身的状态，并发送消息给其他的Actor。
6.Actor&lt;/p&gt;

&lt;p&gt;为了实现这些行为，Actor必须有以下特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;邮箱（作为一个消息队列）&lt;/li&gt;
&lt;li&gt;行为（作为Actor的内部状态，处理消息逻辑）&lt;/li&gt;
&lt;li&gt;消息（请求Actor的数据，可看成方法调用时的参数数据）&lt;/li&gt;
&lt;li&gt;执行环境（比如线程池，调度器，消息分发机制等）&lt;/li&gt;
&lt;li&gt;位置信息（用于后续可能会发生的行为）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;消息会被添加到Actor的信箱中，Actor的行为可以看成Actor是如何对消息做出回应的（比如发送更多消息或者修改自身状态）。执行环境提供一组线程池，用于执行Actor的这些行为操作。&lt;/p&gt;

&lt;p&gt;Actor是一个非常简单的模型而且它可以解决先前提到的问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;继续使用封装，但通过信号机制保障不需传递执行（方法调用需要传递执行线程，但发送消息不需要）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;不需要任何的锁，修改Actor内部的状态只能通过消息，Actor是串行处理消息，可以保障内部状态和变量的正确性。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;因为不会再任何地方使用锁，所以发送者不会被阻塞，成千上万个Actor可以被合理的分配在几十个线程上执行，充分利用了现代CPU的潜力。任务委托这个模式在Actor上非常适用。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Actor的状态是本地的，不可共享的，变化和数据只能通过消息传递。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Actor优雅的处理错误&lt;/h3&gt;

&lt;p&gt;Actor不再使用共享的堆栈调用，所以它要以不同的方式去处理错误。这里有两种错误需要考虑：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;第一种情况是当任务委托后再目标Actor上由于任务本身错误而失败了（典型的如验证错误，比如不存在的用户ID）。在这个情况下，Actor服务本身是正确的，只是相应的任务出错了。服务Actor应该想发送Actor发送消息，已告知错误情况。这里没什么特殊的，错误作为Actor模型的一部分，也可以当做消息。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;第二种情况是当服务本身遇到内部故障时。Akka强制所有Actor被组织成一个树状的层次结构，即创建另一个Actor的Actor成为该新Actor的分级。 这与操作系统将流程组合到树中非常相似。就像进程一样，当一个Actor失败时，它的父actor被通知，并对失败做出反应。此外，如果父actor停止，其所有子Actor也被递归停止。这中形式被称为监督，它是Akka的核心：&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/actor-tree-supervision.png&quot; alt=&quot;actor tree supervision&quot; /&gt;&lt;/p&gt;

&lt;p&gt;监管者可以根据被监管者（子Actor）的失败的错误类型来执行不同的策略，比如重启该Actor或者停止该Actor让其它Actor代替执行任务。一个Actor不会无缘无故的死亡（除非出现死循环之类的情况），而是失败，并可以将失败传递给它的监管者让其做出相应的故障处理策略，当然也可能会被停止（若被停止，也会接收到相应的消息指令）。一个Actor总有监管者就是它的父级Actor。Actor重新启动是不可见的，协作Actor可以帮其代发消息直到目标Actor重启成功。&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
