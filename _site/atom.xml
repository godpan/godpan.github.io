<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>泮</title>
 <link href="/atom.xml" rel="self"/>
 <link href=""/>
 <updated>2017-10-22T20:38:37+08:00</updated>
 <id>/</id>
 <author>
   <name></name>
 </author>

 
 <entry>
   <title>Java IO初探</title>
   <link href="/2017/10/21/java-io.html"/>
   <updated>2017-10-21T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;Java IO对大多数Java程序员来说是熟悉又陌生，熟悉的是感觉到处都有它的身影，小到简单的读取文件，大到各种服务器的应用，陌生的是Java IO背后到底是一个怎样的机制，今天就让我们去了解一下这位老朋友吧。本文不讲解Java IO如何具体使用，有这方面需求的同学可以自己查下。&lt;/p&gt;

&lt;h3&gt;IO模型&lt;/h3&gt;

&lt;p&gt;要说IO，就不得不说IO模型，IO模型大家都有所了解，同步异步，阻塞非阻塞什么的，总的来说IO模型可分为以下五种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;阻塞IO&lt;/li&gt;
&lt;li&gt;非阻塞IO&lt;/li&gt;
&lt;li&gt;多路复用IO&lt;/li&gt;
&lt;li&gt;信号驱动IO&lt;/li&gt;
&lt;li&gt;异步IO&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;那么这几种IO都有什么区别呢？下面我们一一来看，每种模型我都会举一个适当的例子助于理解：&lt;/p&gt;

&lt;h4&gt;1.阻塞IO&lt;/h4&gt;

&lt;p&gt;阻塞IO相信大家都最熟悉了，线程发起一个IO请求，直到有结果返回，否则则一直阻塞等待，比如我们平常常见的阻塞数据库操作，网络IO等。&lt;/p&gt;

&lt;p&gt;小明阻塞IO吃饭：&lt;/p&gt;

&lt;p&gt;五年前一天周末，小明和朋友一起去商场的外婆家吃饭，到店后发现排队的人超多，所以他就领了一个号码，然后他和朋友就坐在旁边等候，一直等着服务员叫他们的号，也不能做其他事，过了一个多小时终于轮到他们了，然后他们进店点菜，又得等待上菜，最后他们吃饭总共花了两个小时；&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;等待座位吃饭：一直阻塞，直到有座位&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;没什么说的，反正就是一直等，反应到程序中就是一直阻塞，而一个IO请求需要一个线程，可想而知当有大量的IO请求，线程的创建和销毁，线程间的切换，线程所占用的资源等等要耗费多少时间和资源，系统的性能会有多差。&lt;/p&gt;

&lt;h4&gt;2.非阻塞IO&lt;/h4&gt;

&lt;p&gt;非阻塞IO和阻塞IO的最大区别就在于线程发起一个IO请求,不会一直堵塞直到有数据，而是不断的检查是否已有数据，若有数据则读取数据。&lt;/p&gt;

&lt;p&gt;小明非阻塞IO吃饭：&lt;/p&gt;

&lt;p&gt;有了第一次的教训，小明学乖了，他在拿到后不再傻傻的等着，而是去外婆家旁边逛了逛，每过3分钟他就会回来，然后跑到前台去询问服务员轮到他了吗？不幸的是，排队的人超多，直到过了半个多小时后才轮到他进店吃饭，期间他大概问了十几次，他们进店点菜，又得等待上菜，最后他们吃饭总共花了两个小时，基本也没做啥其他事；&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后询问是否轮到他：非阻塞，非询问期间可以做点别的事,但也不做了啥大事&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说非阻塞IO的非阻塞主要体现在不需要一直等待到有数据，当然读数据那部分操作还是阻塞的，另外这种非阻塞模式需要用户线程自己不断询问检查，其实效率也不是太高，实际编程中运用的也不多。&lt;/p&gt;

&lt;h4&gt;3.多路复用IO&lt;/h4&gt;

&lt;p&gt;既然上面我们说到非阻塞IO的缺点，那么有没有什么方式改进呢？答案是当然有，那就是多路复用IO，我理解的它的特点就是复用，首先它也是一种非阻塞IO的模型，只不过上面说到轮询的方式用了不同的方式处理了，当一个线程发起IO请求，系统会将它注册到一个单独管理IO请求的一个线程，之后该IO的相关操作的通知状态都有这个管理IO请求的线程处理，Java 1.4发布的NIO就是这种模式，我们可以大致来看一下它的流程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;// 打开服务器套接字通道
ServerSocketChannel ssc = ServerSocketChannel.open();
// 服务器配置为非阻塞
ssc.configureBlocking(false);
// 进行服务的绑定
ssc.bind(new InetSocketAddress(&quot;localhost&quot;, 8008));
// 这里的selector就相当于单独管理IO请求的线程
Selector selector = Selector.open();
// 注册到selector，等待连接
ssc.register(selector, SelectionKey.OP_ACCEPT);

while (true) {
    selector.select();  //为IO请求去轮询状态
    Set&amp;lt;SelectionKey&amp;gt; keys = selector.selectedKeys(); //多个IO请求的状态
    Iterator&amp;lt;SelectionKey&amp;gt; keyIterator = keys.iterator();
    while (keyIterator.hasNext()) { //依次处理IO请求
        SelectionKey key = keyIterator.next();
        doThing(key)
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出Java NIO的模式就是多路复用IO模型的应用。&lt;/p&gt;

&lt;p&gt;小明多路复用IO吃饭：&lt;/p&gt;

&lt;p&gt;随着生意越来越好，外婆家发现好多顾客都堵在门口等待吃饭，等待区都站不下来人了，，思来想去，外婆家准备请一个人专门来维护顾客的排队请求，这样顾客取号后，就不用堵在门口了，我们叫他小A，小明这次取号后，将自己的相关信息告诉小A，并从小A那里获得了一个GPS（用于小A能快速找到小明，假设有了GPS后，小A能秒速找到小明），然后小明就跟朋友们开心的去逛商场，看看MM，买买衣服，而小A则不断的观察店里的情况，当有空座位出现的时候，他便会按照相关信息找到具体的顾客，将其带回进行用餐，但他们进店点菜，还得等待上菜，最后他们吃饭总共花了两个小时，但是他们不再需要排队等位，而是去做一些其他的事。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后委托给小A，小A观察到有空位后带回小明：非阻塞，领号后可以安心去做自己的事，不用担心错过&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;多路复用IO可以看成普通非阻塞IO的升级版，也是目前Java编程中用到比较多的IO模型，它的优势在于可以处理大量的IO请求，用一个线程管理所有的IO请求，无需像阻塞IO和非阻塞IO一样，每个IO需要一个线程处理，提升了系统的吞吐量。&lt;/p&gt;

&lt;h4&gt;4.信号驱动IO&lt;/h4&gt;

&lt;p&gt;信号驱动IO相对于以上几种模型最大的特点就是它支持内核信号通知，线程在发起一个IO请求后，会注册一个信号函数，然后内核在确认数据可读了，便会给相应的线程发送通知，让其进行具体IO读写操作。&lt;/p&gt;

&lt;p&gt;小明信号驱动IO吃饭：&lt;/p&gt;

&lt;p&gt;又了一段时间，外婆家通过使用复用IO模式缓解了排队拥挤的情况，但是觉得还要请一个人专门维护队列，感觉不划算，那么有没有一种更好的方式呢？经过一天的苦思冥想，外婆家的经理又想出一个好办法，让每个顾客在领完号后，关注一下外婆家的公众号，然后顾客就可以去做别的事了，定时或者当排队信息发生改变时给顾客发送通知，告知他现在的排队序号或者轮到他吃饭了，顾客可以根据相应的信息做相应的行为，比如快轮到了就开始往店里走（实际程序中并不一定有这种状态，这里只是大概模拟），或者进店吃饭，他们仍然不用排队等位，而是去做一些其他的事。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后关注公众号，注册关系：非阻塞，领号后可以安心去做自己的事，不用担心错过&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;就实际来说，信号驱动IO用的并不多，因为信号驱动IO底层是使用SIGIO信号，所以它主要使用在UDP协议上，因为UDP产生SIGIO信号的时候只有两种可能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.要么数据到达&lt;/li&gt;
&lt;li&gt;2.发生错误&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;但相对TCP来说，产生SIGIO信号的地方太多了，比如请求连接，确认，断开，错误等等，所以我们很难根据SIGIO信号判断到底发生了什么。&lt;/p&gt;

&lt;h4&gt;5.异步IO&lt;/h4&gt;

&lt;p&gt;以上四种IO其实都还是同步IO，因为它们在读写数据时都是阻塞的，异步IO相较于它们最大的特点是它读写数据的时候也是非阻塞的，用户线程在发起一个IO请求的时候，除了给内核线程传递具体的IO请求外，还会给其传递数据缓冲区，回调函数通知等内容，然后用户线程就继续执行，等到内核线程发起相应通知的时候，说明数据已经准备就绪，用户线程直接使用即可，无需再阻塞从内核拷贝数据到用户线程。&lt;/p&gt;

&lt;p&gt;小明异步IO吃饭：&lt;/p&gt;

&lt;p&gt;有过了一段时间，小明又想吃外婆家了，但是这个周末他并不想出门，他突然在网上看到新闻说外婆家竟然可以叫外婆，小明高兴坏了，他马上打电话给外婆家，告诉它自己想要吃哪些菜（相当于IO请求所需要的数据），然后将自己的联系号码（相当于回调通知）和住址（相当于数据缓冲区）也告诉它，然后就挂掉电话，开心的做去打游戏了，过了半个小时后，手机响起，告知外卖已经到了，小明开门取外卖就可以直接开吃了。整个过程小明直到吃饭都没有等待阻塞。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;叫外卖并提供相应的信息：非阻塞，打完电话后做自己的事&lt;/li&gt;
&lt;li&gt;通知外卖到了：直接开门取外卖直接开吃，非阻塞&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;我们可以看出，异步IO才是真正的异步，因为它连数据拷贝这个过程都是非阻塞的，用户线程根本不用关心数据的读写等操作，只需等待内核线程通知后，直接处理数据即可，当然异步IO需要系统内核支持，比如Linux中的AIO和Windows中的IOCP，但是也可以通过多线程跟阻塞I/O模拟异步IO，比如可以在多路复用IO模型上进行相应的改变，另外也有现有的实现，比如异步I/O的库：libeio&lt;/p&gt;

&lt;p&gt;最后用一张图总体概括一下Java IO（图片来自美团技术博客）：&lt;/p&gt;

&lt;p&gt;Java IO概图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/10/java-io.jpg&quot; alt=&quot;java-io&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;多路复用IO在Linux中的实现&lt;/h3&gt;

&lt;p&gt;因为后续会讲到Java NIO，所以我们需要了解操作系统是如何支持多路复用IO的，Linux中支持支持三种多路IO复用机制，分别是select、poll和epoll，本来这里我想自己写的，但查阅了相应的一些资料后，发现自己的水平还是不够，这里我不准备班门弄斧了，因为我找到了很多写的比较好的文章，这里就给大家列一下，仅供参考：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/tennysonsky/article/details/45745887&quot;&gt;Linux系统编程——I/O多路复用select、poll、epoll的区别使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.jianshu.com/p/dfd940e7fca2&quot;&gt;聊聊IO多路复用之select、poll、epoll详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/32163005&quot;&gt;IO 多路复用是什么意思？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;这篇文章主要讲了最基础的IO模型，不过我认为最基础的往往是最重要的，只有理解了基础的原理，才能对基于它们实现的类库或者工具有更加深刻的认识，下一篇文章将会主要讲一下基于多路复用IO的Java NIO，敬请期待。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MySQL几个简单SQL的优化</title>
   <link href="/2017/10/13/mysql-sql-optimize.html"/>
   <updated>2017-10-13T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;最近在做项目的时候，遇到了一些大数据量的操作，有大批量的CRUD的操作，一开始的实现的方案经过性能测试，发现性能并不是很好，然后开始审查代码，对相关可以提升性能的操作进行了优化，这里分享给大家。&lt;/p&gt;

&lt;h3&gt;原则&lt;/h3&gt;

&lt;p&gt;首先我这里不讲索引相关的内容以及数据库相应参数的优化，这里假设你对索引已经有了相关的了解了，我总结了下我这次的优化，主要两个原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一些特定的场景，尽量用批处理处理数据，比如批量添加数据，批量修改数据；&lt;/li&gt;
&lt;li&gt;结合业务尽量减少SQL的执行次数和查询不必要的数据；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;场景实践&lt;/h3&gt;

&lt;p&gt;为模拟运行场景，我这里建了一个表，并往里面添加了300w条数据，表结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;CREATE TABLE `tb_big_data` (
 `id` int(11) NOT NULL AUTO_INCREMENT,
 `weixin_id` varchar(64) NOT NULL,
 `openid` varchar(64) NOT NULL,
 `status` int(3) NOT NULL,
 `gmt_create` datetime NOT NULL,
 `gmt_modified` datetime NOT NULL,
 PRIMARY KEY (`id`),
 KEY `weixin_id_gmt_create_openid` (`weixin_id`,`gmt_create`,`openid`)
) ENGINE=InnoDB AUTO_INCREMENT DEFAULT CHARSET=utf8
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;1.分页查询小优化&lt;/h4&gt;

&lt;p&gt;分页查询老生常谈，网上各种优化方法都很多，这里就不提及了，这里只是分享一个小技巧：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何在使用最普通的limit的时候提高性能？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;假设我们现在有一条这样的SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` where weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-10 00:00:00' order by id asc limit 800000, 100;

执行时间：100 rows in set (1.53 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假如我们现在不能进行其他优化，比如传入最小id，分表查询等策略，以及不进行SQL预热，怎么提高这条SQL的速度呢？
其实很简单我们只需要一个in操作即可：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` t1 where t1.id in ( 
    SELECT tt.id FROM ( 
        SELECT id FROM `tb_big_data` t2 where weixin_id = 'gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-10 00:00:00' order by t2.id asc limit 800100, 100
        ) as tt);

执行时间：100 rows in set (1.17 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出只需稍加修改，SQL的效率可以提高30%~40%，而且在单条数据记录越大的情况下效果越好，当然这不是最好的分页方法，这只是一个小技巧；&lt;/p&gt;

&lt;h4&gt;2.减少SQL查询&lt;/h4&gt;

&lt;p&gt;现在有一个需求我们现在有一个用户的列表（用户的唯一标识为openid）然后我们需要判断用户在当天是否有过相应的记录；&lt;/p&gt;

&lt;p&gt;这是问题其实很简单，我们首先一想到的操作就是循环这个列表一个一个判断，很简单也很好实现，但是真正测试的时候发现性能却很差，尤其在数据量大的情况下，倍数级增长，这里有有网络数据传输消耗的时间和SQL本身的执行时间；&lt;/p&gt;

&lt;p&gt;假设我们现在执行一条以下的SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid='2n6bvynihm5bzgyx';

执行时间：1 row in set (0.95 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在如果我们执行100次，不敢想象会是什么情况，庆幸自己发现了这个问题，因为在数据量少的情况下，这个问题表现的并不是那么严重，其实我们稍加改变就能以另一种高效的方式解决这个问题：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid in ('2n6bvynihm5bzgyx','1stbvdnl63de2q37','3z8552gxzfi3wy27'...);

执行时间：100 row in set (1.05 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现了没有，还是用in，而且执行时间几乎与单条查询的时间一样，可见只是单一这一部分处理就可以提升了很大的性能。&lt;/p&gt;

&lt;h4&gt;3.特定场景使用SQL的批处理&lt;/h4&gt;

&lt;p&gt;这个跟上一点有一个相似点，那就是减少SQL执行，上面只是查询而已，而当出现大批量的CUD的操作时，执行每条SQL，数据库都会进行事务处理，这将会消耗大量的时间，而且极端情况下会引起大批量SQL等待无法执行，导致业务出错，正是因为这些原因，我们在一些适当的情况下可以使用批处理来解决这个问题。&lt;/p&gt;

&lt;h5&gt;（1）批量插入&lt;/h5&gt;

&lt;p&gt;批量插入比较简单，也比较常用，这里就给一下基本语法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;INSERT INTO table_name (field1,filed2,...) values (value11,value12,...),(value21,value22,...),...
&lt;/code&gt;&lt;/pre&gt;

&lt;h5&gt;（2）批量更新&lt;/h5&gt;

&lt;p&gt;我先举个简单的例子，我们现在来根据一些条件来更新数据，具体SQL如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;update `tb_big_data` set status = 2 WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid = '2n6bvynihm5bzgyx';

Query OK, 1 row affected (2.28 sec)
Rows matched: 1  Changed: 1  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很惊讶，我们只是更新了一条记录，而且更新条件上是有复合索引的，没想到速度还那么慢，可以想象如果我们批量更新数据，那得耗时多少；&lt;/p&gt;

&lt;p&gt;但是我们看一下另一条SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;update `tb_big_data` set status = 1 WHERE id = 900098;

Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的id值为之前条件筛选出来的记录的id，是不是很惊讶，怎么这条SQL执行的时间几乎不需要什么时间，所以我们可以利用这个特点和批量查询简化批量更新，虽然这种方式不能让性能到最优，但是也能提升很大了，我进行了一个测试，根据相应条件批量更新100条数据：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方式&lt;/th&gt;
&lt;th&gt;直接批量更新&lt;/th&gt;
&lt;th&gt;先批量查主键再批量更新&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;耗时 &lt;/td&gt;
&lt;td&gt; 289.12s &lt;/td&gt;
&lt;td&gt; 1.342s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;可以看出这种方式相对对于普通方式来说，性能提升巨大，具体执行的时候我们也可以将这些SQL放在一个事务提交，减少数据库事务次数，但只这是一种在代码层面上的优化；&lt;/p&gt;

&lt;p&gt;另外我们可以利用MySQL提供的特殊语法进行批量更新，具体语法为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;#语法
INSERT INTO table_name (id,field1,field2,...) VALUES  (id1,value11,value12,...),(id1,value11,value12,...),... on duplicate key update  field = VAULES(field);

#使用例子

INSERT INTO `tb_big_data` (id,weixin_id,openid,gmt_create,status) values  (1,'gh_266a30a8a1f6','w9q8fmodytjgppsr','2017-10-13 12:00:00',3),(2,'gh_266a30a8a1f6','bu1flmch4i8eegzf','2017-10-13 12:00:00',3) on duplicate key update status = VAULES(status);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过测试这种方式在数据量小的情况下与上述方式效率差不多，但是随着数据量越来越大，性能也越来越好，缺点的话主要传输的数据量很大，不需要更新的字段也需要传输。&lt;/p&gt;

&lt;p&gt;另外也不推荐大量数据的批量更新，一次不要超过1000条为好。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;总的来说，SQL优化是一门细心的学问，需要不断去尝试，测试，找到最优方式，另外还有一点就是要结合实际情况，综合考虑选择合适的方式。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Asyncdb（一）：写一个纯函数式的Mysql异步驱动</title>
   <link href="/2017/10/04/mysql-driver-info.html"/>
   <updated>2017-10-04T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;之前的Akka系列博客接下去可能并不会经常更新了，但是后续看到一些好的点或者大家对哪些还是比较感兴趣还会继续写几篇，这里先跟大家说明一下。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;写一个纯函数式的Mysql异步驱动&lt;/strong&gt;这个构思是公司的一个大佬提的，这将会是一个开源项目，我也很有幸能够参与其中，尝试写一个自己真正意义上的开源项目，其实很多人会有疑惑，为什么我们要做一个数据库驱动，就目前JVM生态上，已经有了比较成熟的产品，我们还能做出一个怎样的数据库驱动呢？&lt;/p&gt;

&lt;p&gt;首先我们明确了一点，绝不做重复造轮子的事，做这个项目一定要有意义，即使未来可能实用性兼容性等方面不是很擅长，我们也要表达出新的设计理念，能给数据库驱动注入一股新的活力。&lt;/p&gt;

&lt;p&gt;我们在确定这个项目的时候，也对目前JVM生态中的数据库驱动进行了一定的总结，仅供参考：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;项目&lt;/th&gt;
&lt;th&gt;mysql-async&lt;/th&gt;
&lt;th&gt;HikariCP + mysql-connector/j&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;编程模型 &lt;/td&gt;
&lt;td&gt; 异步 &lt;/td&gt;
&lt;td&gt; 同步&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;网络IO &lt;/td&gt;
&lt;td&gt; NIO &lt;/td&gt;
&lt;td&gt; BIO&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;链接池 &lt;/td&gt;
&lt;td&gt; 异步实现 &lt;/td&gt;
&lt;td&gt; 同步实现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;过载防护 &lt;/td&gt;
&lt;td&gt; 通过调节队列长度实现 &lt;/td&gt;
&lt;td&gt; 需要额外实现 （例如指定线程池任务队列长度）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;可伸缩性 &lt;/td&gt;
&lt;td&gt; 只需要设置合理连接数(例如几十个) &lt;/td&gt;
&lt;td&gt; 需要测试最佳线程数和链接数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;线程数 &lt;/td&gt;
&lt;td&gt; 少 &lt;/td&gt;
&lt;td&gt; 多&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;具体相关测试及说明可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/04/mysql-async-1/&quot;&gt;MySQL 异步驱动浅析 （一）：性能分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;相信写过Java工程的同学都应该知道mysql-connector-java，但应该很多人对其的实现和相关架构设计应该不是很了解，正如我们上面对其相关功能测试，发现它的某些方面表现并不是很好，比如使用了BIO，请求时需要大量的线程等等。&lt;/p&gt;

&lt;p&gt;相信你们也注意到了mysql-async，但是应该大多数人都不是很熟悉，它也是一个基于Netty，使用Scala编写的，完全异步的数据库驱动，同时支持PostgreSQL和MySQL，其项目地址&lt;a href=&quot;https://github.com/mauricio/postgresql-async&quot;&gt;postgresql-async&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;其实我们公司项目底层用的数据库驱动也是基于mysql-async的，不过因为实际使用中遇到了一些问题，，具体相关问题分析可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/05/mysql-async-2/&quot;&gt;MySQL 异步驱动浅析 （二）：缺点分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;虽然我们使用的mysql-async内部版本对上述的许多问题都进行了修复，具体信息可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/07/mysql-async-3/&quot;&gt;MySQL 异步驱动浅析 （三）：连接池改进方案&lt;/a&gt;，但是整个项目变得混乱，架构设计也不是很完美，所以我们最终决定自己实现一个纯函数式的Mysql异步驱动，我们叫它：&lt;strong&gt;asyncdb&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;目标&lt;/h3&gt;

&lt;p&gt;那么我们到底要做一个怎样的驱动呢？我们提了以下几个主要方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.构建于cats-effect(纯函数式的关键)&lt;/li&gt;
&lt;li&gt;2.合理的数据库包解析框架&lt;/li&gt;
&lt;li&gt;3.支持简单的流处理(可选)&lt;/li&gt;
&lt;li&gt;4.基于Java NIO2，绝不阻塞&lt;/li&gt;
&lt;li&gt;5.提供对应Java8的接口&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说，除了第一点大家可能比较陌生，其他几点大家都应该能大致了解,但是第一点才是我们这个项目最重要的一点，也是用来解决我们之前遇到问题的关键，后续我会写几篇文章对于这一点进行的相关介绍，如果有兴趣的同学可以自己了解一下：&lt;a href=&quot;https://github.com/typelevel/cats-effect&quot;&gt;cats-effect&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;关注 Asyncdb&lt;/h3&gt;

&lt;p&gt;如果你对我们的项目也有兴趣，欢迎你们star我们的项目，项目地址:&lt;a href=&quot;https://github.com/asyncdb/asyncdb&quot;&gt;asyncdb&lt;/a&gt;,我们将会从头开始，你可以一步一步了解我们的架构设计和具体的实现方法，当然你有好的想法或者相关问题，也欢迎给我们提issue。&lt;/p&gt;

&lt;h3&gt;进阶学习&lt;/h3&gt;

&lt;p&gt;若是你对数据库驱动非常有兴趣，也想探究里面的奥秘，这里我提一些相应的建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.熟悉了解Java NIO，并熟练使用它&lt;/li&gt;
&lt;li&gt;2.学习MySQL数据库网络传输包协议&lt;/li&gt;
&lt;li&gt;3.掌握函数式语言中的Monad表达式，理解其的含义和使用场景&lt;/li&gt;
&lt;li&gt;4.学习Scala相关的函数库比如：&lt;a href=&quot;https://github.com/typelevel/cats&quot;&gt;cats&lt;/a&gt;,&lt;a href=&quot;https://github.com/milessabin/shapeless&quot;&gt;shapeless&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.学习IO-Monad(cats-effect)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;最后也希望大家能参与其中，帮助我们不断的完善它，共同成长！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（十）：Akka集群之Akka Cluster</title>
   <link href="/2017/09/05/learning-akka-10.html"/>
   <updated>2017-09-05T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;上一篇文章我们讲了Akka Remote，理解了Akka中的远程通信，其实Akka Cluster可以看成Akka Remote的扩展，由原来的两点变成由多点组成的通信网络，这种模式相信大家都很了解，就是集群，它的优势主要有两点：系统伸缩性高，容错性更好。&lt;/p&gt;

&lt;h3&gt;集群概念&lt;/h3&gt;

&lt;p&gt;很多人很容易把分布式和集群的概念搞错，包括我也是，我一开始也以为它们两个是一样的概念，只是叫法不同而已，但其实不然，虽然它们在实际场景中都是部署在不同的机器上，但它们所提供的功能并不是一样的。举个简单的例子来看看它们之间的不同：&lt;/p&gt;

&lt;p&gt;为了保持整个系列连续性，我又以抽奖为基础举一个例子：&lt;/p&gt;

&lt;p&gt;假定我们现在抽奖流程包括，抽奖分配奖品和用户根据链接领取指定奖品，用户先抽奖然后获取奖品链接，点击链接填写相应信息领取奖品。&lt;/p&gt;

&lt;h4&gt;1.分布式：&lt;/h4&gt;

&lt;p&gt;我们现在把抽奖分配奖品和用户根据链接领取指定奖品分别部署在两台机器上，突然有一天很不幸，抽奖活动进行到一半，抽奖分配奖品那台机子所在的区域停电了，很显然，后续的用户参与抽奖就不能进行了，因为我们只有一台抽奖分配奖品的机子，但由于我们将领取奖品的业务部署在另一台机器上，所以前面那些中奖的用户还是可以正常的领取奖品，具体相关定义可参考《分布式系统概念与设计》中对分布式系统的定义。&lt;/p&gt;

&lt;h4&gt;2.集群：&lt;/h4&gt;

&lt;p&gt;现在我们还是有两台机器，但是我们在两个机器上都部署了抽奖分配奖品和用户根据链接领取指定奖品的业务逻辑，突然有一天，有一台所在的区域停电了，但这时我们并担心，因为另一台服务器还是可以正常的运行处理用户的所有请求。&lt;/p&gt;

&lt;p&gt;它们的各自特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分布式：是指在多台不同的服务器中部署不同的服务模块，通过远程调用协同工作，对外提供服务；&lt;/li&gt;
&lt;li&gt;集群：是指在多台不同的服务器中部署相同应用或服务模块，构成一个集群，通过负载均衡设备对外提供服务；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说： 分布式是以分离任务缩短时间来提高效率，而集群是在单位时间内处理更多的任务来提高效率。&lt;/p&gt;

&lt;h3&gt;Akka Cluster&lt;/h3&gt;

&lt;p&gt;在前面的文章Akka Actor的工作方式，我们可以将一个任务分解成一个个小任务，然后分配给它的子Actor执行，其实这就可以看成一个小的分布式系统，那么在Akka中，集群又是一种怎样的概念呢？&lt;/p&gt;

&lt;p&gt;其实往简单里说，就是一些相同的ActorSystem的组合，它们具有着相同的功能，我们需要执行的任务可以随机的分配到目前可用的ActorSystem上，这点跟Nginx的负载均衡很类似，根据算法和配置将请求转发给运行正常的服务器去，Akka集群的表现形式也是这样，当然它背后的理论基础是基于gossip协议的，目前很多分布式的数据库的数据同步都采用这个协议，有兴趣的同学可以自己去研究研究，只是我也是一知半解，这里就不写了，怕误导了大家。&lt;/p&gt;

&lt;p&gt;下面我来讲讲Akka Cluster中比较重要的几个概念：&lt;/p&gt;

&lt;h4&gt;Seed Nodes&lt;/h4&gt;

&lt;p&gt;Seed Nodes可以看过是种子节点或者原始节点，它的一个主要作用用于可以自动接收新加入集群的节点的信息，并与之通信，使用方式可以用配置文件或者运行时指定，推荐使用配置文件方式，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.seed-nodes = [
  &quot;akka.tcp://ClusterSystem@host1:2552&quot;,
  &quot;akka.tcp://ClusterSystem@host2:2552&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;seed-nodes列表中的第一个节点会集群启动的时候初始化，而其他节点则是在有需要时再初始化。&lt;/p&gt;

&lt;p&gt;当然你也可以不指定seed nodes，但你可以需要手动或者在程序中写相关逻辑让相应的节点加入集群，具体使用方式可参考官方文档。&lt;/p&gt;

&lt;h4&gt;Cluster Events&lt;/h4&gt;

&lt;p&gt;Cluster Events字面意思是集群事件，那么这是什么意思呢？其实它代表着是一个节点的各种状态和操作，举个例子，假设你在打一局王者5v5的游戏，那么你可以把十个人看成一个集群，我们每个人都是一个节点，我们的任何操作和状态都能被整个系统捕获到，比如A杀了B、A超神了，A离开了游戏，A重新连接了游戏等等，这些状态和操作在Cluster Events中就相当于节点之于集群，那么它具体是怎么使用的呢？&lt;/p&gt;

&lt;p&gt;首先我们必须将节点注册到集群中，或者说节点订阅了某个集群，我们可以这么做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;cluster.subscribe(self, classOf[MemberEvent], classOf[UnreachableMember])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体代码相关的使用我会再下面写一个demo例子，来说明是如何具体使用它们的。&lt;/p&gt;

&lt;p&gt;从上面的代码我们可以看到有一个MemberEvent的概念，这个其实就是每个成员所可能拥有的events，那么一个成员在它的生命周期中有以下的events&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ClusterEvent.MemberJoined - 新的节点加入集群，此时的状态是Joining；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberUp - 新的节点加入集群，此时的状态是Up；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberExited - 节点正在离开集群，此时的状态是Exiting；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberRemoved - 节点已经离开集群，此时的状态是Removed；&lt;/li&gt;
&lt;li&gt;ClusterEvent.UnreachableMember - 节点被标记为不可触达；&lt;/li&gt;
&lt;li&gt;ClusterEvent.ReachableMember - 节点被标记为可触达；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;状态说明：
- Joining: 加入集群的瞬间状态
- Up: 正常服务状态
- Leaving / Exiting: 正常移出中状态
- Down: 被标记为停机（不再是集群决策的一部分）
- Removed: 已从集群中移除&lt;/p&gt;

&lt;h4&gt;Roles&lt;/h4&gt;

&lt;p&gt;虽然上面说到集群中的各个节点的功能是一样的，其实并不一定，比如我们将分布式和集群融合到一起，集群中的一部分节点负责接收请求，一部分用于计算，一部分用于数据存储等等，所以Akka Cluster提供了一种Roles的概念，用来表示该节点的功能特性，我们可以在配置文件中指定,比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.roles = request
akka.cluster.roles = compute
akka.cluster.roles = store
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;ClusterClient&lt;/h4&gt;

&lt;p&gt;ClusterClient是一个集群客户端，主要用于集群外部系统与集群通信，使用它非常方便，我们只需要将集群中的任意指定一个节点作为集群客户端，然后将其注册为一个该集群的接待员，最后我们就可以在外部系统直接与之通信了，使用ClusterClient需要做相应的配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.extensions = [&quot;akka.cluster.client.ClusterClientReceptionist&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假设我们现在我一个接待的Actor，叫做frontend,我们就可以这样做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sacla&quot;&gt;val frontend = system.actorOf(Props[TransformationFrontend], name = &quot;frontend&quot;)
ClusterClientReceptionist(system).registerService(frontend)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Akka Cluster例子&lt;/h3&gt;

&lt;p&gt;上面讲了集群概念和Akka Cluster中相对重要的概念，下面我们就来写一个Akka Cluster的demo，&lt;/p&gt;

&lt;p&gt;demo需求：&lt;/p&gt;

&lt;p&gt;线假设需要执行一些相同任务，频率为2s一个，现在我们需要将这些任务分配给Akka集群中的不同节点去执行，这里使用ClusterClient作为集群与外部的通信接口。&lt;/p&gt;

&lt;p&gt;首先我们先来定义一些命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
package sample.cluster.transformation

final case class TransformationJob(text: String) // 任务内容
final case class TransformationResult(text: String) // 执行任务结果
final case class JobFailed(reason: String, job: TransformationJob) //任务失败相应原因
case object BackendRegistration // 后台具体执行任务节点注册事件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们实现具体执行任务逻辑的后台节点：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationBackend extends Actor {

  val cluster = Cluster(context.system)

  override def preStart(): Unit = cluster.subscribe(self, classOf[MemberEvent])  //在启动Actor时将该节点订阅到集群中
  override def postStop(): Unit = cluster.unsubscribe(self)

  def receive = {
    case TransformationJob(text) =&amp;gt; { // 接收任务请求
      val result = text.toUpperCase // 任务执行得到结果（将字符串转换为大写）
      sender() ! TransformationResult(text.toUpperCase) // 向发送者返回结果
    }
    case state: CurrentClusterState =&amp;gt;
      state.members.filter(_.status == MemberStatus.Up) foreach register // 根据节点状态向集群客户端注册
    case MemberUp(m) =&amp;gt; register(m)  // 将刚处于Up状态的节点向集群客户端注册
  }

  def register(member: Member): Unit = {   //将节点注册到集群客户端
    context.actorSelection(RootActorPath(member.address) / &quot;user&quot; / &quot;frontend&quot;) !
      BackendRegistration
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;相应节点的配置文件信息，我这里就不贴了，请从相应的源码demo里获取。&lt;/em&gt;&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;接着我们来实现集群客户端：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationFrontend extends Actor {

  var backends = IndexedSeq.empty[ActorRef] //任务后台节点列表
  var jobCounter = 0

  def receive = {
    case job: TransformationJob if backends.isEmpty =&amp;gt;  //目前暂无执行任务节点可用
      sender() ! JobFailed(&quot;Service unavailable, try again later&quot;, job)

    case job: TransformationJob =&amp;gt; //执行相应任务
      jobCounter += 1
      implicit val timeout = Timeout(5 seconds)
      val backend = backends(jobCounter % backends.size) //根据相应算法选择执行任务的节点
      println(s&quot;the backend is ${backend} and the job is ${job}&quot;)
      val result  = (backend ? job)
        .map(x =&amp;gt; x.asInstanceOf[TransformationResult])  // 后台节点处理得到结果
      result pipeTo sender  //向外部系统发送执行结果

    case BackendRegistration if !backends.contains(sender()) =&amp;gt;  // 添加新的后台任务节点
      context watch sender() //监控相应的任务节点
      backends = backends :+ sender()

    case Terminated(a) =&amp;gt;
      backends = backends.filterNot(_ == a)  // 移除已经终止运行的节点
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt; 最后我们实现与集群客户端交互的逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class ClientJobTransformationSendingActor extends Actor {

  val initialContacts = Set(
    ActorPath.fromString(&quot;akka.tcp://ClusterSystem@127.0.0.1:2551/system/receptionist&quot;))
  val settings = ClusterClientSettings(context.system)
    .withInitialContacts(initialContacts)

  val c = context.system.actorOf(ClusterClient.props(settings), &quot;demo-client&quot;)


  def receive = {
    case TransformationResult(result) =&amp;gt; {
      println(s&quot;Client response and the result is ${result}&quot;)
    }
    case Send(counter) =&amp;gt; {
        val job = TransformationJob(&quot;hello-&quot; + counter)
        implicit val timeout = Timeout(5 seconds)
        val result = Patterns.ask(c,ClusterClient.Send(&quot;/user/frontend&quot;, job, localAffinity = true), timeout)
        result.onComplete {
          case Success(transformationResult) =&amp;gt; {
            self ! transformationResult
          }
          case Failure(t) =&amp;gt; println(&quot;An error has occured: &quot; + t.getMessage)
        }
      }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们开始运行这个domo：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object DemoClient {
  def main(args : Array[String]) {

    TransformationFrontendApp.main(Seq(&quot;2551&quot;).toArray)  //启动集群客户端
    TransformationBackendApp.main(Seq(&quot;8001&quot;).toArray)   //启动三个后台节点
    TransformationBackendApp.main(Seq(&quot;8002&quot;).toArray)
    TransformationBackendApp.main(Seq(&quot;8003&quot;).toArray)

    val system = ActorSystem(&quot;OTHERSYSTEM&quot;)
    val clientJobTransformationSendingActor =
      system.actorOf(Props[ClientJobTransformationSendingActor],
        name = &quot;clientJobTransformationSendingActor&quot;)

    val counter = new AtomicInteger
    import system.dispatcher
    system.scheduler.schedule(2.seconds, 2.seconds) {   //定时发送任务
      clientJobTransformationSendingActor ! Send(counter.incrementAndGet())
    }
    StdIn.readLine()
    system.terminate()
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/09/akka-cluster.png&quot; alt=&quot;akka-cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从结果可以看到，我们将任务根据算法分配给不同的后台节点进行执行，最终返回结果。&lt;/p&gt;

&lt;h3&gt;本文目的&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;掌握集群基本概念&lt;/li&gt;
&lt;li&gt;了解学习Akka cluster的工作方式和主要角色&lt;/li&gt;
&lt;li&gt;尝试自己写一个Akka cluster的相关例子&lt;/li&gt;
&lt;li&gt;下一步进阶了解Akka cluster的背后原理&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;本文的demo例子已上传github：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（九）：Akka分布式之Akka Remote</title>
   <link href="/2017/08/10/learning-akka-9.html"/>
   <updated>2017-08-10T00:00:00+08:00</updated>
   <id>urn:uuid:8d4f2b63-e930-3d54-8ca7-fbvbds2a4fgd</id>
   <content type="html">&lt;p&gt;Akka作为一个天生用于构建分布式应用的工具，当然提供了用于分布式组件即Akka Remote，那么我们就来看看如何用Akka Remote以及Akka Serialization来构建分布式应用。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;很多同学在程序的开发中都会遇到一个问题，当业务需求变得越来越复杂，单机服务器已经不足以承载相应的请求的时候，我们都会考虑将服务部署到不同的服务器上，但服务器之间可能需要相互调用，那么系统必须拥有相互通信的接口，用于相应的数据交互，这时候一个好的远程调用方案是一个绝对的利器，主流的远程通信有以下几种选择：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RPC（Remote Procedure Call Protocol）&lt;/li&gt;
&lt;li&gt;Web Service&lt;/li&gt;
&lt;li&gt;JMS（Java Messaging Service）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这几种方式都是被采用比较广泛的通信方案，有兴趣的同学可以自己去了解一下，这里我会讲一下Java中的RPC即RMI （Remote Method Invocation）和JMS。&lt;/p&gt;

&lt;h3&gt;JAVA远程调用&lt;/h3&gt;

&lt;p&gt;RMI和JMS相信很多写过Java程序的同学都知道，是Java程序用来远程通信的主要方式，那么RMI和JMS又有什么区别呢？&lt;/p&gt;

&lt;h4&gt;1.RMI&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;同步通信：在使用RMI调用远程方法时，线程会持续等待直到结果返回，所以它是一个同步阻塞操作；&lt;/li&gt;
&lt;li&gt;强耦合：请求的系统中需要使用的RMI服务进行接口声明，返回的数据类型有一定的约束；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;实现相对简单，方法调用形式通俗易理解，接口声明服务功能清晰。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;只局限支持JVM平台；&lt;/li&gt;
&lt;li&gt;对无法兼容Java语言的其他语言也不适用；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;2.JMS&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;异步通信：JMS发送消息进行通信，在通信过程中，线程不会被阻塞，不必等待请求回应，所以是一个异步操作；&lt;/li&gt;
&lt;li&gt;松耦合：不需要接口声明，返回的数据类型可以是各种各样，比如JSON，XML等；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.通信方式：&lt;/h5&gt;

&lt;p&gt;（1）点对点消息传送模型&lt;/p&gt;

&lt;p&gt;顾名思义，点对点可以理解为两个服务器的定点通信，发送者和接收者都能明确知道对方是谁，大致模型如下：
&lt;img src=&quot;/media/images/2017/08/jms-point-to-point.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（2）发布/订阅消息传递模型&lt;/p&gt;

&lt;p&gt;点对点模型有些场景并不是很适用，比如有一台主服务器，它产生一条消息需要让所有的从服务器都能收到，若采用点对点模型的话，那主服务器需要循环发送消息，后续若有新的从服务器增加，还要改主服务器的配置，这样就会导致不必要的麻烦，那么发布/订阅模型是怎么样的呢？其实这种模式跟设计模式中的观察者模式很相似，相信很多同学都很熟悉，它最大的特点就是较松耦合，易扩展等特点，所以发布/订阅模型的大致结构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/jms-topic.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;h5&gt;iii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;由于使用异步通信，不需要线程暂停等待，性能相对较高。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iiii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;技术实现相对复杂，并需要维护相关的消息队列；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;更通俗的说：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RMI可以看成是用打电话的方式进行信息交流，而JMS更像是发短信。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总的来说两种方式没有孰优孰劣，我们也不用比较到底哪种方式比较好，存在即合理，更重要的是哪种选择可能更适合你的系统。&lt;/p&gt;

&lt;h3&gt;RMI Example&lt;/h3&gt;

&lt;p&gt;这里我写一个RMI的例子，一方面来看一下它的使用方式，另一方面用于和后续的Akka Remote做一些比较：&lt;/p&gt;

&lt;p&gt;首先我们来编写相应的传输对象和通信接口：&lt;/p&gt;

&lt;p&gt;1.JoinRmiEvt：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class JoinRmiEvt implements Remote , Serializable{
    private static final long serialVersionUID = 1L;
    private Long id;
    private String name;

    public JoinRmiEvt(Long id, String name) {
        this.id = id;
        this.name = name;
    }

    public Long getId() {
        return id;
    }

    public void setId(Long id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.RemoteRmi:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public interface RemoteRmi extends Remote {
    public void sendNoReturn(String message) throws RemoteException, InterruptedException;
    public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在服务端对该接口进行实现：&lt;/p&gt;

&lt;p&gt;3.RemoteRmiImpl:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRmiImpl extends UnicastRemoteObject implements RemoteRmi {

    private static final long serialVersionUID = 1L;

    public  RemoteRmiImpl() throws RemoteException {};

    @Override
    public void sendNoReturn(String message) throws RemoteException, InterruptedException {
        Thread.sleep(2000);
        //throw new RemoteException(); 
    }

    @Override
    public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException {
      if (joinRmiEvt.getId() &amp;gt;= 0)
          return new StringBuilder(&quot;the&quot;).append(joinRmiEvt.getName()).append(&quot;has join&quot;).toString();
      else return null;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接着我们在Server端绑定相应端口并发布服务，然后启动：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRMIServer {
    public static void main(String[] args) throws RemoteException, AlreadyBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the RemoteRMIServer is Starting ...&quot;);
        RemoteRmiImpl remoteRmi = new RemoteRmiImpl();
        System.out.println(&quot;Binding server implementation to registry&quot;);
        LocateRegistry.createRegistry(2553);
        Naming.bind(&quot;rmi://127.0.0.1:2553/remote_rmi&quot;,remoteRmi);
        System.out.println(&quot;the RemoteRMIServer is Started&quot;);
        Thread.sleep(10000000);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们在Client端调用Server端的服务：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRmiClient {
    public static void main(String[] args) throws RemoteException, NotBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the client has started&quot;);
        String url = &quot;rmi://127.0.0.1:2553/remote_rmi&quot;;
        RemoteRmi remoteRmi = (RemoteRmi) Naming.lookup(url);
        System.out.println(&quot;the client has running&quot;);
        remoteRmi.sendNoReturn(&quot;send no return&quot;);
        System.out.println(remoteRmi.sendHasReturn(new JoinRmiEvt(1L,&quot;godpan&quot;)));
        System.out.println(&quot;the client has end&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/java-rmi-result.png&quot; alt=&quot;java-rmi-result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Java Rmi调用是一个阻塞的过程，这会导致一个问题，假如服务端的服务奔溃了，会导致客户端没有反应；&lt;/li&gt;
&lt;li&gt;Java Rmi使用的是Java默认的序列化方式,性能并不是很好，而且并不提供支持使用其他序列化的接口，在一些性能要求高的系统会有一定的瓶颈；&lt;/li&gt;
&lt;li&gt;在Rmi中使用的相应的接口和对象必须实现相应的接口，必须制定抛出相应的Exception，导致代码看起来异常的繁琐；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Remote&lt;/h3&gt;

&lt;p&gt;上面讲到JAVA中远程通信的方式，但我们之前说过Akka也是基于JVM平台的，那么它的通信方式又有什么不同呢？&lt;/p&gt;

&lt;p&gt;在我看来，Akka的远程通信方式更像是RMI和JMS的结合，但更偏向于JMS的方式，为什么这么说呢，我们先来看一个示例:&lt;/p&gt;

&lt;p&gt;我们先来创建一个远程的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class RemoteActor extends Actor {
  def receive = {
    case msg: String =&amp;gt;
      println(s&quot;RemoteActor received message '$msg'&quot;)
      sender ! &quot;Hello from the RemoteActor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们在远程服务器上启动这个Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么现在我们假如有一个系统需要向这个Actor发送消息应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们需要类似RMI发布自己的服务一样，我们需要为其他系统调用远程Actor提供消息通信的接口，在Akka中，设置非常简单，不需要代码侵入，只需简单的在配置文件里配置即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka {
  actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
  }
  remote {
    enabled-transports = [&quot;akka.remote.netty.tcp&quot;]
    netty.tcp {
      hostname = $localIp  //比如127.0.0.1
      port = $port //比如2552
    }
    log-sent-messages = on
    log-received-messages = on
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们只需配置相应的驱动，传输方式，ip，端口等属性就可简单完成Akka Remote的配置。&lt;/p&gt;

&lt;p&gt;当然本地服务器也需要配置这些信息，因为Akka之间是需要相互通信的，当然配置除了hostname有一定的区别外，其他配置信息可一致，本例子是在同一台机器上，所以这里hostname是相同的。&lt;/p&gt;

&lt;p&gt;这时候我们就可以在本地的服务器向这个Actor发送消息了，首先我们可以创建一个本地的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object Init
case object SendNoReturn

class LocalActor extends Actor{

  val path = ConfigFactory.defaultApplication().getString(&quot;remote.actor.name.test&quot;)
  implicit val timeout = Timeout(4.seconds)
  val remoteActor = context.actorSelection(path)

  def receive: Receive = {
    case Init =&amp;gt; &quot;init local actor&quot;
    case SendNoReturn =&amp;gt; remoteActor ! &quot;hello remote actor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;remote.actor.name.test&lt;/code&gt;的值为：“akka.tcp://RemoteDemoSystem@127.0.0.1:4444/user/RemoteActor”，另外我们可以看到我们使用了&lt;code&gt;context.actorSelection(path)&lt;/code&gt;来获取的是一个ActorSelection对象，若是需要获得ActorRef，我们可以调用它的resolveOne(),它返回的是是一个Future[ActorRef],这里是不是很熟悉，因为它跟本地获取Actor方式是一样的，因为Akka中Actor是位置透明的，获取本地Actor和远程Actor是一样的。&lt;/p&gt;

&lt;p&gt;最后我们首先启动远程Actor的系统：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object RemoteDemo extends App  {
  val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
  val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
  remoteActor ! &quot;The RemoteActor is alive&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们在本地系统中启动这个LocalActor，并向它发送消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object LocalDemo extends App {

  implicit val system = ActorSystem(&quot;LocalDemoSystem&quot;)
  val localActor = system.actorOf(Props[LocalActor], name = &quot;LocalActor&quot;)

  localActor ! Init
  localActor ! SendNoReturn
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到RemoteActor收到了一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-no-return.png&quot; alt=&quot;send-no-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从以上的步骤和结果看出可以看出，Akka的远程通信跟JMS的点对点模式似乎更相似一点，但是它有不需要我们维护消息队列，而是使用Actor自身的邮箱，另外我们利用context.actorSelection获取的ActorRef，可以看成远程Actor的副本，这个又和RMI相关概念类似，所以说Akka远程通信的形式上像是RMI和JMS的结合,当然底层还是通过TCP、UDP等相关网络协议进行数据传输的，从配置文件的相应内容便可以看出。&lt;/p&gt;

&lt;p&gt;上述例子演示的是sendNoReturn的模式，那么假如我们需要远程Actor给我们一个回复应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们创建一个消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object SendHasReturn

 def receive: Receive = {
    case SendHasReturn =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(&quot;hello remote actor&quot;)
      } yield r
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们重新运行LocalActor并像RemoteActor发送一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-has-return.png&quot; alt=&quot;send-has-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到LocalActor在发送消息后并收到了RemoteActor返回来的消息，另外我们这里设置了超时时间，若在规定的时间内没有得到反馈，程序就会报错。&lt;/p&gt;

&lt;h3&gt;Akka Serialization&lt;/h3&gt;

&lt;p&gt;其实这一部分本可以单独拿出来写，但是相信序列化这块大家都应该有所了解了，所以就不准备讲太多序列化的知识了，怕班门弄斧，主要讲讲Akka中的序列化。&lt;/p&gt;

&lt;p&gt;继续上面的例子，假如我们这时向RemoteActor发送一个自定义的对象，比如一个case class对象，但是我们这是是在网络中传输这个消息，那么怎么保证这个对象类型和值呢，在同一个JVM系统中我们不需要担心这个，因为对象就在堆中，我们只要传递相应的地址即可就行，但是在不同的环境中，我们并不能这么做，我们在网络中只能传输字节数据，所以我们必须将对象做特殊的处理，在传输的时候转化成特定的由一连串字节组成的数据，而且我们又可以根据这些数据恢复成一个相应的对象，这便是序列化。&lt;/p&gt;

&lt;p&gt;我们先定义一个参与的case class, 并修改一下上面发送消息的语句:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case object SendSerialization
case class JoinEvt(
    id: Long,
    name: String
)
def receive: Receive = {
    case SendSerialization =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(JoinEvt(1L,&quot;godpan&quot;))
      } yield println(r)
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时我们重新启动RemoteActor和LocalActor所在的系统，发送这条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-serialization.png&quot; alt=&quot;send-serialization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有同学可能会觉得奇怪，我们明明没有对JoinEvt进行过任何序列化的标识和处理，为什么程序还能运行成功呢？&lt;/p&gt;

&lt;p&gt;其实不然，只不过是有人替我们默认做了，不用说，肯定是贴心的Akka，它为我们提供了一个默认的序列化策略，那就是我们熟悉又纠结的java.io.Serializable，沉浸在它的易使用性上，又对它的性能深恶痛绝，尤其是当有大量对象需要传输的分布式系统，如果是小系统，当我没说，毕竟存在即合理。&lt;/p&gt;

&lt;p&gt;又有同学说，既然Akka是一个天生分布式组件，为什么还用低效的java.io.Serializable，你问我我也不知道，可能当时的作者偷了偷懒，当然Akka现在可能觉醒了，首先它支持第三方的序列化工具，当然如果你有特殊需求，你也可以自己实现一个，而且在最新的文档中说明，在Akka 2.5x之后Akka内核消息全面废弃java.io.Serializable，用户自定义的消息暂时还是支持使用java.io.Serializable的，但是不推荐用，因为它是低效的，容易被攻击，所以在这里我也推荐大家再Akka中尽量不要在使用了java.io.Serializable。&lt;/p&gt;

&lt;p&gt;那么在Akka中我们如何使用第三方的序列化工具呢？&lt;/p&gt;

&lt;p&gt;这里我推荐一个在Java社区已经久负盛名的序列化工具：kryo，有兴趣的同学可以去了解一下：&lt;a href=&quot;https://github.com/EsotericSoftware/kryo&quot;&gt;kryo&lt;/a&gt;,而且它也提供Akka使用的相关包，这里我们就使用它作为示例：&lt;/p&gt;

&lt;p&gt;这里我贴上整个项目的build.sbt, kryo的相关依赖也在里面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
import sbt._
import sbt.Keys._

lazy val AllLibraryDependencies =
  Seq(
    &quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.5.3&quot;,
    &quot;com.typesafe.akka&quot; %% &quot;akka-remote&quot; % &quot;2.5.3&quot;,
    &quot;com.twitter&quot; %% &quot;chill-akka&quot; % &quot;0.8.4&quot;
  )

lazy val commonSettings = Seq(
  name := &quot;AkkaRemoting&quot;,
  version := &quot;1.0&quot;,
  scalaVersion := &quot;2.11.11&quot;,
  libraryDependencies := AllLibraryDependencies
)

lazy val remote = (project in file(&quot;remote&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )

lazy val local = (project in file(&quot;local&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们只需将application.conf中的actor配置替换成以下的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
    serializers {
      kryo = &quot;com.twitter.chill.akka.AkkaSerializer&quot;
    }
    serialization-bindings {
      &quot;java.io.Serializable&quot; = none
      &quot;scala.Product&quot; = kryo
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实其中的&quot;java.io.Serializable&quot; = none可以省略，因为若是有其他序列化的策略则会替换掉默认的java.io.Serializable的策略，这里只是为了更加仔细的说明。&lt;/p&gt;

&lt;p&gt;至此我们就可以使用kryo了，整个过程是不是很easy，迫不及待开始写demo了，那就快快开始吧。&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Akka Remote使用内置的序列化工具，并支持配置指定的序列化方式，可以按需配置；&lt;/li&gt;
&lt;li&gt;Akka Remote使用的过程是一个异步非阻塞的过程，客户端能尽量减少对服务端的依赖；&lt;/li&gt;
&lt;li&gt;Akka Remote的代码实现相对Java Rmi实现来说简单的多，非常简洁；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;整个例子的相关的源码已经上传到akka-demo中：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_06&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（八）：Akka persistence设计理念之CQRS</title>
   <link href="/2017/07/29/learning-akka-8.html"/>
   <updated>2017-07-29T00:00:00+08:00</updated>
   <id>urn:uuid:8dcf2b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这一篇文章主要是讲解Akka persistence的核心设计理念，也是CQRS（Command Query Responsibility Segregation）架构设计的典型应用，就让我们来看看为什么Akka persistence会采用CQRS架构设计。&lt;/p&gt;

&lt;h3&gt;CQRS&lt;/h3&gt;

&lt;p&gt;很多时候我们在处理高并发的业务需求的时候，往往能把应用层的代码优化的很好，比如缓存，限流，均衡负载等，但是很难避免的一个问题就是数据的持久化，以致数据库的性能很可能就是系统性能的瓶颈，我前面的那篇文章也讲到，如果我们用数据库去保证记录的CRUD，在并发高的情况下，让数据库执行这么多的事务操作，会让很多数据库操作超时，连接池不够用的情况，导致大量请求失败，系统的错误率上升和负载性能下降。&lt;/p&gt;

&lt;p&gt;既然这样，那我们可不可借鉴一下读写分离的思想呢？假使写操作和同操作分离，甚至是对不同数据表，数据库操作，那么我们就可以大大降低数据库的瓶颈，使整个系统的性能大大提升。那么CQRS到底是做了什么呢？&lt;/p&gt;

&lt;p&gt;我们先来看看普通的方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/acid.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看出，我们对数据的请求都是通过相应的接口直接对数据库进行操作，这在并发大的时候肯定会对数据库造成很大的压力，虽然架构简单，但在面对并发高的情况下力不从心。&lt;/p&gt;

&lt;p&gt;那么CQRS的方式有什么不同呢？我们也来看看它的执行方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;乍得一看，似乎跟普通的方式没什么不同啊，不就多了一个事件和存储DB么，其实不然，小小的改动便是核心理念的转换，首先我们可以看到在CQRS架构中会多出一个Event，那它到底代表着什么含义呢？其实看过上篇文章的同学很容易理解，Event是我们系统根据请求处理得出的一个领域模型，比如一个修改余额操作事件，当然这个Event中只会保存关键性的数据。&lt;/p&gt;

&lt;p&gt;很多同学又有疑问了，这不跟普通的读写分离很像么，难道还隐藏着什么秘密？那我们就来比较一下几种方式的不同之处：&lt;/p&gt;

&lt;h5&gt;1.单数据库模式&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;写操作会产生互斥锁，导致性能降低；&lt;/li&gt;
&lt;li&gt;即使使用乐观锁，但是在大量写操作的情况下也会大量失败；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;2.读写分离&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;读写分离通过物理服务器增加，负荷增加；&lt;/li&gt;
&lt;li&gt;读写分离更适用于读操作大于写操作的场景；&lt;/li&gt;
&lt;li&gt;读写分离在面对大量写操作的情况下还是很吃力；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;3.CQRS&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;普通数据的持久化和Event持久化可以使用同一台数据库；&lt;/li&gt;
&lt;li&gt;利用架构设计可以使读和写操作尽可能的分离；&lt;/li&gt;
&lt;li&gt;能支撑大量写的操作情况；&lt;/li&gt;
&lt;li&gt;可以支持数据异步持久，确保数据最终一致性；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;从三种方式各自的特点可以看出，单数据库模式的在大量读写的情况下有很大的性能瓶颈，但简单的读写分离在面对大量写操作的时候也还是力不从心，比如最常见的库存修改查询场景：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/common-action.png&quot; alt=&quot;common-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以发现在这种模式下写数据库的压力还会很大，而且还有数据同步，数据延迟等问题。&lt;/p&gt;

&lt;p&gt;那么我们用CQRS架构设计会是怎么样呢：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-action.png&quot; alt=&quot;cqrs-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先我们可以业务模型进行分离，对不同的查询进行分离，另外避免不了的同一区间数据段进行异步持久化，在保证数据一致性的情况下提升系统的吞吐量。这种设计我们很少会遇到事务竞争，另外还可以使用内存数据库（当然如果是内存操作那就最快）来提升数据的写入。（以上的数据库都可为分布式数据库，不担心单机宕机）&lt;/p&gt;

&lt;p&gt;那么CRQS机制是怎么保证数据的一致性的呢？&lt;/p&gt;

&lt;p&gt;从上图中我们可以看出，一个写操作我们会在系统进行初步处理后生成一个领域事件，比如a用户购买了xx商品1件，b用户购买了xx商品2件等，按照普通的方式我们肯定是直接将订单操作，库存修改操作一并放在一个事务内去操作数据库，性能可想而知，而用CQRS的方式后，首先系统在持久化相应的领域事件后和修改内存中的库存（这个处理非常迅速）后便可马上向用户做出反应，真正的具体信息持久可以异步进行，当然若是当在具体信息持久化的过程中出错了怎么办，系统能恢复正确的数据么，当然可以，因为我们的领域事件事件已经持久化成功了，在系统恢复的时候，我们可以根据领域事件来恢复真正的数据，当然为了防止恢复数据是造成数据丢失，数据重复等问题我们需要制定相应的原则，比如给领域事件分配相应id等。&lt;/p&gt;

&lt;p&gt;使用CQRS会带来性能上的提升，当然它也有它的弊端：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使系统变得更复杂，做一些额外的设计；&lt;/li&gt;
&lt;li&gt;CQRS保证的是最终一致性，有可能只适用于特定的业务场景；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Persistence 中CQRS的应用&lt;/h3&gt;

&lt;p&gt;通过上面的讲解，相信大家对CQRS已经有了一定的了解，下面我们就来看看它在Akka Persistence中的具体应用，这里我就结合上一篇文章抽奖的例子，比如其中的LotteryCmd便是一个写操作命令，系统经过相应的处理后得到相应的领域事件，比如其中LuckyEvent，然后我们将LuckyEvent进行持久化，并修改内存中抽奖的余额，返回相应的结果，这里我们就可以同时将结果反馈给用户，并对结果进行异步持久化，流程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-example.png&quot; alt=&quot;cqrs-example&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出，Akka Persistence的原理完全是基于CQRS的架构设计的，另外Persistence Actor还会保存一个内存状态，相当于一个in memory数据库，可以用来提供关键数据的存储和查询，比如前面说到的库存，余额等数据，这部分的设计取决于具体的业务场景。&lt;/p&gt;

&lt;p&gt;阅读Akka Persistence相关源码，其的核心就在于PersistentActor接口中的几个持久方法，比如其中的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;def persist[A](event: A)(handler: A ⇒ Unit): Unit

def persistAll[A](events: immutable.Seq[A])(handler: A ⇒ Unit): Unit 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等方法，它们都有两个参数，一个是持久化的事件，一个是持久化后的后续处理逻辑，我们可以在后续handler中修改Actor内部状态，向外部发送消息等操作,这里的模式就是基于CQRS架构的，修改状态有事件驱动，另外Akka还可以在系统出错时，利用相应的事件恢复Actor的状态。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;总的来说，CQRS架构是一种不同于以往的CRUD的架构，所以你在享受它带来的高性能的同时可能会遇到一些奇怪的问题，当然这些都是可以解决的，重要的是思维上的改变，比如事件驱动，领域模型等概念，不过相信当你理解并掌握它之后，你便会爱上它的。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（七）：Actor持久化之Akka persistence</title>
   <link href="/2017/07/25/learning-akka-7.html"/>
   <updated>2017-07-25T00:00:00+08:00</updated>
   <id>urn:uuid:8dcf2b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这次把这部分内容提到现在写，是因为这段时间开发的项目刚好在这一块遇到了一些难点，所以准备把经验分享给大家，我们在使用Akka时，会经常遇到一些存储Actor内部状态的场景，在系统正常运行的情况下，我们不需要担心什么，但是当系统出错，比如Actor错误需要重启，或者内存溢出，亦或者整个系统崩溃，如果我们不采取一定的方案的话，在系统重启时Actor的状态就会丢失，这会导致我们丢失一些关键的数据，造成系统数据不一致的问题。Akka作为一款成熟的生产环境应用，为我们提供了相应的解决方案就是Akka persistence。&lt;/p&gt;

&lt;h3&gt;为什么需要持久化的Actor？&lt;/h3&gt;

&lt;p&gt;万变不离其宗，数据的一致性是永恒的主题，一个性能再好的系统，不能保证数据的正确，也称不上是一个好的系统，一个系统在运行的时候难免会出错，如何保证系统在出错后能正确的恢复数据，不让数据出现混乱是一个难题。使用Actor模型的时候，我们会有这么一个想法，就是能不对数据库操作就尽量不对数据库操作（这里我们假定我们的数据库是安全，可靠的，能保证数据的正确性和一致性，比如使用国内某云的云数据库），一方面如果大量的数据操作会使数据库面临的巨大的压力，导致崩溃，另一方面即使数据库能处理的过来，比如一些count，update的大表操作也会消耗很多的时间，远没有内存中直接操作来的快，大大影响性能。但是又有人说内存操作这么快，为什么不把数据都放内存中呢？答案显而易见，当出现机器死机，或者内存溢出等问题时，数据很有可能就丢失了导致无法恢复。在这种背景下，我们是不是有一种比较好的解决方案，既能满足需求又能用最小的性能消耗，答案就是上面我们的说的Akka persistence。&lt;/p&gt;

&lt;h3&gt;Akka persistence的核心架构&lt;/h3&gt;

&lt;p&gt;在具体深入Akka persistence之前，我们可以先了解一下它的核心设计理念，其实简单来说，我们可以利用一些thing来恢复Actor的状态，这里的thing可以是日志、数据库中的数据，亦或者是文件，所以说它的本质非常容易理解，在Actor处理的时候我们会保存一些数据，Actor在恢复的时候能根据这些数据恢复其自身的状态。&lt;/p&gt;

&lt;p&gt;所以Akka persistence 有以下几个关键部分组成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PersistentActor：任何一个需要持久化的Actor都必须继承它，并必须定义或者实现其中的三个关键属性：&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt; def persistenceId = &quot;example&quot; //作为持久化Actor的唯一表示，用于持久化或者查询时使用

 def receiveCommand: Receive = ??? //Actor正常运行时处理处理消息逻辑，可在这部分内容里持久化自己想要的消息

 def receiveRecover: Receive = ??? //Actor重启恢复是执行的逻辑
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比普通的Actor，除receiveCommand相似以外，还必须实现另外两个属性。
另外在持久化Actor中还有另外两个关键的的概念就是&lt;em&gt;Journal&lt;/em&gt;和&lt;em&gt;Snapshot&lt;/em&gt;，前者用于持久化事件，后者用于保存Actor的快照，两者在Actor恢复状态的时候都起到了至关重要的作用。&lt;/p&gt;

&lt;h3&gt;Akka persistence的demo实战&lt;/h3&gt;

&lt;p&gt;这里我首先会用一个demo让大家能对Akka persistence的使用有一定了解的，并能大致明白它的工作原理，后面再继续讲解一些实战可能会遇到的问题。&lt;/p&gt;

&lt;p&gt;假定现在有这么一个场景，现在假设有一个1w元的大红包，瞬间可能会很多人同时来抢，每个人抢的金额也可能不一样，场景很简单，实现方式也有很多种，但前提是保证数据的正确性，比如最普通的使用数据库保证，但对这方面有所了解的同学都知道这并不是一个很好的方案，因为需要锁，并需要大量的数据库操作，导致性能不高，那么我们是否可以用Actor来实现这个需求么？答案是当然可以。&lt;/p&gt;

&lt;p&gt;我们首先来定义一个抽奖命令，
&lt;code&gt;scala
case class LotteryCmd(
  userId: Long, // 参与用户Id
  username: String, //参与用户名
  email: String // 参与用户邮箱
)
&lt;/code&gt;
然后我们实现一个抽奖Actor，并继承PersistentActor作出相应的实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case class LuckyEvent(  //抽奖成功事件
    userId: Long,
    luckyMoney: Int
)
case class FailureEvent(  //抽奖失败事件
    userId: Long,
    reason: String
)
case class Lottery(
    totalAmount: Int,  //红包总金额
    remainAmount: Int  //剩余红包金额
) {
  def update(luckyMoney: Int) = {
    copy(
      remainAmount = remainAmount - luckyMoney
    )
  }
}
class LotteryActor(initState: Lottery) extends PersistentActor with ActorLogging{
  override def persistenceId: String = &quot;lottery-actor-1&quot;

  var state = initState  //初始化Actor的状态

  override def receiveRecover: Receive = {
    case event: LuckyEvent =&amp;gt;
      updateState(event)  //恢复Actor时根据持久化的事件恢复Actor状态
    case SnapshotOffer(_, snapshot: Lottery) =&amp;gt;
      log.info(s&quot;Recover actor state from snapshot and the snapshot is ${snapshot}&quot;)
      state = snapshot //利用快照恢复Actor的状态
    case RecoveryCompleted =&amp;gt; log.info(&quot;the actor recover completed&quot;)
  }

  def updateState(le: LuckyEvent) =
    state = state.update(le.luckyMoney)  //更新自身状态

  override def receiveCommand: Receive = {
    case lc: LotteryCmd =&amp;gt;
      doLottery(lc) match {     //进行抽奖，并得到抽奖结果，根据结果做出不同的处理
        case le: LuckyEvent =&amp;gt;  //抽到随机红包
          persist(le) { event =&amp;gt;
            updateState(event)
            increaseEvtCountAndSnapshot()
            sender() ! event
          }
        case fe: FailureEvent =&amp;gt;  //红包已经抽完
          sender() ! fe
      }
    case &quot;saveSnapshot&quot; =&amp;gt;  // 接收存储快照命令执行存储快照操作
      saveSnapshot(state)
    case SaveSnapshotSuccess(metadata) =&amp;gt;  ???  //你可以在快照存储成功后做一些操作，比如删除之前的快照等
  }

  private def increaseEvtCountAndSnapshot() = {
    val snapShotInterval = 5
    if (lastSequenceNr % snapShotInterval == 0 &amp;amp;&amp;amp; lastSequenceNr != 0) {  //当有持久化5个事件后我们便存储一次当前Actor状态的快照
      self ! &quot;saveSnapshot&quot;
    }
  }

  def doLottery(lc: LotteryCmd) = {  //抽奖逻辑具体实现
    if (state.remainAmount &amp;gt; 0) {
      val luckyMoney = scala.util.Random.nextInt(state.remainAmount) + 1
      LuckyEvent(lc.userId, luckyMoney)
    }
    else {
      FailureEvent(lc.userId, &quot;下次早点来，红包已被抽完咯！&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;程序很简单，关键位置我也给了注释，相信大家对Actor有所了解的话很容易理解，当然要是有些疑惑，可以看看我之前写的文章，下面我们就对刚才写的抽红包Actor进行测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object PersistenceTest extends App {
  val lottery = Lottery(10000,10000)
  val system = ActorSystem(&quot;example-05&quot;)
  val lotteryActor = system.actorOf(Props(new LotteryActor(lottery)), &quot;LotteryActor-1&quot;)  //创建抽奖Actor
  val pool: ExecutorService = Executors.newFixedThreadPool(10)
  val r = (1 to 100).map(i =&amp;gt;
    new LotteryRun(lotteryActor, LotteryCmd(i.toLong,&quot;godpan&quot;,&quot;xx@gmail.com&quot;))  //创建100个抽奖请求
  )
  r.map(pool.execute(_))  //使用线程池来发起抽奖请求，模拟同时多人参加
  Thread.sleep(5000)
  pool.shutdown()
  system.terminate()
}

class LotteryRun(lotteryActor: ActorRef, lotteryCmd: LotteryCmd) extends Runnable { //抽奖请求
  implicit val timeout = Timeout(3.seconds)
  def run: Unit = {
    for {
      fut &amp;lt;- lotteryActor ? lotteryCmd
    } yield fut match {  //根据不同事件显示不同的抽奖结果
      case le: LuckyEvent =&amp;gt; println(s&quot;恭喜用户${le.userId}抽到了${le.luckyMoney}元红包&quot;)
      case fe: FailureEvent =&amp;gt;  println(fe.reason)
      case _ =&amp;gt; println(&quot;系统错误，请重新抽取&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行程序,我们可能看到以下的结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/result-persistence-demo.png&quot; alt=&quot;result persistence demo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面我会把persistence actor在整个运行过程的步骤给出，帮助大家理解它的原理：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.初始化Persistence Actor&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.1若是第一次初始化，则与正常的Actor的初始化一致。&lt;/li&gt;
&lt;li&gt;1.2若是重启恢复Actor，这根据Actor之前持久的数据恢复。

&lt;ul&gt;
&lt;li&gt;1.2.1从快照恢复，可快速恢复Actor，但并非每次持久化事件都会保存快照，在快照完整的情况下，Actor优先从快照恢复自身状态。&lt;/li&gt;
&lt;li&gt;1.2.2从事件（日志，数据库记录等）恢复，通过重放持久化事件恢复Actor状态，比较关键。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2.接收命令进行处理，转化为需要持久化的事件（持久化的事件尽量只包含关键性的数据）使用Persistence Actor的持久化方法进行持久化（上述例子中的persist，后面我会讲一下批量持久化），并处理持久化成功后的逻辑处理，比如修改Actor状态，向外部Actor发送消息等。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;3.若是我们需要存储快照，那么可以主动指定存储快照的频率，比如持久化事件100次我们就存储一次快照，这个频率应该要考虑实际的业务场景，在存储快照成功后我们也可以执行一些操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说Persistence Actor运行时的大致操作就是以上这些，当然它是r如何持久化事件，恢复时的机制是怎么样的等有兴趣的可以看一下Akka源码。&lt;/p&gt;

&lt;h3&gt;使用Akka persistence的相关配置&lt;/h3&gt;

&lt;p&gt;首先我们必须加载相应的依赖包，在&lt;code&gt;bulid.sbt&lt;/code&gt;中加入以下依赖：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(
&quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.4.16&quot;,  //Akka actor 核心依赖
  &quot;com.typesafe.akka&quot; %% &quot;akka-persistence&quot; % &quot;2.4.16&quot;, //Akka persistence 依赖
  &quot;org.iq80.leveldb&quot;            % &quot;leveldb&quot;          % &quot;0.7&quot;, //leveldb java版本依赖
  &quot;org.fusesource.leveldbjni&quot;   % &quot;leveldbjni-all&quot;   % &quot;1.8&quot;, //leveldb java版本依赖
  &quot;com.twitter&quot;              %% &quot;chill-akka&quot;                  % &quot;0.8.0&quot; //事件序列化依赖
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外我们还需在&lt;code&gt;application.conf&lt;/code&gt;加入以下配置:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;akka.persistence.journal.plugin = &quot;akka.persistence.journal.leveldb&quot;
akka.persistence.snapshot-store.plugin = &quot;akka.persistence.snapshot-store.local&quot;

akka.persistence.journal.leveldb.dir = &quot;log/journal&quot;
akka.persistence.snapshot-store.local.dir = &quot;log/snapshots&quot;

# DO NOT USE THIS IN PRODUCTION !!!
# See also https://github.com/typesafehub/activator/issues/287
akka.persistence.journal.leveldb.native = false  //因为我们本地并没有安装leveldb，所以这个属性置为false，但是生产环境并不推荐使用

akka.actor.serializers {
  kryo = &quot;com.twitter.chill.akka.AkkaSerializer&quot;
}

akka.actor.serialization-bindings {
  &quot;scala.Product&quot; = kryo
  &quot;akka.persistence.PersistentRepr&quot; = kryo
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此为止我们整个Akka persistence demo已经搭建好了，可以正常运行了，有兴趣的同学可以下载源码。&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_05&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Akka persistence进阶&lt;/h3&gt;

&lt;h4&gt;1.持久化插件&lt;/h4&gt;

&lt;p&gt;有同学可能会问，我对leveldb不是很熟悉亦或者觉得单机存储并不是安全，有没有支持分布式数据存储的插件呢，比如某爸的云数据库？答案当然是有咯，良心的我当然是帮你们都找好咯。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.akka-persistence-sql-async: 支持MySQL和PostgreSQL，另外使用了全异步的数据库驱动，提供异步非阻塞的API，我司用的就是它的变种版，6的飞起。&lt;a href=&quot;https://github.com/okumin/akka-persistence-sql-async&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2.akka-persistence-cassandra: 官方推荐的插件，使用写性能very very very fast的cassandra数据库，是几个插件中比较流行的一个，另外它还支持persistence query。&lt;a href=&quot;https://github.com/krasserm/akka-persistence-cassandra&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;3.akka-persistence-redis: redis应该也很符合Akka persistence的场景，熟悉redis的同学可以使用看看。&lt;a href=&quot;https://github.com/hootsuite/akka-persistence-redis&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;4.akka-persistence-jdbc: 怎么能少了jdbc呢？不然怎么对的起java爸爸呢，支持scala和java哦。&lt;a href=&quot;https://github.com/dnvriend/akka-persistence-jdbc&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;相应的插件的具体使用可以看该项目的具体介绍使用，我看了下相对来说都是比较容易的。&lt;/p&gt;

&lt;h4&gt;2.批量持久化&lt;/h4&gt;

&lt;p&gt;上面说到我司用的是akka-persistence-sql-async插件，所以我们是将事件和快照持久化到数据库的，一开始我也是像上面demo一样，每次事件都会持久化到数据库，但是后来在性能测试的时候，因为本身业务场景对数据库的压力也比较大，在当数据库到达每秒1000+的读写量后，另外说明一下使用的是某云数据库，性能中配以上，发现每次持久化的时间将近要15ms，这样换算一下的话Actor每秒只能处理60~70个需要持久化的事件，而实际业务场景要求Actor必须在3秒内返回处理结果，这种情况下导致大量消息处理超时得不到反馈，另外还有大量的消息得不到处理，导致系统错误暴增，用户体验下降，既然我们发现了问题，那么我们能不能进行优化呢?事实上当然是可以，既然单个插入慢，那么我们能不能批量插入呢，Akka persistence为我们提供了persistAll方法，下面我就对上面的demo进行一下改造，让其变成批量持久化：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class LotteryActorN(initState: Lottery) extends PersistentActor with ActorLogging{
  override def persistenceId: String = &quot;lottery-actor-2&quot;

  var state = initState  //初始化Actor的状态

  override def receiveRecover: Receive = {
    case event: LuckyEvent =&amp;gt;
      updateState(event)  //恢复Actor时根据持久化的事件恢复Actor状态
    case SnapshotOffer(_, snapshot: Lottery) =&amp;gt;
      log.info(s&quot;Recover actor state from snapshot and the snapshot is ${snapshot}&quot;)
      state = snapshot //利用快照恢复Actor的状态
    case RecoveryCompleted =&amp;gt; log.info(&quot;the actor recover completed&quot;)
  }

  def updateState(le: LuckyEvent) =
    state = state.update(le.luckyMoney)  //更新自身状态

  var lotteryQueue : ArrayBuffer[(LotteryCmd, ActorRef)] = ArrayBuffer()

  context.system.scheduler  //定时器，定时触发抽奖逻辑
    .schedule(
      0.milliseconds,
      100.milliseconds,
      new Runnable {
        def run = {
          self ! &quot;doLottery&quot;
        }
      }
    )

  override def receiveCommand: Receive = {
    case lc: LotteryCmd =&amp;gt;
      lotteryQueue = lotteryQueue :+ (lc, sender())  //参与信息加入抽奖队列
      println(s&quot;the lotteryQueue size is ${lotteryQueue.size}&quot;)
      if (lotteryQueue.size &amp;gt; 5)  //当参与人数有5个时触发抽奖
        joinN(lotteryQueue)
    case &quot;doLottery&quot; =&amp;gt;
      if (lotteryQueue.size &amp;gt; 0)
        joinN(lotteryQueue)
    case &quot;saveSnapshot&quot; =&amp;gt;  // 接收存储快照命令执行存储快照操作
      saveSnapshot(state)
    case SaveSnapshotSuccess(metadata) =&amp;gt;  ???  //你可以在快照存储成功后做一些操作，比如删除之前的快照等
  }

  private def joinN(lotteryQueue: ArrayBuffer[(LotteryCmd, ActorRef)]) = {  //批量处理抽奖结果
    val rs = doLotteryN(lotteryQueue)
    val success = rs.collect {  //得到其中中奖的相应信息
      case (event: LuckyEvent, ref: ActorRef) =&amp;gt;
        event -&amp;gt; ref
    }.toMap
    val failure = rs.collect {  //得到其中未中奖的相应信息
      case (event: FailureEvent, ref: ActorRef) =&amp;gt; event -&amp;gt; ref
    }
    persistAll(success.keys.toIndexedSeq) {  //批量持久化中奖用户事件
      case event =&amp;gt;  println(event)
        updateState(event)
        increaseEvtCountAndSnapshot()
        success(event) ! event
    }
    failure.foreach {
      case (event, ref) =&amp;gt; ref ! event
    }
    this.lotteryQueue.clear()  //清空参与队列
  }


  private def increaseEvtCountAndSnapshot() = {
    val snapShotInterval = 5
    if (lastSequenceNr % snapShotInterval == 0 &amp;amp;&amp;amp; lastSequenceNr != 0) {  //当有持久化5个事件后我们便存储一次当前Actor状态的快照
      self ! &quot;saveSnapshot&quot;
    }
  }

  private def doLotteryN(lotteryQueue: ArrayBuffer[(LotteryCmd, ActorRef)]) = {  //抽奖逻辑具体实现
    var remainAmount = state.remainAmount
    lotteryQueue.map(lq =&amp;gt;
      if (remainAmount &amp;gt; 0) {
        val luckyMoney = scala.util.Random.nextInt(remainAmount) + 1
        remainAmount = remainAmount - luckyMoney
        (LuckyEvent(lq._1.userId, luckyMoney),lq._2)
      }
      else {
        (FailureEvent(lq._1.userId, &quot;下次早点来，红包已被抽完咯！&quot;),lq._2)
      }
    )
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是改造后的参与Actor，实现了批量持久的功能，当然这里为了给发送者返回消息，处理逻辑稍微复杂了一点，不过真实场景可能会更复杂，相关源码也在刚才的项目上。&lt;/p&gt;

&lt;h4&gt;3.Persistence Query&lt;/h4&gt;

&lt;p&gt;另外Akka Persistence还提供了Query接口，用于需要查询持久化事件的需求，这部分内容可能要根据实际业务场景考虑是否需要应用，我就不展开讲了，另外我也写了一个小demo在项目中，想要尝试的同学也可以试试。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（六）：Actor解决了什么问题？</title>
   <link href="/2017/07/10/learning-akka-6.html"/>
   <updated>2017-07-10T00:00:00+08:00</updated>
   <id>urn:uuid:85cf4b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这段时间由于忙毕业前前后后的事情，拖更了很久，表示非常抱歉，回归后的第一篇文章主要是看到了Akka最新文档中写的&lt;a href=&quot;http://doc.akka.io/docs/akka/current/scala/guide/actors-intro.html&quot;&gt;What problems does the actor model solve?&lt;/a&gt;,阅读完后觉得还是蛮不错，能简洁清晰的阐述目前并发领域遇到的问题，并为何利用Actor模型可以解决这些问题，本文主要是利用自己的理解将这篇文章进行翻译，有不足之处还请指出。&lt;/p&gt;

&lt;h2&gt;Actor解决了什么问题？&lt;/h2&gt;

&lt;p&gt;Akka使用Actor模型来克服传统面向对象编程模型的局限性，并应对高并发分布式系统所带来的挑战。 充分理解Actor模型是必需的，它有助于我们认识到传统的编程方法在并发和分布式计算的领域上的不足之处。&lt;/p&gt;

&lt;h3&gt;封装的弊端&lt;/h3&gt;

&lt;p&gt;面向对象编程（OOP）是一种广泛采用的，熟悉的编程模型，它的一个核心理念就是封装，并规定对象封装的内部数据不能从外部直接访问，只允许相关的属性方法进行数据操作，比如我们熟悉的Javabean中的getX，setX等方法，对象为封装的内部数据提供安全的数据操作。&lt;/p&gt;

&lt;p&gt;举个例子，有序二叉树必须保证树节点数据的分布规则，若你想利用有序二叉树进行查询相关数据，就必须要依赖这个约束。&lt;/p&gt;

&lt;p&gt;当我们在分析面向对象编程在运行时的行为时，我们可能会绘制一个消息序列图，用来显示方法调用时的交互，如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart.png&quot; alt=&quot;seq chart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但上述图表并不能准确地表示实例在执行过程中的生命线。实际上，一个线程执行所有这些调用，并且变量的操作也在调用该方法的同一线程上。为刚才的序列图加上执行线程，看起来像这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart-thread.png&quot; alt=&quot;seq chart thread&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但当在面对多线程的情况下，会发现此前的图越来越混乱和变得不清晰，现在我们模拟多个线程访问同一个示例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart-multi-thread.png&quot; alt=&quot;seq chart multi thread&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在上面的这种情况中，两个线程调用同一个方法，但别调用的对象并不能保证其封装的数据发生了什么，两个调用的方法指令可以任意方式的交织，无法保证共享变量的一致性，现在，想象一下在更多线程下这个问题会更加严重。&lt;/p&gt;

&lt;p&gt;解决这个问题最通常的方法就是在该方法上加锁。通过加锁可以保证同一时刻只有一个线程能进入该方法，但这是一个代价非常昂贵的方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;锁非常严重的限制并发，它在现在的CPU架构上代价是非常大的，它需要操作系统暂停和重启线程。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;调用者的线程会被阻塞，以致于它不能去做其他有意义的任务，举个例子我们希望桌面程序在后台运行的时候，操作UI界面也能得到响应。在后台，，线程阻塞完全是浪费的，有人可能会说可以通过启动新线程进行补偿，但线程也是一种非常昂贵的资源。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用锁会导致一个新的问题：死锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这些现实存在的问题让我们只能两者选一：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;不使用锁，但会导致状态混乱。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用大量的锁，但是会降低性能并很容易导致死锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;另外，锁只能在本地更好的利用，当我们的程序部署在不同的机器上时，我们只能选择使用分布式锁，但不幸的是，分布式锁的效率可能比本地锁低好几个量级，对后续的扩展也会有很大的限制，分布式锁的协议要求多台机器在网络上进行相互通信，因此延迟可能会变得非常高。&lt;/p&gt;

&lt;p&gt;在面向对象语言中，我们很少会去考虑线程或者它的执行路径，我们通常将系统想象成许多实例对象连接成的网络，通过方法调用，修改实例对象内部的状态，然后通过实例对象之前的方法调用驱动整个程序进行交互：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/object-graph.png&quot; alt=&quot;object graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后，在多线程分布式环境中，实际上线程是通过方法调用遍历这个对象实例网络。因此，线程是方法调用驱动执行的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/object-graph-snakes.png&quot; alt=&quot;object graph snakes&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对象只能保证在单一线程中封装数据的正确性，在多线程环境下可能会导致状态混乱，在同一个代码段，两个竞争的线程可能导致变量的不一致。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用锁看起来可以在多线程环境下保证封装数据的正确性，但实际上它在程序真是运行时是低效的并且很容易导致死锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁在单机工作可能还不错，但是在分布式的环境表现的很不理想，扩展性很差。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;共享内存在现代计算机架构上的弊端&lt;/h3&gt;

&lt;p&gt;在80-90年代的编程模型概念中，写一个变量相当于直接把它写入内存，但是在现代的计算机架构中，我们做了一些改变，写入相应的缓存中而不是直接写入内存，大多数缓存都是CPU核心的本地缓存，但是由一个CPU写入的缓存对其他CPU是不可见的。为了让本地缓存的变化对其他CPU或者线程可见的话，缓存必须进行交互。&lt;/p&gt;

&lt;p&gt;在JVM上，我们必须使用volatile标识或者Atomic包装类来保证内存对跨线程的共享，否则，我们只能用锁来保证共享内存的正确性。那么我们为什么不在所有的变量上都加volatile标识呢？因为在缓存间交互信息是一个代价非常昂贵的操作，而且这个操作会隐式的阻止CPU核心不能去做其他的工作，并且会导致缓存一致性协议（缓存一致性协议是指CPU用于在主内存和其他CPU之间传输缓存）的瓶颈。&lt;/p&gt;

&lt;p&gt;即使开发者认识到这些问题，弄清楚哪些内存位置需要使用volatile标识或者Atomic包装类，但这并非是一种很好的解决方案，可能到程序后期，你都不清楚自己做了什么。&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;没有真正的共享内存了，CPU核心就像网络上的计算机一样，将数据块（高速缓存行）明确地传递给彼此。CPU间的通信和网络通信有更多的共同点。 现在通过CPU或网络计算机传递消息是标准的。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用共享内存标识或者Atomic数据结构来代替隐藏消息传递，其实有一种更加规范的方法就是将共享状态保存在并发实体内，并明确并发实体间通过消息来传递事件和数据。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;调用堆栈的弊端&lt;/h3&gt;

&lt;p&gt;今天，我们还经常调用堆栈来进行任务执行，但是它是在并发并不那么重要的时代发明的，因为当时多核的CPU系统并不常见。调用堆栈不能跨线程，所以不能进行异步调用。&lt;/p&gt;

&lt;p&gt;线程在将任务委托后台执行会出现一个问题，实际中，是将任务委托给另一个线程执行，这不是简单的方法调用，而是有本地的线程直接调用执行，通常来说，一个调用者线程将任务添加到一个内存位置中，具体的工作线程可以不断的从中选取任务进行执行，这样的话，调用者线程不必阻塞可以去做一些其他的任务了。&lt;/p&gt;

&lt;p&gt;但是这里有几个问题，第一个就是调用者如何受到任务完成的通知？还有一个更重要的问题是当任务发生异常出现错误后，异常会被谁处理？异常将会被具体执行任务的工作线程所处理并不会关心是哪个调用者调用的任务：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/exception-prop.png&quot; alt=&quot;exception prop&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是一个很严重的问题，具体执行任务的线程是怎么处理这种状况的？具体执行任务去处理这个问题并不是一个好的方案，因为它并不清楚该任务执行的真正目的，而且调用者应该被通知发生了什么，但是实际上并没有这样的结构去解决这个问题。假如并不能正确的通知，调用者线程将不会的到任何错误的信息甚至任务都会丢失。这就好比在网络上你的请求失败或者消息丢失却得不到任何的通知。&lt;/p&gt;

&lt;p&gt;在某些情况，这个问题可能会变得更糟糕，工作线程发生了错误但是其自身却无法恢复。比如一个由bug引起的内部错误导致了线程的关闭，那么会导致一个问题，到底应该由谁来重启线程并且保存线程之前的状态呢？表面上看，这个问题是可以解决的，但又会有一个新的意外可能发生，当工作线程正在执行任务的时候，它便不能共享任务队列，而事实上，当一个异常发生后，并逐级上传，最终可能导致整个任务队列的状态全部丢失。所以说即使我们在本地交互也可能存在消息丢失的情况。&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;实现任何一个高并发且高效性能的系统，线程必须将任务有效率的委托给别的线程执行以至不会阻塞，这种任务委托的并发方式在分布式的环境也适用，但是需要引入错误处理和失败通知等机制。失败成为这种领域模型的一部分。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;并发系统适用任务委托机制需要去处理服务故障也就意味需要在发生故障后去恢复服务，但实际情况下，重启服务可能会丢失消息，即使没有发生这种情况，调用者得到的回应也可能因为队列等待，垃圾回收等影响而延迟，所以，在真正的环境中，我们需要设置请求回复的超时时间，就像在网络系统亦或者分布式系统。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;为什么在高并发，分布式系统需要Actor模型？&lt;/h2&gt;

&lt;p&gt;综上所述，通常的编程模型并不适用现代的高并发分布式系统，幸运的是，我们可以不必抛弃我们了解的知识，另外，Actor用很好的方式帮我们克服了这些问题，它让我们以一种更好的模型去实现我们的系统。&lt;/p&gt;

&lt;p&gt;我们重点需求的是以下几个方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用封装，但是不使用锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;构建一种实体能够处理消息，更改状态，发送消息用来推动整个程序运行。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;不必担心程序执行与真实环境的不匹配。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Actor模型能帮我们实现这些目标，以下是具体描述。&lt;/p&gt;

&lt;h3&gt;使用消息机制避免使用锁以防止阻塞&lt;/h3&gt;

&lt;p&gt;不同于方法调用，Actor模型使用消息进行交互。发送消息的方式不会将发送消息方的执行线程转换为具体的任务执行线程。Actor可以不断的发送和接收消息但不会阻塞。因此它可以做更多的工作，比如发送消息和接收消息。&lt;/p&gt;

&lt;p&gt;在面对对象编程上，直到一个方法返回后，才会释放对调用者线程的控制。在这这一方面上，Actor模型跟面对对象模型类似，它对消息做出处理，并在消息处理完成后返回执行。我们可以模拟这种执行模式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/actor-graph.png&quot; alt=&quot;actor graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是这种方式与方法调用方式最大的区别就是没有返回值。通过发送消息，Actor将任务委托给另一Actor执行。就想我们之前说的堆栈调用一样，加入你需要一个返回值，那么发送Actor需要阻塞或者与具体执行任务的Actor在同一个线程中。另外，接收Actor以消息的方式返回结果。&lt;/p&gt;

&lt;p&gt;第二个关键的变化是继续保持封装。Actor对消息处理就就跟调用方法一样，但是不同的是，Actor在多线程的情况下能保证自身内部的状态和变量不会被破坏，Actor的执行独立于发送消息的Actor，并且同一个Actor在同一个时刻只处理一个消息。每个Actor有序的处理接收的消息，所以一个Actor系统中多个Actor可以并发的处理自己的消息，充分的利用多核CPU。因为一个Actor同一时刻最多处理一个消息，所以它不需要同步机制保障变量的一致性。所以说它并不需要锁：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/serialized-timeline-invariants.png&quot; alt=&quot;serialized timeline invariants&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总而言之，Actor执行的时候会发生以下行为：&lt;/p&gt;

&lt;p&gt;1.Actor将消息加入到消息队列的尾部。
2.假如一个Actor并未被调度执行，则将其标记为可执行。
3.一个（对外部不可见）调度器对Actor的执行进行调度。
4.Actor从消息队列头部选择一个消息进行处理。
5.Actor在处理过程中修改自身的状态，并发送消息给其他的Actor。
6.Actor&lt;/p&gt;

&lt;p&gt;为了实现这些行为，Actor必须有以下特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;邮箱（作为一个消息队列）&lt;/li&gt;
&lt;li&gt;行为（作为Actor的内部状态，处理消息逻辑）&lt;/li&gt;
&lt;li&gt;消息（请求Actor的数据，可看成方法调用时的参数数据）&lt;/li&gt;
&lt;li&gt;执行环境（比如线程池，调度器，消息分发机制等）&lt;/li&gt;
&lt;li&gt;位置信息（用于后续可能会发生的行为）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;消息会被添加到Actor的信箱中，Actor的行为可以看成Actor是如何对消息做出回应的（比如发送更多消息或者修改自身状态）。执行环境提供一组线程池，用于执行Actor的这些行为操作。&lt;/p&gt;

&lt;p&gt;Actor是一个非常简单的模型而且它可以解决先前提到的问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;继续使用封装，但通过信号机制保障不需传递执行（方法调用需要传递执行线程，但发送消息不需要）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;不需要任何的锁，修改Actor内部的状态只能通过消息，Actor是串行处理消息，可以保障内部状态和变量的正确性。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;因为不会再任何地方使用锁，所以发送者不会被阻塞，成千上万个Actor可以被合理的分配在几十个线程上执行，充分利用了现代CPU的潜力。任务委托这个模式在Actor上非常适用。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Actor的状态是本地的，不可共享的，变化和数据只能通过消息传递。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Actor优雅的处理错误&lt;/h3&gt;

&lt;p&gt;Actor不再使用共享的堆栈调用，所以它要以不同的方式去处理错误。这里有两种错误需要考虑：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;第一种情况是当任务委托后再目标Actor上由于任务本身错误而失败了（典型的如验证错误，比如不存在的用户ID）。在这个情况下，Actor服务本身是正确的，只是相应的任务出错了。服务Actor应该想发送Actor发送消息，已告知错误情况。这里没什么特殊的，错误作为Actor模型的一部分，也可以当做消息。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;第二种情况是当服务本身遇到内部故障时。Akka强制所有Actor被组织成一个树状的层次结构，即创建另一个Actor的Actor成为该新Actor的分级。 这与操作系统将流程组合到树中非常相似。就像进程一样，当一个Actor失败时，它的父actor被通知，并对失败做出反应。此外，如果父actor停止，其所有子Actor也被递归停止。这中形式被称为监督，它是Akka的核心：&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/actor-tree-supervision.png&quot; alt=&quot;actor tree supervision&quot; /&gt;&lt;/p&gt;

&lt;p&gt;监管者可以根据被监管者（子Actor）的失败的错误类型来执行不同的策略，比如重启该Actor或者停止该Actor让其它Actor代替执行任务。一个Actor不会无缘无故的死亡（除非出现死循环之类的情况），而是失败，并可以将失败传递给它的监管者让其做出相应的故障处理策略，当然也可能会被停止（若被停止，也会接收到相应的消息指令）。一个Actor总有监管者就是它的父级Actor。Actor重新启动是不可见的，协作Actor可以帮其代发消息直到目标Actor重启成功。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（五）：Java和Scala中的Future</title>
   <link href="/2017/05/15/learning-akka-5.html"/>
   <updated>2017-05-15T00:00:00+08:00</updated>
   <id>urn:uuid:85cf4b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;随着CPU的核数的增加，异步编程模型在并发领域中的得到了越来越多的应用，由于Scala是一门函数式语言，天然的支持异步编程模型，今天主要来看一下Java和Scala中的Futrue，带你走入异步编程的大门。&lt;/p&gt;

&lt;h2&gt;Future&lt;/h2&gt;

&lt;p&gt;很多同学可能会有疑问，Futrue跟异步编程有什么关系？从Future的表面意思是未来，一个Future对象可以看出一个将来得到的结果，这就和异步执行的概念很像，你只管自己去执行，只要将最终的结果传达给我就行，线程不必一直暂停等待结果，可以在具体异步任务执行的时候去执行其他操作，举个例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/async-work.png&quot; alt=&quot;async work&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们现在在执行做饭这么一个任务，它需要煮饭，烧菜，摆置餐具等操作，如果我们通过异步这种概念去执行这个任务，比如煮饭可能需要比较久的时间，但煮饭这个过程又不需要我们管理，我们可以利用这段时间去烧菜，烧菜过程中也可能有空闲时间，我们可以去摆置餐具，当电饭锅通知我们饭烧好了，菜也烧好了，最后我们就可以开始吃饭了，所以说，上面的“&lt;strong&gt;煮饭 -&gt; 饭&lt;/strong&gt;”，“&lt;strong&gt;烧菜 -&gt; 菜&lt;/strong&gt;”都可以看成一个Future的过程。&lt;/p&gt;

&lt;h3&gt;Java中的Future&lt;/h3&gt;

&lt;p&gt;在Java的早期版本中，我们不能得到线程的执行结果，不管是继承Thread类还是实现Runnable接口，都无法获取线程的执行结果，所以我们只能在线程执行的run方法里去做相应的一些业务逻辑操作，但随着Java5的发布，它为了我们带来了Callable和Future接口，我们可以利用这两个接口的特性来获取线程的执行结果。&lt;/p&gt;

&lt;h4&gt;Callable接口&lt;/h4&gt;

&lt;p&gt;通俗的讲，Callable接口也是一个线程执行类接口，那么它跟Runnable接口有什么区别呢？我们先来看看它们两个的定义：&lt;/p&gt;

&lt;p&gt;1.Callable接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;@FunctionalInterface
public interface Callable&amp;lt;V&amp;gt; {
    /**
     * Computes a result, or throws an exception if unable to do so.
     *
     * @return computed result
     * @throws Exception if unable to compute a result
     */
    V call() throws Exception;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.Runnable接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;@FunctionalInterface
public interface Runnable {
    public abstract void run();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的定义，我们可以看出，两者最大的区别就是对应的执行方法是否有返回值。Callable接口中call方法具有返回值，这便是为什么我们可以通过Callable接口来得到一个线程执行的返回值或者是异常信息。&lt;/p&gt;

&lt;h4&gt;Future接口&lt;/h4&gt;

&lt;p&gt;上面说到既然Callable接口能返回线程执行的结果，那么为什么还需要Future接口呢？因为Callable接口执行的结果只是一个将来的结果值，我们若是需要得到具体的结果就必须利用Future接口，另外Callable接口需要委托ExecutorService的submit提交任务去执行，我们来看看它是如何定义的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt; &amp;lt;T&amp;gt; Future&amp;lt;T&amp;gt; submit(Callable&amp;lt;T&amp;gt; task);

 public &amp;lt;T&amp;gt; Future&amp;lt;T&amp;gt; submit(Callable&amp;lt;T&amp;gt; task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture&amp;lt;T&amp;gt; ftask = newTaskFor(task);
        execute(ftask);
        return ftask;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从submit的方法定义也可以看出它的返回值是一个Future接口类型的值，这里其实是RunnableFuture接口，这是一个很重要的接口，我们来看一下它的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public interface RunnableFuture&amp;lt;V&amp;gt; extends Runnable, Future&amp;lt;V&amp;gt; {
    /**
     * Sets this Future to the result of its computation
     * unless it has been cancelled.
     */
    void run();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个接口分别继承了Runnable和Future接口，而FutureTask又实现了RunnableFuture接口，它们之间的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/future-runnable.png&quot; alt=&quot;future runnable&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RunnableFuture有以下两个特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;继承Runnable接口，还是以run方法作为线程执行入口，其实上面submit方法的具体实现也可以看出，一个Callable的Task再执行的时候会被包装成RunnableFuture，然后以FutureTask作为实现类，执行FutureTask时，还是执行其的run方法，只不过run方法里面的业务逻辑是由我们定义的call方法的内容，当然再执行run方法时，程序会自动将call方法的执行结果帮我们包装起来，对外部表现成一个Future对象。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;继承Future接口，通过实现Future接口中的方法更新或者获取线程的的执行状态，比如其中的cancel(),isDone(),get()等方法。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Future程序示例与结果获取&lt;/h4&gt;

&lt;p&gt;下面是一个简单的Future示例，我们先来看一下代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;ExecutorService es = Executors.newSingleThreadExecutor();
Future f = es.submit(() -&amp;gt; {
        System.out.println(&quot;execute call&quot;);
        Thread.sleep(1000);
        return 5;
    });
try {
    System.out.println(f.isDone()); //检测任务是否完成
    System.out.println(f.get(2000, TimeUnit.MILLISECONDS));
    System.out.println(f.isDone()); //检测任务是否完成
} catch (InterruptedException e) {
    e.printStackTrace();
} catch (ExecutionException e) {
    e.printStackTrace();
} catch (TimeoutException e) {
    e.printStackTrace();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码使用了lambda表达式，有兴趣的同学可以自己去了解下，这里我们首先构建了一个ExecutorService，然后利用submit提交执行Callable接口的任务。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么是Callable接口呢？&lt;/strong&gt; 其实这里我们并没有显示声明Callable接口，这里lambda会帮我们自动进行类型推导，首先submit接受Callable接口或Runnble接口类型作为参数，而这里我们又给定了返回值，所以lambda能自动帮我们推导出内部是一个Callable接口参数。&lt;/p&gt;

&lt;p&gt;到这里我们应该大致清楚了在Java中的得到Future，那么我们又是如何从Future中得到我们想要的值呢？这个结论其实很容易得出，你只需要去跑一下上面的程序即可，在利用get去获取Future中的值时，线程会一直阻塞，直到返回值或者超时，所以Future中的get方法是阻塞，所以虽然利用Future似乎是异步执行任务，但是在某些需求上还是会阻塞的，并不是真正的异步，stackoverflow上有两个讨论说明了这个问题&lt;a href=&quot;http://stackoverflow.com/questions/31092067/method-call-to-future-get-blocks-is-that-really-desirable&quot;&gt;Future.get&lt;/a&gt;，&lt;a href=&quot;http://stackoverflow.com/questions/31092067/method-call-to-future-get-blocks-is-that-really-desirable&quot;&gt;without blocking when task complete&lt;/a&gt;，有兴趣的同学可以去看看。&lt;/p&gt;

&lt;h3&gt;Scala中的Future&lt;/h3&gt;

&lt;p&gt;Scala中的Future相对于Java的Future有什么不同呢？我总结了一下几点：&lt;/p&gt;

&lt;h4&gt;1.创建Future变得很容易&lt;/h4&gt;

&lt;p&gt;异步编程作为函数式语言的一大优势，Scala对于Future的支持也是非常棒的，首先它也提供了Futrue接口，但不同的是我们在构建Future对象是不用像Java一样那么繁琐，并且非常简单，举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;import scala.concurrent._ 
import ExecutionContext.Implicits.global 

val f: Future[String] = Future { &quot;Hello World!&quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是不是非常简单，也大大降低了我们使用Future的难度。&lt;/p&gt;

&lt;h4&gt;2.提供真正异步的Future&lt;/h4&gt;

&lt;p&gt;前面我们也说到，Java中的Future并不是全异步的，当你需要Future里的值的时候，你只能用get去获取它，亦或者不断访问Future的状态，若完成再去取值，但其意义上便不是真正的异步了，它在获取值的时候是一个阻塞的操作，当然也就无法执行其他的操作，直到结果返回。&lt;/p&gt;

&lt;p&gt;但在Scala中，我们无需担心，虽然它也提供了类似Java中获取值的方式，比如：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Future        &lt;/th&gt;
&lt;th style=&quot;text-align:center;&quot;&gt; Java          &lt;/th&gt;
&lt;th style=&quot;text-align:right;&quot;&gt; Scala  &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; 判断任务是否完成 &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; isDone        &lt;/td&gt;
&lt;td style=&quot;text-align:right;&quot;&gt; isCompleted &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; 获取值          &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; get          &lt;/td&gt;
&lt;td style=&quot;text-align:right;&quot;&gt;   value &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;但是我们并不推荐这么做，因为这么做又回到了Java的老路上了，在Scala中我们可以利用Callback来获取它的结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val fut = Future {
    Thread.sleep(1000)
    1 + 1
}

fut onComplete {
    case Success(r) =&amp;gt; println(s&quot;the result is ${r}&quot;)
    case _ =&amp;gt; println(&quot;some Exception&quot;)
}

println(&quot;I am working&quot;)
Thread.sleep(2000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是一个简单的例子，Future在执行完任务后会进行回调，这里使用了onComplete，也可以注册多个回调函数，但不推荐那么做，因为你不能保证这些回调函数的执行顺序，其他的一些回调函数基本都是基于onComplete的，有兴趣的同学可以去阅读一下Future的源码。&lt;/p&gt;

&lt;p&gt;我们先来看一下它的运行结果:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;I am working
the result is 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从结果中我们可以分析得出，我们在利用Callback方式来获取Future结果的时候并不会阻塞，而只是当Future完成后会自动调用onComplete，我们只需要根据它的结果再做处理即可，而其他互不依赖的操作可以继续执行不会阻塞。&lt;/p&gt;

&lt;h4&gt;3.强大的Future组合&lt;/h4&gt;

&lt;p&gt;前面我们讲的较多的都是单个Future的情况，但是在真正实际应用时往往会遇到多个Future的情况，那么在Scala中是如何处理这种情况的呢？&lt;/p&gt;

&lt;p&gt;Scala中的有多种方式来组合Future,那我们就来看看这些方式吧。&lt;/p&gt;

&lt;h5&gt;1.flatMap&lt;/h5&gt;

&lt;p&gt;我们可以利用flatMap来组合多个Future，不多说，先上代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val fut1 = Future {
  println(&quot;enter task1&quot;)
  Thread.sleep(2000)
  1 + 1
}

val fut2 = Future {
  println(&quot;enter task2&quot;)
  Thread.sleep(1000)
  2 + 2
}

fut1.flatMap { v1 =&amp;gt;
  fut2.map { v2 =&amp;gt;
    println(s&quot;the result is ${v1 + v2}&quot;)
  }
}
Thread.sleep(2500)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;利用flatMap确实能组合Future，但代码的阅读性实在是有点差，你能想象5个甚至10个map层层套着么，所以我们并不推荐这么做，但是我们需要了解这种方式，其他简洁的方式可能最终转化成的版本也许就是这样的。&lt;/p&gt;

&lt;h5&gt;2.for yield表达式&lt;/h5&gt;

&lt;p&gt;我们只是把上面关于flatMap的代码替换一下，看下面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;for {
  v1 &amp;lt;- fut1
  v2 &amp;lt;- fut2
} yield println(s&quot;the result is ${v1 + v2}&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看上去是不是比之前的方式简洁多了，这也是我们在面对Future组合时推荐的方式，当然不得不说for yield表达式是一种语法糖，它最终还是会被翻译成我们常见的方法，比如flatMap，map，filter等，感兴趣的可以参考它的官方文档。&lt;a href=&quot;http://docs.scala-lang.org/tutorials/FAQ/yield.html&quot;&gt;for yield表达式&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;3.scala-async&lt;/h5&gt;

&lt;p&gt;另外我们可以用scala-async来组装Futrue语句块，示例如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;import scala.async.Async.{async, await}

val v1 = async {
  await(fut1) + await(fut2)
}

v1 foreach {
  case r =&amp;gt; println(s&quot;the result is ${v1}&quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种方式与for yield表达式有啥区别呢？其实主要有两点：
- 表达语意更加清晰，不需要用为中间值命名
- 不需要&lt;code&gt;&amp;lt;-&lt;/code&gt;等表达式，可减少一定的代码量&lt;/p&gt;

&lt;p&gt;scala-async相关的具体信息可以参考它的项目主页。&lt;a href=&quot;https://github.com/scala/async&quot;&gt;scala-async&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;总的来说Scala中的Future确实强大，在实现真正异步的情况下，为我们提供许多方便而又简洁的操作模式，其实比如还有Future.reduce()，Future.traverse(),Future.sequence()等方法，这些方法的具体功能和具体使用这里就不讲了，但相关的示例代码都会在我的示例工程里，有兴趣的同学可以去跑跑加深理解。&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_04&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;这篇文章主要讲解了JVM生态上两大语言Java和Scala在异步编程上的一些表现，这里主要是Future机制，在清楚明白它的概念后，我们才能写出更好的程序，虽然本篇文章没有涉及到Akka相关的内容，但是Akka本身是用Scala写的，而且大量使用了Scala中的Future，相信通过对Future的学习，对Akka的理解会有一定的帮助。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（四）：Akka中的共享内存模型</title>
   <link href="/2017/05/01/learning-akka-4.html"/>
   <updated>2017-05-01T00:00:00+08:00</updated>
   <id>urn:uuid:8ecf4b63-e920-3d54-8ca7-fbvbdc2a2fad</id>
   <content type="html">&lt;p&gt;通过前几篇的学习，相信大家对Akka应该有所了解了，都说解决并发哪家强，JVM上面找Akka，那么Akka到底在解决并发问题上帮我们做了什么呢？&lt;/p&gt;

&lt;h2&gt;共享内存&lt;/h2&gt;

&lt;p&gt;众所周知，在处理并发问题上面，最核心的一部分就是如何处理共享内存，很多时候我们都需要花费很多时间和精力在共享内存上，那么在学习Akka对共享内存是如何管理之前，我们先来看看Java中是怎么处理这个问题的。&lt;/p&gt;

&lt;h3&gt;Java共享内存&lt;/h3&gt;

&lt;p&gt;相信对Java并发有所了解的同学都应该知道在Java5推出JSR 133后，Java对内存管理有了更高标准的规范了，这使我们开发并发程序也有更好的标准了，不会有一些模糊的定义导致的无法确定的错误。&lt;/p&gt;

&lt;p&gt;首先来看看一下Java内存模型的简单构图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/java-memory.png&quot; alt=&quot;Java Memory&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从图中我们可以看到我们线程都有自己的一个工作内存，这就好比高速缓存，它是对主内存部分数据的拷贝，线程对自己工作内存的操作速度远远快于对主内存的操作，但这也往往会引起共享变量不一致的问题，比如以下一个场景：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;int a = 0;
public void setA() {
  a = a + 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面是一个很简单的例子，a是一个全局变量，然后我们有一个方法去修改这个值，每次增加一，假如我们用100个线程去运行这段代码，那a最终的结果会是多少呢？
100？显然不一定，它可能是80，90，或者其他数，这就造成共享变量不一致的问题，那么为什么会导致这个问题呢，就是我们上面所说的，线程去修改a的时候可能就只是修改了自己工作内存中a的副本，但并没有将a的值及时的刷新到主内存中，这便会导致其他线程可能读到未被修改a的值，最终出现变量不一致问题。&lt;/p&gt;

&lt;p&gt;那么Java中是怎么处理这种问题，如何保证共享变量的一致性的呢？&lt;/p&gt;

&lt;h4&gt;同步机制&lt;/h4&gt;

&lt;p&gt;大体上Java中有3类同步机制，但它们所解决的问题并不相同，我们先来看一看这三种机制：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;final关键词&lt;/li&gt;
&lt;li&gt;volatile关键词&lt;/li&gt;
&lt;li&gt;synchronized关键词（这里代表了所有类似监视锁的机制）&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;1.final关键词&lt;/h5&gt;

&lt;p&gt;写过Java程序的同学对这个关键词应该再熟悉不过了，其基本含义就是&lt;strong&gt;不可变&lt;/strong&gt;，不可变变量，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;final int a = 10;
final String b = &quot;hello&quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不可变的含义在于当你对这些变量或者对象赋初值后，不能再重新去赋值，但对于对象来说，我们不能修改的是它的引用，但是对象内的内容还是可以修改的。下面是一个简单的例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;final User u = new User(1,&quot;a&quot;);
u.id = 2; //可以修改
u = new User(2,&quot;b&quot;); //不可修改
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以在利用final关键词用来保证共享变量的一致性时一定要了解清楚自己的需求，选择合适的方法，另外final变量必须在定义或者构建对象的时候进行初始化，不然会报错。&lt;/p&gt;

&lt;h4&gt;2.volatile关键词&lt;/h4&gt;

&lt;p&gt;很多同学在遇到共享变量不一致的问题后，都会说我在声明变量前加一个volatile就好了，但事实真是这样嘛？答案显然不是。那我们来看看volatile到底为我们做了什么。&lt;/p&gt;

&lt;p&gt;前面我们说过每个线程都有自己的工作内存，很多时候线程去修改一个变量的值只是修改了自己工作内存中副本的值，这便会导致主内存的值并不是最新的，其他线程读取到的变量便会出现问题。volatile帮我们解决了这个问题，它有两个特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;线程每次都会去主内存中读取变量&lt;/li&gt;
&lt;li&gt;线程每次修改变量后的值都会及时更新到主内存中去&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;volatile int a = 0;
public void setA() {
  a = a + 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在线程在执行这段代码时，都会强制去主内存中读取变量的值，修改后也会马上更新到主内存中去，但是这真的能解决共享变量不一致的问题嘛，其实不然，比如我们有这么一个场景：两个线程同时读取了主内存中变量最新的值，这是我们两个线程都去执行修改操作，最后结果会是什么呢？这里就留给大家自己去思考了，其实也很简单的。&lt;/p&gt;

&lt;p&gt;那么volatile在什么场景下能保证线程安全，按照官方来说，有以下两个条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对变量的写操作不依赖于当前值&lt;/li&gt;
&lt;li&gt;该变量没有包含在具有其他变量的不变式中&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;多的方面这里我就不展开了，推荐两篇我觉得写的还不错的文章：&lt;a href=&quot;http://www.cnblogs.com/paddix/p/5428507.html&quot;&gt;volatile的使用及其原理&lt;/a&gt;&lt;a href=&quot;http://blog.csdn.net/vking_wang/article/details/9982709&quot;&gt;volatile的适用场景&lt;/a&gt;&lt;/p&gt;

&lt;h4&gt;3.synchronized关键词&lt;/h4&gt;

&lt;p&gt;很多同学在学习Java并发过程中最先接触的就是synchronized关键词了，它确实能解决我们上述的并发问题，那它到时如何帮我们保证共享变量的一致性的呢？&lt;/p&gt;

&lt;p&gt;简而言之的说，线程在访问请求用synchronized关键词修饰的方法，代码块都会要求获得一个监视器锁，当线程获得了监视器锁后，它才有权限去执行相应的方法或代码块，并在执行结束后释放监视器锁，这便能保证共享内存的一致性了，因为本文主要是讲Akka的共享内存，过多的篇幅就不展开了，这里推荐一篇解析synchronized原理很不错的文章，有兴趣的同学可以去看看：&lt;a href=&quot;http://www.cnblogs.com/paddix/p/5367116.html&quot;&gt;Synchronized及其实现原理&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Akka共享内存&lt;/h3&gt;

&lt;p&gt;Akka中的共享内存是基于Actor模型的，Actor模型提倡的是：&lt;strong&gt;通过通讯来实现共享内存，而不是用共享内存来实现通讯&lt;/strong&gt;，这点是跟Java解决共享内存最大的区别，举个例子：
在Java中我们要去操作共享内存中数据时，每个线程都需要不断的获取共享内存的监视器锁，然后将操作后的数据暴露给其他线程访问使用，用共享内存来实现各个线程之间的通讯，而在Akka中我们可以将共享可变的变量作为一个Actor内部的状态，利用Actor模型本身串行处理消息的机制来保证变量的一致性。&lt;/p&gt;

&lt;p&gt;当然要使用Akka中的机制也必须满足一下两条原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;消息的发送必须先于消息的接收&lt;/li&gt;
&lt;li&gt;同一个Actor对一条消息的处理先于下一条消息处理&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;第二个原则很好理解，就是上面我们说的Actor内部是串行处理消息，那我们来看看第一个原则，为什么要保证消息的发送先于消息的接收，是为了防止我们在创建消息的时候发生了不确定的错误，接收者将可能接收到不正确的消息，导致发生奇怪的异常，主要表现为消息对象未初始化完整时，若没有这条规则保证，Actor收到的消息便会不完整。&lt;/p&gt;

&lt;p&gt;通过前面的学习我们知道Actor是一种比线程更轻量级，抽象程度更高的一种结构，它帮我们规避了我们自己去操作线程，那么Akka底层到底是怎么帮我们去保证共享内存的一致性的呢？&lt;/p&gt;

&lt;p&gt;一个Actor它可能会有很多线程同时向它发送消息，之前我们也说到Actor本身是串行处理的消息的，那它是如何保障这种机制的呢？&lt;/p&gt;

&lt;h4&gt;Mailbox&lt;/h4&gt;

&lt;p&gt;Mailbox在Actor模型是一个很重要的概念，我们都知道向一个Actor发送的消息首先都会被存储到它所对应的Mailbox中，那么我们先来看看MailBox的定义结构(本文所引用的代码都在akka.dispatch.Mailbox.scala中，有兴趣的同学也可以去研究一下）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;private[akka] abstract class Mailbox(val messageQueue: MessageQueue)
  extends ForkJoinTask[Unit] with SystemMessageQueue with Runnable {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很清晰Mailbox内部维护了一个messageQueue这样的消息队列，并继承了Scala自身定义的ForkJoinTask任务执行类和我们很熟悉的Runnable接口，由此可以看出，Mailbox底层还是利用Java中的线程进行处理的。那么我们先来看看它的run方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;override final def run(): Unit = {
    try {
      if (!isClosed) { //Volatile read, needed here
        processAllSystemMessages() //First, deal with any system messages
        processMailbox() //Then deal with messages
      }
    } finally {
      setAsIdle() //Volatile write, needed here
      dispatcher.registerForExecution(this, false, false)
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了配合理解，我们这里先来看一下定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@inline
  final def currentStatus: Mailbox.Status = Unsafe.instance.getIntVolatile(this, AbstractMailbox.mailboxStatusOffset)

@inline
  final def isClosed: Boolean = currentStatus == Closed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里我们可以看出Mailbox本身会维护一个状态Mailbox.Status，是一个Int变量,而且是可变的，并且用到volatile来保证了它的可见性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@volatile
  protected var _statusDoNotCallMeDirectly: Status = _ //0 by default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们在回去看上面的代码，run方法的执行过程，首先它会去读取MailBox此时的状态，因为是一个Volatile read，所以能保证读取到的是最新的值，然后它会先处理任何的系统消息，这部分不需要我们太过关心，之后便是执行我们发送的消息，这里我们需要详细看一下processMailbox()的实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
@tailrec private final def processMailbox(
    left:       Int  = java.lang.Math.max(dispatcher.throughput, 1),
    deadlineNs: Long = if (dispatcher.isThroughputDeadlineTimeDefined == true) System.nanoTime + dispatcher.throughputDeadlineTime.toNanos else 0L): Unit =
    if (shouldProcessMessage) {
      val next = dequeue()  //去出下一条消息
      if (next ne null) {
        if (Mailbox.debug) println(actor.self + &quot; processing message &quot; + next)
        actor invoke next
        if (Thread.interrupted())
          throw new InterruptedException(&quot;Interrupted while processing actor messages&quot;)
        processAllSystemMessages()
        if ((left &amp;gt; 1) &amp;amp;&amp;amp; ((dispatcher.isThroughputDeadlineTimeDefined == false) || (System.nanoTime - deadlineNs) &amp;lt; 0))
          processMailbox(left - 1, deadlineNs) //递归处理下一条消息
      }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上述代码中我们可以清晰的看到，当满足消息处理的情况下就会进行消息处理，从消息队列列取出下一条消息就是上面的&lt;code&gt;dequeue()&lt;/code&gt;,然后将消息发给具体的Actor进行处理，接下去又是处理系统消息，然后判断是否还有满足情况需要下一条消息，若有则再次进行处理，可以看成一个递归操作,&lt;code&gt;@tailrec&lt;/code&gt;也说明了这一点，它表示的是让编译器进行尾递归优化。&lt;/p&gt;

&lt;p&gt;现在我们来看一下一条消息从发送到最终处理在Akka中到底是怎么执行的，下面的内容是我通过阅读Akka源码加自身理解得出的，这里先画了一张流程图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/actor-process.png&quot; alt=&quot;Actor process&quot; /&gt;&lt;/p&gt;

&lt;p&gt;消息的大致流程我都在图中给出，还有一些细节，必须序列化消息，获取状态等就没有具体说明了，有兴趣的同学可以自己去阅读以下Akka的源码，个人觉得Akka的源码阅读性还是很好的，比如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;基本没有方法超过20行&lt;/li&gt;
&lt;li&gt;不会有过多的注释，但关键部分会给出，更能加深自己的理解&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;当然也有一些困扰，我们在不了解各个类，接口之间的关系时，阅读体验就会变得很糟糕，当然我用IDEA很快就解决了这个问题。&lt;/p&gt;

&lt;p&gt;我们这里来看看关键的部分：&lt;strong&gt;Actor是如何保证串行处理消息的？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上图中有一根判定，是否已有线程在执行任务？我们来看看这个判定的具体逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@tailrec
  final def setAsScheduled(): Boolean = {  //是否有线程正在调度执行该MailBox的任务
    val s = currentStatus
    /*
     * Only try to add Scheduled bit if pure Open/Suspended, not Closed or with
     * Scheduled bit already set.
     */
    if ((s &amp;amp; shouldScheduleMask) != Open) false
    else updateStatus(s, s | Scheduled) || setAsScheduled()
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从注释和代码的逻辑上我们可以看出当已有线程在执行返回false，若没有则去更改状态为以调度，直到被其他线程抢占或者更改成功，其中updateStatus()是线程安全的，我们可以看一下它的实现,是一个CAS操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@inline
  protected final def updateStatus(oldStatus: Status, newStatus: Status): Boolean =
    Unsafe.instance.compareAndSwapInt(this, AbstractMailbox.mailboxStatusOffset, oldStatus, newStatus)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里我们应该可以大致清楚Actor内部是如何保证共享内存的一致性了，Actor接收消息是多线程的，但处理消息是单线程的，利用MailBox中的Status来保障这一机制。&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;通过上面的内容我们可以总结出以下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Akka并不是说用了什么特殊魔法来保证并发的，底层使用的还是Java和JVM的同步机制&lt;/li&gt;
&lt;li&gt;Akka并没有使用任何的锁机制，这就避免了死锁的可能性&lt;/li&gt;
&lt;li&gt;Akka并发执行的处理并没有使用线程切换，不仅提高了线程的使用效率，也大大减少了线程切换消耗&lt;/li&gt;
&lt;li&gt;Akka为我们提供了更高层次的并发抽象模型，让我们不必关心底层的实现，只需着重实现业务逻辑就行，遵循它的规范，让框架帮我们处理一切难点&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 
</feed>
