<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>泮</title>
 <link href="/atom.xml" rel="self"/>
 <link href=""/>
 <updated>2017-09-28T12:58:33+08:00</updated>
 <id>/</id>
 <author>
   <name></name>
 </author>

 
 <entry>
   <title>Akka系列（十）：Akka集群之Akka Cluster</title>
   <link href="/2017/09/05/learning-akka-10.html"/>
   <updated>2017-09-05T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;上一篇文章我们讲了Akka Remote，理解了Akka中的远程通信，其实Akka Cluster可以看成Akka Remote的扩展，由原来的两点变成由多点组成的通信网络，这种模式相信大家都很了解，就是集群，它的优势主要有两点：系统伸缩性高，容错性更好。&lt;/p&gt;

&lt;h3&gt;集群概念&lt;/h3&gt;

&lt;p&gt;很多人很容易把分布式和集群的概念搞错，包括我也是，我一开始也以为它们两个是一样的概念，只是叫法不同而已，但其实不然，虽然它们在实际场景中都是部署在不同的机器上，但它们所提供的功能并不是一样的。举个简单的例子来看看它们之间的不同：&lt;/p&gt;

&lt;p&gt;为了保持整个系列连续性，我又以抽奖为基础举一个例子：&lt;/p&gt;

&lt;p&gt;假定我们现在抽奖流程包括，抽奖分配奖品和用户根据链接领取指定奖品，用户先抽奖然后获取奖品链接，点击链接填写相应信息领取奖品。&lt;/p&gt;

&lt;h4&gt;1.分布式：&lt;/h4&gt;

&lt;p&gt;我们现在把抽奖分配奖品和用户根据链接领取指定奖品分别部署在两台机器上，突然有一天很不幸，抽奖活动进行到一半，抽奖分配奖品那台机子所在的区域停电了，很显然，后续的用户参与抽奖就不能进行了，因为我们只有一台抽奖分配奖品的机子，但由于我们将领取奖品的业务部署在另一台机器上，所以前面那些中奖的用户还是可以正常的领取奖品，具体相关定义可参考《分布式系统概念与设计》中对分布式系统的定义。&lt;/p&gt;

&lt;h4&gt;2.集群：&lt;/h4&gt;

&lt;p&gt;现在我们还是有两台机器，但是我们在两个机器上都部署了抽奖分配奖品和用户根据链接领取指定奖品的业务逻辑，突然有一天，有一台所在的区域停电了，但这时我们并担心，因为另一台服务器还是可以正常的运行处理用户的所有请求。&lt;/p&gt;

&lt;p&gt;它们的各自特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分布式：是指在多台不同的服务器中部署不同的服务模块，通过远程调用协同工作，对外提供服务；&lt;/li&gt;
&lt;li&gt;集群：是指在多台不同的服务器中部署相同应用或服务模块，构成一个集群，通过负载均衡设备对外提供服务；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说： 分布式是以分离任务缩短时间来提高效率，而集群是在单位时间内处理更多的任务来提高效率。&lt;/p&gt;

&lt;h3&gt;Akka Cluster&lt;/h3&gt;

&lt;p&gt;在前面的文章Akka Actor的工作方式，我们可以将一个任务分解成一个个小任务，然后分配给它的子Actor执行，其实这就可以看成一个小的分布式系统，那么在Akka中，集群又是一种怎样的概念呢？&lt;/p&gt;

&lt;p&gt;其实往简单里说，就是一些相同的ActorSystem的组合，它们具有着相同的功能，我们需要执行的任务可以随机的分配到目前可用的ActorSystem上，这点跟Nginx的负载均衡很类似，根据算法和配置将请求转发给运行正常的服务器去，Akka集群的表现形式也是这样，当然它背后的理论基础是基于gossip协议的，目前很多分布式的数据库的数据同步都采用这个协议，有兴趣的同学可以自己去研究研究，只是我也是一知半解，这里就不写了，怕误导了大家。&lt;/p&gt;

&lt;p&gt;下面我来讲讲Akka Cluster中比较重要的几个概念：&lt;/p&gt;

&lt;h4&gt;Seed Nodes&lt;/h4&gt;

&lt;p&gt;Seed Nodes可以看过是种子节点或者原始节点，它的一个主要作用用于可以自动接收新加入集群的节点的信息，并与之通信，使用方式可以用配置文件或者运行时指定，推荐使用配置文件方式，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.seed-nodes = [
  &quot;akka.tcp://ClusterSystem@host1:2552&quot;,
  &quot;akka.tcp://ClusterSystem@host2:2552&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;seed-nodes列表中的第一个节点会集群启动的时候初始化，而其他节点则是在有需要时再初始化。&lt;/p&gt;

&lt;p&gt;当然你也可以不指定seed nodes，但你可以需要手动或者在程序中写相关逻辑让相应的节点加入集群，具体使用方式可参考官方文档。&lt;/p&gt;

&lt;h4&gt;Cluster Events&lt;/h4&gt;

&lt;p&gt;Cluster Events字面意思是集群事件，那么这是什么意思呢？其实它代表着是一个节点的各种状态和操作，举个例子，假设你在打一局王者5v5的游戏，那么你可以把十个人看成一个集群，我们每个人都是一个节点，我们的任何操作和状态都能被整个系统捕获到，比如A杀了B、A超神了，A离开了游戏，A重新连接了游戏等等，这些状态和操作在Cluster Events中就相当于节点之于集群，那么它具体是怎么使用的呢？&lt;/p&gt;

&lt;p&gt;首先我们必须将节点注册到集群中，或者说节点订阅了某个集群，我们可以这么做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;cluster.subscribe(self, classOf[MemberEvent], classOf[UnreachableMember])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体代码相关的使用我会再下面写一个demo例子，来说明是如何具体使用它们的。&lt;/p&gt;

&lt;p&gt;从上面的代码我们可以看到有一个MemberEvent的概念，这个其实就是每个成员所可能拥有的events，那么一个成员在它的生命周期中有以下的events&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ClusterEvent.MemberJoined - 新的节点加入集群，此时的状态是Joining；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberUp - 新的节点加入集群，此时的状态是Up；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberExited - 节点正在离开集群，此时的状态是Exiting；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberRemoved - 节点已经离开集群，此时的状态是Removed；&lt;/li&gt;
&lt;li&gt;ClusterEvent.UnreachableMember - 节点被标记为不可触达；&lt;/li&gt;
&lt;li&gt;ClusterEvent.ReachableMember - 节点被标记为可触达；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;状态说明：
- Joining: 加入集群的瞬间状态
- Up: 正常服务状态
- Leaving / Exiting: 正常移出中状态
- Down: 被标记为停机（不再是集群决策的一部分）
- Removed: 已从集群中移除&lt;/p&gt;

&lt;h4&gt;Roles&lt;/h4&gt;

&lt;p&gt;虽然上面说到集群中的各个节点的功能是一样的，其实并不一定，比如我们将分布式和集群融合到一起，集群中的一部分节点负责接收请求，一部分用于计算，一部分用于数据存储等等，所以Akka Cluster提供了一种Roles的概念，用来表示该节点的功能特性，我们可以在配置文件中指定,比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.roles = request
akka.cluster.roles = compute
akka.cluster.roles = store
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;ClusterClient&lt;/h4&gt;

&lt;p&gt;ClusterClient是一个集群客户端，主要用于集群外部系统与集群通信，使用它非常方便，我们只需要将集群中的任意指定一个节点作为集群客户端，然后将其注册为一个该集群的接待员，最后我们就可以在外部系统直接与之通信了，使用ClusterClient需要做相应的配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.extensions = [&quot;akka.cluster.client.ClusterClientReceptionist&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假设我们现在我一个接待的Actor，叫做frontend,我们就可以这样做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sacla&quot;&gt;val frontend = system.actorOf(Props[TransformationFrontend], name = &quot;frontend&quot;)
ClusterClientReceptionist(system).registerService(frontend)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Akka Cluster例子&lt;/h3&gt;

&lt;p&gt;上面讲了集群概念和Akka Cluster中相对重要的概念，下面我们就来写一个Akka Cluster的demo，&lt;/p&gt;

&lt;p&gt;demo需求：&lt;/p&gt;

&lt;p&gt;线假设需要执行一些相同任务，频率为2s一个，现在我们需要将这些任务分配给Akka集群中的不同节点去执行，这里使用ClusterClient作为集群与外部的通信接口。&lt;/p&gt;

&lt;p&gt;首先我们先来定义一些命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
package sample.cluster.transformation

final case class TransformationJob(text: String) // 任务内容
final case class TransformationResult(text: String) // 执行任务结果
final case class JobFailed(reason: String, job: TransformationJob) //任务失败相应原因
case object BackendRegistration // 后台具体执行任务节点注册事件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们实现具体执行任务逻辑的后台节点：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationBackend extends Actor {

  val cluster = Cluster(context.system)

  override def preStart(): Unit = cluster.subscribe(self, classOf[MemberEvent])  //在启动Actor时将该节点订阅到集群中
  override def postStop(): Unit = cluster.unsubscribe(self)

  def receive = {
    case TransformationJob(text) =&amp;gt; { // 接收任务请求
      val result = text.toUpperCase // 任务执行得到结果（将字符串转换为大写）
      sender() ! TransformationResult(text.toUpperCase) // 向发送者返回结果
    }
    case state: CurrentClusterState =&amp;gt;
      state.members.filter(_.status == MemberStatus.Up) foreach register // 根据节点状态向集群客户端注册
    case MemberUp(m) =&amp;gt; register(m)  // 将刚处于Up状态的节点向集群客户端注册
  }

  def register(member: Member): Unit = {   //将节点注册到集群客户端
    context.actorSelection(RootActorPath(member.address) / &quot;user&quot; / &quot;frontend&quot;) !
      BackendRegistration
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;相应节点的配置文件信息，我这里就不贴了，请从相应的源码demo里获取。&lt;/em&gt;&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;接着我们来实现集群客户端：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationFrontend extends Actor {

  var backends = IndexedSeq.empty[ActorRef] //任务后台节点列表
  var jobCounter = 0

  def receive = {
    case job: TransformationJob if backends.isEmpty =&amp;gt;  //目前暂无执行任务节点可用
      sender() ! JobFailed(&quot;Service unavailable, try again later&quot;, job)

    case job: TransformationJob =&amp;gt; //执行相应任务
      jobCounter += 1
      implicit val timeout = Timeout(5 seconds)
      val backend = backends(jobCounter % backends.size) //根据相应算法选择执行任务的节点
      println(s&quot;the backend is ${backend} and the job is ${job}&quot;)
      val result  = (backend ? job)
        .map(x =&amp;gt; x.asInstanceOf[TransformationResult])  // 后台节点处理得到结果
      result pipeTo sender  //向外部系统发送执行结果

    case BackendRegistration if !backends.contains(sender()) =&amp;gt;  // 添加新的后台任务节点
      context watch sender() //监控相应的任务节点
      backends = backends :+ sender()

    case Terminated(a) =&amp;gt;
      backends = backends.filterNot(_ == a)  // 移除已经终止运行的节点
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt; 最后我们实现与集群客户端交互的逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class ClientJobTransformationSendingActor extends Actor {

  val initialContacts = Set(
    ActorPath.fromString(&quot;akka.tcp://ClusterSystem@127.0.0.1:2551/system/receptionist&quot;))
  val settings = ClusterClientSettings(context.system)
    .withInitialContacts(initialContacts)

  val c = context.system.actorOf(ClusterClient.props(settings), &quot;demo-client&quot;)


  def receive = {
    case TransformationResult(result) =&amp;gt; {
      println(s&quot;Client response and the result is ${result}&quot;)
    }
    case Send(counter) =&amp;gt; {
        val job = TransformationJob(&quot;hello-&quot; + counter)
        implicit val timeout = Timeout(5 seconds)
        val result = Patterns.ask(c,ClusterClient.Send(&quot;/user/frontend&quot;, job, localAffinity = true), timeout)
        result.onComplete {
          case Success(transformationResult) =&amp;gt; {
            self ! transformationResult
          }
          case Failure(t) =&amp;gt; println(&quot;An error has occured: &quot; + t.getMessage)
        }
      }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们开始运行这个domo：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object DemoClient {
  def main(args : Array[String]) {

    TransformationFrontendApp.main(Seq(&quot;2551&quot;).toArray)  //启动集群客户端
    TransformationBackendApp.main(Seq(&quot;8001&quot;).toArray)   //启动三个后台节点
    TransformationBackendApp.main(Seq(&quot;8002&quot;).toArray)
    TransformationBackendApp.main(Seq(&quot;8003&quot;).toArray)

    val system = ActorSystem(&quot;OTHERSYSTEM&quot;)
    val clientJobTransformationSendingActor =
      system.actorOf(Props[ClientJobTransformationSendingActor],
        name = &quot;clientJobTransformationSendingActor&quot;)

    val counter = new AtomicInteger
    import system.dispatcher
    system.scheduler.schedule(2.seconds, 2.seconds) {   //定时发送任务
      clientJobTransformationSendingActor ! Send(counter.incrementAndGet())
    }
    StdIn.readLine()
    system.terminate()
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/09/akka-cluster.png&quot; alt=&quot;akka-cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从结果可以看到，我们将任务根据算法分配给不同的后台节点进行执行，最终返回结果。&lt;/p&gt;

&lt;h3&gt;本文目的&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;掌握集群基本概念&lt;/li&gt;
&lt;li&gt;了解学习Akka cluster的工作方式和主要角色&lt;/li&gt;
&lt;li&gt;尝试自己写一个Akka cluster的相关例子&lt;/li&gt;
&lt;li&gt;下一步进阶了解Akka cluster的背后原理&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;本文的demo例子已上传github：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（九）：Akka分布式之Akka Remote</title>
   <link href="/2017/08/10/learning-akka-9.html"/>
   <updated>2017-08-10T00:00:00+08:00</updated>
   <id>urn:uuid:8d4f2b63-e930-3d54-8ca7-fbvbds2a4fgd</id>
   <content type="html">&lt;p&gt;Akka作为一个天生用于构建分布式应用的工具，当然提供了用于分布式组件即Akka Remote，那么我们就来看看如何用Akka Remote以及Akka Serialization来构建分布式应用。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;很多同学在程序的开发中都会遇到一个问题，当业务需求变得越来越复杂，单机服务器已经不足以承载相应的请求的时候，我们都会考虑将服务部署到不同的服务器上，但服务器之间可能需要相互调用，那么系统必须拥有相互通信的接口，用于相应的数据交互，这时候一个好的远程调用方案是一个绝对的利器，主流的远程通信有以下几种选择：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RPC（Remote Procedure Call Protocol）&lt;/li&gt;
&lt;li&gt;Web Service&lt;/li&gt;
&lt;li&gt;JMS（Java Messaging Service）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这几种方式都是被采用比较广泛的通信方案，有兴趣的同学可以自己去了解一下，这里我会讲一下Java中的RPC即RMI （Remote Method Invocation）和JMS。&lt;/p&gt;

&lt;h3&gt;JAVA远程调用&lt;/h3&gt;

&lt;p&gt;RMI和JMS相信很多写过Java程序的同学都知道，是Java程序用来远程通信的主要方式，那么RMI和JMS又有什么区别呢？&lt;/p&gt;

&lt;h4&gt;1.RMI&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;同步通信：在使用RMI调用远程方法时，线程会持续等待直到结果返回，所以它是一个同步阻塞操作；&lt;/li&gt;
&lt;li&gt;强耦合：请求的系统中需要使用的RMI服务进行接口声明，返回的数据类型有一定的约束；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;实现相对简单，方法调用形式通俗易理解，接口声明服务功能清晰。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;只局限支持JVM平台；&lt;/li&gt;
&lt;li&gt;对无法兼容Java语言的其他语言也不适用；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;2.JMS&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;异步通信：JMS发送消息进行通信，在通信过程中，线程不会被阻塞，不必等待请求回应，所以是一个异步操作；&lt;/li&gt;
&lt;li&gt;松耦合：不需要接口声明，返回的数据类型可以是各种各样，比如JSON，XML等；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.通信方式：&lt;/h5&gt;

&lt;p&gt;（1）点对点消息传送模型&lt;/p&gt;

&lt;p&gt;顾名思义，点对点可以理解为两个服务器的定点通信，发送者和接收者都能明确知道对方是谁，大致模型如下：
&lt;img src=&quot;/media/images/2017/08/jms-point-to-point.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（2）发布/订阅消息传递模型&lt;/p&gt;

&lt;p&gt;点对点模型有些场景并不是很适用，比如有一台主服务器，它产生一条消息需要让所有的从服务器都能收到，若采用点对点模型的话，那主服务器需要循环发送消息，后续若有新的从服务器增加，还要改主服务器的配置，这样就会导致不必要的麻烦，那么发布/订阅模型是怎么样的呢？其实这种模式跟设计模式中的观察者模式很相似，相信很多同学都很熟悉，它最大的特点就是较松耦合，易扩展等特点，所以发布/订阅模型的大致结构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/jms-topic.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;h5&gt;iii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;由于使用异步通信，不需要线程暂停等待，性能相对较高。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iiii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;技术实现相对复杂，并需要维护相关的消息队列；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;更通俗的说：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RMI可以看成是用打电话的方式进行信息交流，而JMS更像是发短信。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总的来说两种方式没有孰优孰劣，我们也不用比较到底哪种方式比较好，存在即合理，更重要的是哪种选择可能更适合你的系统。&lt;/p&gt;

&lt;h3&gt;RMI Example&lt;/h3&gt;

&lt;p&gt;这里我写一个RMI的例子，一方面来看一下它的使用方式，另一方面用于和后续的Akka Remote做一些比较：&lt;/p&gt;

&lt;p&gt;首先我们来编写相应的传输对象和通信接口：&lt;/p&gt;

&lt;p&gt;1.JoinRmiEvt：
```java
public class JoinRmiEvt implements Remote , Serializable{
    private static final long serialVersionUID = 1L;
    private Long id;
    private String name;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public JoinRmiEvt(Long id, String name) {
    this.id = id;
    this.name = name;
}

public Long getId() {
    return id;
}

public void setId(Long id) {
    this.id = id;
}

public String getName() {
    return name;
}

public void setName(String name) {
    this.name = name;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}
```&lt;/p&gt;

&lt;p&gt;2.RemoteRmi:
```java
public interface RemoteRmi extends Remote {
    public void sendNoReturn(String message) throws RemoteException, InterruptedException;
    public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException;
}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
然后在服务端对该接口进行实现：

3.RemoteRmiImpl:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;public class RemoteRmiImpl extends UnicastRemoteObject implements RemoteRmi {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static final long serialVersionUID = 1L;

public  RemoteRmiImpl() throws RemoteException {};

@Override
public void sendNoReturn(String message) throws RemoteException, InterruptedException {
    Thread.sleep(2000);
    //throw new RemoteException(); 
}

@Override
public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException {
  if (joinRmiEvt.getId() &amp;gt;= 0)
      return new StringBuilder(&quot;the&quot;).append(joinRmiEvt.getName()).append(&quot;has join&quot;).toString();
  else return null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}
```&lt;/p&gt;

&lt;p&gt;接着我们在Server端绑定相应端口并发布服务，然后启动：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRMIServer {
    public static void main(String[] args) throws RemoteException, AlreadyBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the RemoteRMIServer is Starting ...&quot;);
        RemoteRmiImpl remoteRmi = new RemoteRmiImpl();
        System.out.println(&quot;Binding server implementation to registry&quot;);
        LocateRegistry.createRegistry(2553);
        Naming.bind(&quot;rmi://127.0.0.1:2553/remote_rmi&quot;,remoteRmi);
        System.out.println(&quot;the RemoteRMIServer is Started&quot;);
        Thread.sleep(10000000);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们在Client端调用Server端的服务：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRmiClient {
    public static void main(String[] args) throws RemoteException, NotBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the client has started&quot;);
        String url = &quot;rmi://127.0.0.1:2553/remote_rmi&quot;;
        RemoteRmi remoteRmi = (RemoteRmi) Naming.lookup(url);
        System.out.println(&quot;the client has running&quot;);
        remoteRmi.sendNoReturn(&quot;send no return&quot;);
        System.out.println(remoteRmi.sendHasReturn(new JoinRmiEvt(1L,&quot;godpan&quot;)));
        System.out.println(&quot;the client has end&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/java-rmi-result.png&quot; alt=&quot;java-rmi-result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Java Rmi调用是一个阻塞的过程，这会导致一个问题，假如服务端的服务奔溃了，会导致客户端没有反应；&lt;/li&gt;
&lt;li&gt;Java Rmi使用的是Java默认的序列化方式,性能并不是很好，而且并不提供支持使用其他序列化的接口，在一些性能要求高的系统会有一定的瓶颈；&lt;/li&gt;
&lt;li&gt;在Rmi中使用的相应的接口和对象必须实现相应的接口，必须制定抛出相应的Exception，导致代码看起来异常的繁琐；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Remote&lt;/h3&gt;

&lt;p&gt;上面讲到JAVA中远程通信的方式，但我们之前说过Akka也是基于JVM平台的，那么它的通信方式又有什么不同呢？&lt;/p&gt;

&lt;p&gt;在我看来，Akka的远程通信方式更像是RMI和JMS的结合，但更偏向于JMS的方式，为什么这么说呢，我们先来看一个示例:&lt;/p&gt;

&lt;p&gt;我们先来创建一个远程的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class RemoteActor extends Actor {
  def receive = {
    case msg: String =&amp;gt;
      println(s&quot;RemoteActor received message '$msg'&quot;)
      sender ! &quot;Hello from the RemoteActor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们在远程服务器上启动这个Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么现在我们假如有一个系统需要向这个Actor发送消息应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们需要类似RMI发布自己的服务一样，我们需要为其他系统调用远程Actor提供消息通信的接口，在Akka中，设置非常简单，不需要代码侵入，只需简单的在配置文件里配置即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka {
  actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
  }
  remote {
    enabled-transports = [&quot;akka.remote.netty.tcp&quot;]
    netty.tcp {
      hostname = $localIp  //比如127.0.0.1
      port = $port //比如2552
    }
    log-sent-messages = on
    log-received-messages = on
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们只需配置相应的驱动，传输方式，ip，端口等属性就可简单完成Akka Remote的配置。&lt;/p&gt;

&lt;p&gt;当然本地服务器也需要配置这些信息，因为Akka之间是需要相互通信的，当然配置除了hostname有一定的区别外，其他配置信息可一致，本例子是在同一台机器上，所以这里hostname是相同的。&lt;/p&gt;

&lt;p&gt;这时候我们就可以在本地的服务器向这个Actor发送消息了，首先我们可以创建一个本地的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object Init
case object SendNoReturn

class LocalActor extends Actor{

  val path = ConfigFactory.defaultApplication().getString(&quot;remote.actor.name.test&quot;)
  implicit val timeout = Timeout(4.seconds)
  val remoteActor = context.actorSelection(path)

  def receive: Receive = {
    case Init =&amp;gt; &quot;init local actor&quot;
    case SendNoReturn =&amp;gt; remoteActor ! &quot;hello remote actor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;remote.actor.name.test&lt;/code&gt;的值为：“akka.tcp://RemoteDemoSystem@127.0.0.1:4444/user/RemoteActor”，另外我们可以看到我们使用了&lt;code&gt;context.actorSelection(path)&lt;/code&gt;来获取的是一个ActorSelection对象，若是需要获得ActorRef，我们可以调用它的resolveOne(),它返回的是是一个Future[ActorRef],这里是不是很熟悉，因为它跟本地获取Actor方式是一样的，因为Akka中Actor是位置透明的，获取本地Actor和远程Actor是一样的。&lt;/p&gt;

&lt;p&gt;最后我们首先启动远程Actor的系统：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object RemoteDemo extends App  {
  val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
  val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
  remoteActor ! &quot;The RemoteActor is alive&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们在本地系统中启动这个LocalActor，并向它发送消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object LocalDemo extends App {

  implicit val system = ActorSystem(&quot;LocalDemoSystem&quot;)
  val localActor = system.actorOf(Props[LocalActor], name = &quot;LocalActor&quot;)

  localActor ! Init
  localActor ! SendNoReturn
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到RemoteActor收到了一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-no-return.png&quot; alt=&quot;send-no-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从以上的步骤和结果看出可以看出，Akka的远程通信跟JMS的点对点模式似乎更相似一点，但是它有不需要我们维护消息队列，而是使用Actor自身的邮箱，另外我们利用context.actorSelection获取的ActorRef，可以看成远程Actor的副本，这个又和RMI相关概念类似，所以说Akka远程通信的形式上像是RMI和JMS的结合,当然底层还是通过TCP、UDP等相关网络协议进行数据传输的，从配置文件的相应内容便可以看出。&lt;/p&gt;

&lt;p&gt;上述例子演示的是sendNoReturn的模式，那么假如我们需要远程Actor给我们一个回复应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们创建一个消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object SendHasReturn

 def receive: Receive = {
    case SendHasReturn =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(&quot;hello remote actor&quot;)
      } yield r
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们重新运行LocalActor并像RemoteActor发送一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-has-return.png&quot; alt=&quot;send-has-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到LocalActor在发送消息后并收到了RemoteActor返回来的消息，另外我们这里设置了超时时间，若在规定的时间内没有得到反馈，程序就会报错。&lt;/p&gt;

&lt;h3&gt;Akka Serialization&lt;/h3&gt;

&lt;p&gt;其实这一部分本可以单独拿出来写，但是相信序列化这块大家都应该有所了解了，所以就不准备讲太多序列化的知识了，怕班门弄斧，主要讲讲Akka中的序列化。&lt;/p&gt;

&lt;p&gt;继续上面的例子，假如我们这时向RemoteActor发送一个自定义的对象，比如一个case class对象，但是我们这是是在网络中传输这个消息，那么怎么保证这个对象类型和值呢，在同一个JVM系统中我们不需要担心这个，因为对象就在堆中，我们只要传递相应的地址即可就行，但是在不同的环境中，我们并不能这么做，我们在网络中只能传输字节数据，所以我们必须将对象做特殊的处理，在传输的时候转化成特定的由一连串字节组成的数据，而且我们又可以根据这些数据恢复成一个相应的对象，这便是序列化。&lt;/p&gt;

&lt;p&gt;我们先定义一个参与的case class, 并修改一下上面发送消息的语句:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case object SendSerialization
case class JoinEvt(
    id: Long,
    name: String
)
def receive: Receive = {
    case SendSerialization =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(JoinEvt(1L,&quot;godpan&quot;))
      } yield println(r)
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时我们重新启动RemoteActor和LocalActor所在的系统，发送这条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-serialization.png&quot; alt=&quot;send-serialization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有同学可能会觉得奇怪，我们明明没有对JoinEvt进行过任何序列化的标识和处理，为什么程序还能运行成功呢？&lt;/p&gt;

&lt;p&gt;其实不然，只不过是有人替我们默认做了，不用说，肯定是贴心的Akka，它为我们提供了一个默认的序列化策略，那就是我们熟悉又纠结的java.io.Serializable，沉浸在它的易使用性上，又对它的性能深恶痛绝，尤其是当有大量对象需要传输的分布式系统，如果是小系统，当我没说，毕竟存在即合理。&lt;/p&gt;

&lt;p&gt;又有同学说，既然Akka是一个天生分布式组件，为什么还用低效的java.io.Serializable，你问我我也不知道，可能当时的作者偷了偷懒，当然Akka现在可能觉醒了，首先它支持第三方的序列化工具，当然如果你有特殊需求，你也可以自己实现一个，而且在最新的文档中说明，在Akka 2.5x之后Akka内核消息全面废弃java.io.Serializable，用户自定义的消息暂时还是支持使用java.io.Serializable的，但是不推荐用，因为它是低效的，容易被攻击，所以在这里我也推荐大家再Akka中尽量不要在使用了java.io.Serializable。&lt;/p&gt;

&lt;p&gt;那么在Akka中我们如何使用第三方的序列化工具呢？&lt;/p&gt;

&lt;p&gt;这里我推荐一个在Java社区已经久负盛名的序列化工具：kryo，有兴趣的同学可以去了解一下：&lt;a href=&quot;https://github.com/EsotericSoftware/kryo&quot;&gt;kryo&lt;/a&gt;,而且它也提供Akka使用的相关包，这里我们就使用它作为示例：&lt;/p&gt;

&lt;p&gt;这里我贴上整个项目的build.sbt, kryo的相关依赖也在里面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
import sbt._
import sbt.Keys._

lazy val AllLibraryDependencies =
  Seq(
    &quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.5.3&quot;,
    &quot;com.typesafe.akka&quot; %% &quot;akka-remote&quot; % &quot;2.5.3&quot;,
    &quot;com.twitter&quot; %% &quot;chill-akka&quot; % &quot;0.8.4&quot;
  )

lazy val commonSettings = Seq(
  name := &quot;AkkaRemoting&quot;,
  version := &quot;1.0&quot;,
  scalaVersion := &quot;2.11.11&quot;,
  libraryDependencies := AllLibraryDependencies
)

lazy val remote = (project in file(&quot;remote&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )

lazy val local = (project in file(&quot;local&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们只需将application.conf中的actor配置替换成以下的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
    serializers {
      kryo = &quot;com.twitter.chill.akka.AkkaSerializer&quot;
    }
    serialization-bindings {
      &quot;java.io.Serializable&quot; = none
      &quot;scala.Product&quot; = kryo
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实其中的&quot;java.io.Serializable&quot; = none可以省略，因为若是有其他序列化的策略则会替换掉默认的java.io.Serializable的策略，这里只是为了更加仔细的说明。&lt;/p&gt;

&lt;p&gt;至此我们就可以使用kryo了，整个过程是不是很easy，迫不及待开始写demo了，那就快快开始吧。&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Akka Remote使用内置的序列化工具，并支持配置指定的序列化方式，可以按需配置；&lt;/li&gt;
&lt;li&gt;Akka Remote使用的过程是一个异步非阻塞的过程，客户端能尽量减少对服务端的依赖；&lt;/li&gt;
&lt;li&gt;Akka Remote的代码实现相对Java Rmi实现来说简单的多，非常简洁；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;整个例子的相关的源码已经上传到akka-demo中：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_06&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（八）：Akka persistence设计理念之CQRS</title>
   <link href="/2017/07/29/learning-akka-8.html"/>
   <updated>2017-07-29T00:00:00+08:00</updated>
   <id>urn:uuid:8dcf2b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这一篇文章主要是讲解Akka persistence的核心设计理念，也是CQRS（Command Query Responsibility Segregation）架构设计的典型应用，就让我们来看看为什么Akka persistence会采用CQRS架构设计。&lt;/p&gt;

&lt;h3&gt;CQRS&lt;/h3&gt;

&lt;p&gt;很多时候我们在处理高并发的业务需求的时候，往往能把应用层的代码优化的很好，比如缓存，限流，均衡负载等，但是很难避免的一个问题就是数据的持久化，以致数据库的性能很可能就是系统性能的瓶颈，我前面的那篇文章也讲到，如果我们用数据库去保证记录的CRUD，在并发高的情况下，让数据库执行这么多的事务操作，会让很多数据库操作超时，连接池不够用的情况，导致大量请求失败，系统的错误率上升和负载性能下降。&lt;/p&gt;

&lt;p&gt;既然这样，那我们可不可借鉴一下读写分离的思想呢？假使写操作和同操作分离，甚至是对不同数据表，数据库操作，那么我们就可以大大降低数据库的瓶颈，使整个系统的性能大大提升。那么CQRS到底是做了什么呢？&lt;/p&gt;

&lt;p&gt;我们先来看看普通的方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/acid.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看出，我们对数据的请求都是通过相应的接口直接对数据库进行操作，这在并发大的时候肯定会对数据库造成很大的压力，虽然架构简单，但在面对并发高的情况下力不从心。&lt;/p&gt;

&lt;p&gt;那么CQRS的方式有什么不同呢？我们也来看看它的执行方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;乍得一看，似乎跟普通的方式没什么不同啊，不就多了一个事件和存储DB么，其实不然，小小的改动便是核心理念的转换，首先我们可以看到在CQRS架构中会多出一个Event，那它到底代表着什么含义呢？其实看过上篇文章的同学很容易理解，Event是我们系统根据请求处理得出的一个领域模型，比如一个修改余额操作事件，当然这个Event中只会保存关键性的数据。&lt;/p&gt;

&lt;p&gt;很多同学又有疑问了，这不跟普通的读写分离很像么，难道还隐藏着什么秘密？那我们就来比较一下几种方式的不同之处：&lt;/p&gt;

&lt;h5&gt;1.单数据库模式&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;写操作会产生互斥锁，导致性能降低；&lt;/li&gt;
&lt;li&gt;即使使用乐观锁，但是在大量写操作的情况下也会大量失败；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;2.读写分离&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;读写分离通过物理服务器增加，负荷增加；&lt;/li&gt;
&lt;li&gt;读写分离更适用于读操作大于写操作的场景；&lt;/li&gt;
&lt;li&gt;读写分离在面对大量写操作的情况下还是很吃力；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;3.CQRS&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;普通数据的持久化和Event持久化可以使用同一台数据库；&lt;/li&gt;
&lt;li&gt;利用架构设计可以使读和写操作尽可能的分离；&lt;/li&gt;
&lt;li&gt;能支撑大量写的操作情况；&lt;/li&gt;
&lt;li&gt;可以支持数据异步持久，确保数据最终一致性；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;从三种方式各自的特点可以看出，单数据库模式的在大量读写的情况下有很大的性能瓶颈，但简单的读写分离在面对大量写操作的时候也还是力不从心，比如最常见的库存修改查询场景：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/common-action.png&quot; alt=&quot;common-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以发现在这种模式下写数据库的压力还会很大，而且还有数据同步，数据延迟等问题。&lt;/p&gt;

&lt;p&gt;那么我们用CQRS架构设计会是怎么样呢：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-action.png&quot; alt=&quot;cqrs-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先我们可以业务模型进行分离，对不同的查询进行分离，另外避免不了的同一区间数据段进行异步持久化，在保证数据一致性的情况下提升系统的吞吐量。这种设计我们很少会遇到事务竞争，另外还可以使用内存数据库（当然如果是内存操作那就最快）来提升数据的写入。（以上的数据库都可为分布式数据库，不担心单机宕机）&lt;/p&gt;

&lt;p&gt;那么CRQS机制是怎么保证数据的一致性的呢？&lt;/p&gt;

&lt;p&gt;从上图中我们可以看出，一个写操作我们会在系统进行初步处理后生成一个领域事件，比如a用户购买了xx商品1件，b用户购买了xx商品2件等，按照普通的方式我们肯定是直接将订单操作，库存修改操作一并放在一个事务内去操作数据库，性能可想而知，而用CQRS的方式后，首先系统在持久化相应的领域事件后和修改内存中的库存（这个处理非常迅速）后便可马上向用户做出反应，真正的具体信息持久可以异步进行，当然若是当在具体信息持久化的过程中出错了怎么办，系统能恢复正确的数据么，当然可以，因为我们的领域事件事件已经持久化成功了，在系统恢复的时候，我们可以根据领域事件来恢复真正的数据，当然为了防止恢复数据是造成数据丢失，数据重复等问题我们需要制定相应的原则，比如给领域事件分配相应id等。&lt;/p&gt;

&lt;p&gt;使用CQRS会带来性能上的提升，当然它也有它的弊端：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使系统变得更复杂，做一些额外的设计；&lt;/li&gt;
&lt;li&gt;CQRS保证的是最终一致性，有可能只适用于特定的业务场景；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Persistence 中CQRS的应用&lt;/h3&gt;

&lt;p&gt;通过上面的讲解，相信大家对CQRS已经有了一定的了解，下面我们就来看看它在Akka Persistence中的具体应用，这里我就结合上一篇文章抽奖的例子，比如其中的LotteryCmd便是一个写操作命令，系统经过相应的处理后得到相应的领域事件，比如其中LuckyEvent，然后我们将LuckyEvent进行持久化，并修改内存中抽奖的余额，返回相应的结果，这里我们就可以同时将结果反馈给用户，并对结果进行异步持久化，流程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-example.png&quot; alt=&quot;cqrs-example&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出，Akka Persistence的原理完全是基于CQRS的架构设计的，另外Persistence Actor还会保存一个内存状态，相当于一个in memory数据库，可以用来提供关键数据的存储和查询，比如前面说到的库存，余额等数据，这部分的设计取决于具体的业务场景。&lt;/p&gt;

&lt;p&gt;阅读Akka Persistence相关源码，其的核心就在于PersistentActor接口中的几个持久方法，比如其中的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;def persist[A](event: A)(handler: A ⇒ Unit): Unit

def persistAll[A](events: immutable.Seq[A])(handler: A ⇒ Unit): Unit 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等方法，它们都有两个参数，一个是持久化的事件，一个是持久化后的后续处理逻辑，我们可以在后续handler中修改Actor内部状态，向外部发送消息等操作,这里的模式就是基于CQRS架构的，修改状态有事件驱动，另外Akka还可以在系统出错时，利用相应的事件恢复Actor的状态。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;总的来说，CQRS架构是一种不同于以往的CRUD的架构，所以你在享受它带来的高性能的同时可能会遇到一些奇怪的问题，当然这些都是可以解决的，重要的是思维上的改变，比如事件驱动，领域模型等概念，不过相信当你理解并掌握它之后，你便会爱上它的。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（七）：Actor持久化之Akka persistence</title>
   <link href="/2017/07/25/learning-akka-7.html"/>
   <updated>2017-07-25T00:00:00+08:00</updated>
   <id>urn:uuid:8dcf2b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这次把这部分内容提到现在写，是因为这段时间开发的项目刚好在这一块遇到了一些难点，所以准备把经验分享给大家，我们在使用Akka时，会经常遇到一些存储Actor内部状态的场景，在系统正常运行的情况下，我们不需要担心什么，但是当系统出错，比如Actor错误需要重启，或者内存溢出，亦或者整个系统崩溃，如果我们不采取一定的方案的话，在系统重启时Actor的状态就会丢失，这会导致我们丢失一些关键的数据，造成系统数据不一致的问题。Akka作为一款成熟的生产环境应用，为我们提供了相应的解决方案就是Akka persistence。&lt;/p&gt;

&lt;h3&gt;为什么需要持久化的Actor？&lt;/h3&gt;

&lt;p&gt;万变不离其宗，数据的一致性是永恒的主题，一个性能再好的系统，不能保证数据的正确，也称不上是一个好的系统，一个系统在运行的时候难免会出错，如何保证系统在出错后能正确的恢复数据，不让数据出现混乱是一个难题。使用Actor模型的时候，我们会有这么一个想法，就是能不对数据库操作就尽量不对数据库操作（这里我们假定我们的数据库是安全，可靠的，能保证数据的正确性和一致性，比如使用国内某云的云数据库），一方面如果大量的数据操作会使数据库面临的巨大的压力，导致崩溃，另一方面即使数据库能处理的过来，比如一些count，update的大表操作也会消耗很多的时间，远没有内存中直接操作来的快，大大影响性能。但是又有人说内存操作这么快，为什么不把数据都放内存中呢？答案显而易见，当出现机器死机，或者内存溢出等问题时，数据很有可能就丢失了导致无法恢复。在这种背景下，我们是不是有一种比较好的解决方案，既能满足需求又能用最小的性能消耗，答案就是上面我们的说的Akka persistence。&lt;/p&gt;

&lt;h3&gt;Akka persistence的核心架构&lt;/h3&gt;

&lt;p&gt;在具体深入Akka persistence之前，我们可以先了解一下它的核心设计理念，其实简单来说，我们可以利用一些thing来恢复Actor的状态，这里的thing可以是日志、数据库中的数据，亦或者是文件，所以说它的本质非常容易理解，在Actor处理的时候我们会保存一些数据，Actor在恢复的时候能根据这些数据恢复其自身的状态。&lt;/p&gt;

&lt;p&gt;所以Akka persistence 有以下几个关键部分组成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PersistentActor：任何一个需要持久化的Actor都必须继承它，并必须定义或者实现其中的三个关键属性：&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt; def persistenceId = &quot;example&quot; //作为持久化Actor的唯一表示，用于持久化或者查询时使用

 def receiveCommand: Receive = ??? //Actor正常运行时处理处理消息逻辑，可在这部分内容里持久化自己想要的消息

 def receiveRecover: Receive = ??? //Actor重启恢复是执行的逻辑
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比普通的Actor，除receiveCommand相似以外，还必须实现另外两个属性。
另外在持久化Actor中还有另外两个关键的的概念就是&lt;em&gt;Journal&lt;/em&gt;和&lt;em&gt;Snapshot&lt;/em&gt;，前者用于持久化事件，后者用于保存Actor的快照，两者在Actor恢复状态的时候都起到了至关重要的作用。&lt;/p&gt;

&lt;h3&gt;Akka persistence的demo实战&lt;/h3&gt;

&lt;p&gt;这里我首先会用一个demo让大家能对Akka persistence的使用有一定了解的，并能大致明白它的工作原理，后面再继续讲解一些实战可能会遇到的问题。&lt;/p&gt;

&lt;p&gt;假定现在有这么一个场景，现在假设有一个1w元的大红包，瞬间可能会很多人同时来抢，每个人抢的金额也可能不一样，场景很简单，实现方式也有很多种，但前提是保证数据的正确性，比如最普通的使用数据库保证，但对这方面有所了解的同学都知道这并不是一个很好的方案，因为需要锁，并需要大量的数据库操作，导致性能不高，那么我们是否可以用Actor来实现这个需求么？答案是当然可以。&lt;/p&gt;

&lt;p&gt;我们首先来定义一个抽奖命令，
&lt;code&gt;scala
case class LotteryCmd(
  userId: Long, // 参与用户Id
  username: String, //参与用户名
  email: String // 参与用户邮箱
)
&lt;/code&gt;
然后我们实现一个抽奖Actor，并继承PersistentActor作出相应的实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case class LuckyEvent(  //抽奖成功事件
    userId: Long,
    luckyMoney: Int
)
case class FailureEvent(  //抽奖失败事件
    userId: Long,
    reason: String
)
case class Lottery(
    totalAmount: Int,  //红包总金额
    remainAmount: Int  //剩余红包金额
) {
  def update(luckyMoney: Int) = {
    copy(
      remainAmount = remainAmount - luckyMoney
    )
  }
}
class LotteryActor(initState: Lottery) extends PersistentActor with ActorLogging{
  override def persistenceId: String = &quot;lottery-actor-1&quot;

  var state = initState  //初始化Actor的状态

  override def receiveRecover: Receive = {
    case event: LuckyEvent =&amp;gt;
      updateState(event)  //恢复Actor时根据持久化的事件恢复Actor状态
    case SnapshotOffer(_, snapshot: Lottery) =&amp;gt;
      log.info(s&quot;Recover actor state from snapshot and the snapshot is ${snapshot}&quot;)
      state = snapshot //利用快照恢复Actor的状态
    case RecoveryCompleted =&amp;gt; log.info(&quot;the actor recover completed&quot;)
  }

  def updateState(le: LuckyEvent) =
    state = state.update(le.luckyMoney)  //更新自身状态

  override def receiveCommand: Receive = {
    case lc: LotteryCmd =&amp;gt;
      doLottery(lc) match {     //进行抽奖，并得到抽奖结果，根据结果做出不同的处理
        case le: LuckyEvent =&amp;gt;  //抽到随机红包
          persist(le) { event =&amp;gt;
            updateState(event)
            increaseEvtCountAndSnapshot()
            sender() ! event
          }
        case fe: FailureEvent =&amp;gt;  //红包已经抽完
          sender() ! fe
      }
    case &quot;saveSnapshot&quot; =&amp;gt;  // 接收存储快照命令执行存储快照操作
      saveSnapshot(state)
    case SaveSnapshotSuccess(metadata) =&amp;gt;  ???  //你可以在快照存储成功后做一些操作，比如删除之前的快照等
  }

  private def increaseEvtCountAndSnapshot() = {
    val snapShotInterval = 5
    if (lastSequenceNr % snapShotInterval == 0 &amp;amp;&amp;amp; lastSequenceNr != 0) {  //当有持久化5个事件后我们便存储一次当前Actor状态的快照
      self ! &quot;saveSnapshot&quot;
    }
  }

  def doLottery(lc: LotteryCmd) = {  //抽奖逻辑具体实现
    if (state.remainAmount &amp;gt; 0) {
      val luckyMoney = scala.util.Random.nextInt(state.remainAmount) + 1
      LuckyEvent(lc.userId, luckyMoney)
    }
    else {
      FailureEvent(lc.userId, &quot;下次早点来，红包已被抽完咯！&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;程序很简单，关键位置我也给了注释，相信大家对Actor有所了解的话很容易理解，当然要是有些疑惑，可以看看我之前写的文章，下面我们就对刚才写的抽红包Actor进行测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object PersistenceTest extends App {
  val lottery = Lottery(10000,10000)
  val system = ActorSystem(&quot;example-05&quot;)
  val lotteryActor = system.actorOf(Props(new LotteryActor(lottery)), &quot;LotteryActor-1&quot;)  //创建抽奖Actor
  val pool: ExecutorService = Executors.newFixedThreadPool(10)
  val r = (1 to 100).map(i =&amp;gt;
    new LotteryRun(lotteryActor, LotteryCmd(i.toLong,&quot;godpan&quot;,&quot;xx@gmail.com&quot;))  //创建100个抽奖请求
  )
  r.map(pool.execute(_))  //使用线程池来发起抽奖请求，模拟同时多人参加
  Thread.sleep(5000)
  pool.shutdown()
  system.terminate()
}

class LotteryRun(lotteryActor: ActorRef, lotteryCmd: LotteryCmd) extends Runnable { //抽奖请求
  implicit val timeout = Timeout(3.seconds)
  def run: Unit = {
    for {
      fut &amp;lt;- lotteryActor ? lotteryCmd
    } yield fut match {  //根据不同事件显示不同的抽奖结果
      case le: LuckyEvent =&amp;gt; println(s&quot;恭喜用户${le.userId}抽到了${le.luckyMoney}元红包&quot;)
      case fe: FailureEvent =&amp;gt;  println(fe.reason)
      case _ =&amp;gt; println(&quot;系统错误，请重新抽取&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行程序,我们可能看到以下的结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/result-persistence-demo.png&quot; alt=&quot;result persistence demo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面我会把persistence actor在整个运行过程的步骤给出，帮助大家理解它的原理：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.初始化Persistence Actor&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.1若是第一次初始化，则与正常的Actor的初始化一致。&lt;/li&gt;
&lt;li&gt;1.2若是重启恢复Actor，这根据Actor之前持久的数据恢复。

&lt;ul&gt;
&lt;li&gt;1.2.1从快照恢复，可快速恢复Actor，但并非每次持久化事件都会保存快照，在快照完整的情况下，Actor优先从快照恢复自身状态。&lt;/li&gt;
&lt;li&gt;1.2.2从事件（日志，数据库记录等）恢复，通过重放持久化事件恢复Actor状态，比较关键。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2.接收命令进行处理，转化为需要持久化的事件（持久化的事件尽量只包含关键性的数据）使用Persistence Actor的持久化方法进行持久化（上述例子中的persist，后面我会讲一下批量持久化），并处理持久化成功后的逻辑处理，比如修改Actor状态，向外部Actor发送消息等。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;3.若是我们需要存储快照，那么可以主动指定存储快照的频率，比如持久化事件100次我们就存储一次快照，这个频率应该要考虑实际的业务场景，在存储快照成功后我们也可以执行一些操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说Persistence Actor运行时的大致操作就是以上这些，当然它是r如何持久化事件，恢复时的机制是怎么样的等有兴趣的可以看一下Akka源码。&lt;/p&gt;

&lt;h3&gt;使用Akka persistence的相关配置&lt;/h3&gt;

&lt;p&gt;首先我们必须加载相应的依赖包，在&lt;code&gt;bulid.sbt&lt;/code&gt;中加入以下依赖：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(
&quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.4.16&quot;,  //Akka actor 核心依赖
  &quot;com.typesafe.akka&quot; %% &quot;akka-persistence&quot; % &quot;2.4.16&quot;, //Akka persistence 依赖
  &quot;org.iq80.leveldb&quot;            % &quot;leveldb&quot;          % &quot;0.7&quot;, //leveldb java版本依赖
  &quot;org.fusesource.leveldbjni&quot;   % &quot;leveldbjni-all&quot;   % &quot;1.8&quot;, //leveldb java版本依赖
  &quot;com.twitter&quot;              %% &quot;chill-akka&quot;                  % &quot;0.8.0&quot; //事件序列化依赖
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外我们还需在&lt;code&gt;application.conf&lt;/code&gt;加入以下配置:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;akka.persistence.journal.plugin = &quot;akka.persistence.journal.leveldb&quot;
akka.persistence.snapshot-store.plugin = &quot;akka.persistence.snapshot-store.local&quot;

akka.persistence.journal.leveldb.dir = &quot;log/journal&quot;
akka.persistence.snapshot-store.local.dir = &quot;log/snapshots&quot;

# DO NOT USE THIS IN PRODUCTION !!!
# See also https://github.com/typesafehub/activator/issues/287
akka.persistence.journal.leveldb.native = false  //因为我们本地并没有安装leveldb，所以这个属性置为false，但是生产环境并不推荐使用

akka.actor.serializers {
  kryo = &quot;com.twitter.chill.akka.AkkaSerializer&quot;
}

akka.actor.serialization-bindings {
  &quot;scala.Product&quot; = kryo
  &quot;akka.persistence.PersistentRepr&quot; = kryo
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此为止我们整个Akka persistence demo已经搭建好了，可以正常运行了，有兴趣的同学可以下载源码。&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_05&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Akka persistence进阶&lt;/h3&gt;

&lt;h4&gt;1.持久化插件&lt;/h4&gt;

&lt;p&gt;有同学可能会问，我对leveldb不是很熟悉亦或者觉得单机存储并不是安全，有没有支持分布式数据存储的插件呢，比如某爸的云数据库？答案当然是有咯，良心的我当然是帮你们都找好咯。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.akka-persistence-sql-async: 支持MySQL和PostgreSQL，另外使用了全异步的数据库驱动，提供异步非阻塞的API，我司用的就是它的变种版，6的飞起。&lt;a href=&quot;https://github.com/okumin/akka-persistence-sql-async&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2.akka-persistence-cassandra: 官方推荐的插件，使用写性能very very very fast的cassandra数据库，是几个插件中比较流行的一个，另外它还支持persistence query。&lt;a href=&quot;https://github.com/krasserm/akka-persistence-cassandra&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;3.akka-persistence-redis: redis应该也很符合Akka persistence的场景，熟悉redis的同学可以使用看看。&lt;a href=&quot;https://github.com/hootsuite/akka-persistence-redis&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;4.akka-persistence-jdbc: 怎么能少了jdbc呢？不然怎么对的起java爸爸呢，支持scala和java哦。&lt;a href=&quot;https://github.com/dnvriend/akka-persistence-jdbc&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;相应的插件的具体使用可以看该项目的具体介绍使用，我看了下相对来说都是比较容易的。&lt;/p&gt;

&lt;h4&gt;2.批量持久化&lt;/h4&gt;

&lt;p&gt;上面说到我司用的是akka-persistence-sql-async插件，所以我们是将事件和快照持久化到数据库的，一开始我也是像上面demo一样，每次事件都会持久化到数据库，但是后来在性能测试的时候，因为本身业务场景对数据库的压力也比较大，在当数据库到达每秒1000+的读写量后，另外说明一下使用的是某云数据库，性能中配以上，发现每次持久化的时间将近要15ms，这样换算一下的话Actor每秒只能处理60~70个需要持久化的事件，而实际业务场景要求Actor必须在3秒内返回处理结果，这种情况下导致大量消息处理超时得不到反馈，另外还有大量的消息得不到处理，导致系统错误暴增，用户体验下降，既然我们发现了问题，那么我们能不能进行优化呢?事实上当然是可以，既然单个插入慢，那么我们能不能批量插入呢，Akka persistence为我们提供了persistAll方法，下面我就对上面的demo进行一下改造，让其变成批量持久化：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class LotteryActorN(initState: Lottery) extends PersistentActor with ActorLogging{
  override def persistenceId: String = &quot;lottery-actor-2&quot;

  var state = initState  //初始化Actor的状态

  override def receiveRecover: Receive = {
    case event: LuckyEvent =&amp;gt;
      updateState(event)  //恢复Actor时根据持久化的事件恢复Actor状态
    case SnapshotOffer(_, snapshot: Lottery) =&amp;gt;
      log.info(s&quot;Recover actor state from snapshot and the snapshot is ${snapshot}&quot;)
      state = snapshot //利用快照恢复Actor的状态
    case RecoveryCompleted =&amp;gt; log.info(&quot;the actor recover completed&quot;)
  }

  def updateState(le: LuckyEvent) =
    state = state.update(le.luckyMoney)  //更新自身状态

  var lotteryQueue : ArrayBuffer[(LotteryCmd, ActorRef)] = ArrayBuffer()

  context.system.scheduler  //定时器，定时触发抽奖逻辑
    .schedule(
      0.milliseconds,
      100.milliseconds,
      new Runnable {
        def run = {
          self ! &quot;doLottery&quot;
        }
      }
    )

  override def receiveCommand: Receive = {
    case lc: LotteryCmd =&amp;gt;
      lotteryQueue = lotteryQueue :+ (lc, sender())  //参与信息加入抽奖队列
      println(s&quot;the lotteryQueue size is ${lotteryQueue.size}&quot;)
      if (lotteryQueue.size &amp;gt; 5)  //当参与人数有5个时触发抽奖
        joinN(lotteryQueue)
    case &quot;doLottery&quot; =&amp;gt;
      if (lotteryQueue.size &amp;gt; 0)
        joinN(lotteryQueue)
    case &quot;saveSnapshot&quot; =&amp;gt;  // 接收存储快照命令执行存储快照操作
      saveSnapshot(state)
    case SaveSnapshotSuccess(metadata) =&amp;gt;  ???  //你可以在快照存储成功后做一些操作，比如删除之前的快照等
  }

  private def joinN(lotteryQueue: ArrayBuffer[(LotteryCmd, ActorRef)]) = {  //批量处理抽奖结果
    val rs = doLotteryN(lotteryQueue)
    val success = rs.collect {  //得到其中中奖的相应信息
      case (event: LuckyEvent, ref: ActorRef) =&amp;gt;
        event -&amp;gt; ref
    }.toMap
    val failure = rs.collect {  //得到其中未中奖的相应信息
      case (event: FailureEvent, ref: ActorRef) =&amp;gt; event -&amp;gt; ref
    }
    persistAll(success.keys.toIndexedSeq) {  //批量持久化中奖用户事件
      case event =&amp;gt;  println(event)
        updateState(event)
        increaseEvtCountAndSnapshot()
        success(event) ! event
    }
    failure.foreach {
      case (event, ref) =&amp;gt; ref ! event
    }
    this.lotteryQueue.clear()  //清空参与队列
  }


  private def increaseEvtCountAndSnapshot() = {
    val snapShotInterval = 5
    if (lastSequenceNr % snapShotInterval == 0 &amp;amp;&amp;amp; lastSequenceNr != 0) {  //当有持久化5个事件后我们便存储一次当前Actor状态的快照
      self ! &quot;saveSnapshot&quot;
    }
  }

  private def doLotteryN(lotteryQueue: ArrayBuffer[(LotteryCmd, ActorRef)]) = {  //抽奖逻辑具体实现
    var remainAmount = state.remainAmount
    lotteryQueue.map(lq =&amp;gt;
      if (remainAmount &amp;gt; 0) {
        val luckyMoney = scala.util.Random.nextInt(remainAmount) + 1
        remainAmount = remainAmount - luckyMoney
        (LuckyEvent(lq._1.userId, luckyMoney),lq._2)
      }
      else {
        (FailureEvent(lq._1.userId, &quot;下次早点来，红包已被抽完咯！&quot;),lq._2)
      }
    )
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是改造后的参与Actor，实现了批量持久的功能，当然这里为了给发送者返回消息，处理逻辑稍微复杂了一点，不过真实场景可能会更复杂，相关源码也在刚才的项目上。&lt;/p&gt;

&lt;h4&gt;3.Persistence Query&lt;/h4&gt;

&lt;p&gt;另外Akka Persistence还提供了Query接口，用于需要查询持久化事件的需求，这部分内容可能要根据实际业务场景考虑是否需要应用，我就不展开讲了，另外我也写了一个小demo在项目中，想要尝试的同学也可以试试。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（六）：Actor解决了什么问题？</title>
   <link href="/2017/07/10/learning-akka-6.html"/>
   <updated>2017-07-10T00:00:00+08:00</updated>
   <id>urn:uuid:85cf4b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这段时间由于忙毕业前前后后的事情，拖更了很久，表示非常抱歉，回归后的第一篇文章主要是看到了Akka最新文档中写的&lt;a href=&quot;http://doc.akka.io/docs/akka/current/scala/guide/actors-intro.html&quot;&gt;What problems does the actor model solve?&lt;/a&gt;,阅读完后觉得还是蛮不错，能简洁清晰的阐述目前并发领域遇到的问题，并为何利用Actor模型可以解决这些问题，本文主要是利用自己的理解将这篇文章进行翻译，有不足之处还请指出。&lt;/p&gt;

&lt;h2&gt;Actor解决了什么问题？&lt;/h2&gt;

&lt;p&gt;Akka使用Actor模型来克服传统面向对象编程模型的局限性，并应对高并发分布式系统所带来的挑战。 充分理解Actor模型是必需的，它有助于我们认识到传统的编程方法在并发和分布式计算的领域上的不足之处。&lt;/p&gt;

&lt;h3&gt;封装的弊端&lt;/h3&gt;

&lt;p&gt;面向对象编程（OOP）是一种广泛采用的，熟悉的编程模型，它的一个核心理念就是封装，并规定对象封装的内部数据不能从外部直接访问，只允许相关的属性方法进行数据操作，比如我们熟悉的Javabean中的getX，setX等方法，对象为封装的内部数据提供安全的数据操作。&lt;/p&gt;

&lt;p&gt;举个例子，有序二叉树必须保证树节点数据的分布规则，若你想利用有序二叉树进行查询相关数据，就必须要依赖这个约束。&lt;/p&gt;

&lt;p&gt;当我们在分析面向对象编程在运行时的行为时，我们可能会绘制一个消息序列图，用来显示方法调用时的交互，如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart.png&quot; alt=&quot;seq chart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但上述图表并不能准确地表示实例在执行过程中的生命线。实际上，一个线程执行所有这些调用，并且变量的操作也在调用该方法的同一线程上。为刚才的序列图加上执行线程，看起来像这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart-thread.png&quot; alt=&quot;seq chart thread&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但当在面对多线程的情况下，会发现此前的图越来越混乱和变得不清晰，现在我们模拟多个线程访问同一个示例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/seq-chart-multi-thread.png&quot; alt=&quot;seq chart multi thread&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在上面的这种情况中，两个线程调用同一个方法，但别调用的对象并不能保证其封装的数据发生了什么，两个调用的方法指令可以任意方式的交织，无法保证共享变量的一致性，现在，想象一下在更多线程下这个问题会更加严重。&lt;/p&gt;

&lt;p&gt;解决这个问题最通常的方法就是在该方法上加锁。通过加锁可以保证同一时刻只有一个线程能进入该方法，但这是一个代价非常昂贵的方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;锁非常严重的限制并发，它在现在的CPU架构上代价是非常大的，它需要操作系统暂停和重启线程。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;调用者的线程会被阻塞，以致于它不能去做其他有意义的任务，举个例子我们希望桌面程序在后台运行的时候，操作UI界面也能得到响应。在后台，，线程阻塞完全是浪费的，有人可能会说可以通过启动新线程进行补偿，但线程也是一种非常昂贵的资源。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用锁会导致一个新的问题：死锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这些现实存在的问题让我们只能两者选一：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;不使用锁，但会导致状态混乱。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用大量的锁，但是会降低性能并很容易导致死锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;另外，锁只能在本地更好的利用，当我们的程序部署在不同的机器上时，我们只能选择使用分布式锁，但不幸的是，分布式锁的效率可能比本地锁低好几个量级，对后续的扩展也会有很大的限制，分布式锁的协议要求多台机器在网络上进行相互通信，因此延迟可能会变得非常高。&lt;/p&gt;

&lt;p&gt;在面向对象语言中，我们很少会去考虑线程或者它的执行路径，我们通常将系统想象成许多实例对象连接成的网络，通过方法调用，修改实例对象内部的状态，然后通过实例对象之前的方法调用驱动整个程序进行交互：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/object-graph.png&quot; alt=&quot;object graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后，在多线程分布式环境中，实际上线程是通过方法调用遍历这个对象实例网络。因此，线程是方法调用驱动执行的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/object-graph-snakes.png&quot; alt=&quot;object graph snakes&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对象只能保证在单一线程中封装数据的正确性，在多线程环境下可能会导致状态混乱，在同一个代码段，两个竞争的线程可能导致变量的不一致。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用锁看起来可以在多线程环境下保证封装数据的正确性，但实际上它在程序真是运行时是低效的并且很容易导致死锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁在单机工作可能还不错，但是在分布式的环境表现的很不理想，扩展性很差。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;共享内存在现代计算机架构上的弊端&lt;/h3&gt;

&lt;p&gt;在80-90年代的编程模型概念中，写一个变量相当于直接把它写入内存，但是在现代的计算机架构中，我们做了一些改变，写入相应的缓存中而不是直接写入内存，大多数缓存都是CPU核心的本地缓存，但是由一个CPU写入的缓存对其他CPU是不可见的。为了让本地缓存的变化对其他CPU或者线程可见的话，缓存必须进行交互。&lt;/p&gt;

&lt;p&gt;在JVM上，我们必须使用volatile标识或者Atomic包装类来保证内存对跨线程的共享，否则，我们只能用锁来保证共享内存的正确性。那么我们为什么不在所有的变量上都加volatile标识呢？因为在缓存间交互信息是一个代价非常昂贵的操作，而且这个操作会隐式的阻止CPU核心不能去做其他的工作，并且会导致缓存一致性协议（缓存一致性协议是指CPU用于在主内存和其他CPU之间传输缓存）的瓶颈。&lt;/p&gt;

&lt;p&gt;即使开发者认识到这些问题，弄清楚哪些内存位置需要使用volatile标识或者Atomic包装类，但这并非是一种很好的解决方案，可能到程序后期，你都不清楚自己做了什么。&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;没有真正的共享内存了，CPU核心就像网络上的计算机一样，将数据块（高速缓存行）明确地传递给彼此。CPU间的通信和网络通信有更多的共同点。 现在通过CPU或网络计算机传递消息是标准的。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用共享内存标识或者Atomic数据结构来代替隐藏消息传递，其实有一种更加规范的方法就是将共享状态保存在并发实体内，并明确并发实体间通过消息来传递事件和数据。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;调用堆栈的弊端&lt;/h3&gt;

&lt;p&gt;今天，我们还经常调用堆栈来进行任务执行，但是它是在并发并不那么重要的时代发明的，因为当时多核的CPU系统并不常见。调用堆栈不能跨线程，所以不能进行异步调用。&lt;/p&gt;

&lt;p&gt;线程在将任务委托后台执行会出现一个问题，实际中，是将任务委托给另一个线程执行，这不是简单的方法调用，而是有本地的线程直接调用执行，通常来说，一个调用者线程将任务添加到一个内存位置中，具体的工作线程可以不断的从中选取任务进行执行，这样的话，调用者线程不必阻塞可以去做一些其他的任务了。&lt;/p&gt;

&lt;p&gt;但是这里有几个问题，第一个就是调用者如何受到任务完成的通知？还有一个更重要的问题是当任务发生异常出现错误后，异常会被谁处理？异常将会被具体执行任务的工作线程所处理并不会关心是哪个调用者调用的任务：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/exception-prop.png&quot; alt=&quot;exception prop&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是一个很严重的问题，具体执行任务的线程是怎么处理这种状况的？具体执行任务去处理这个问题并不是一个好的方案，因为它并不清楚该任务执行的真正目的，而且调用者应该被通知发生了什么，但是实际上并没有这样的结构去解决这个问题。假如并不能正确的通知，调用者线程将不会的到任何错误的信息甚至任务都会丢失。这就好比在网络上你的请求失败或者消息丢失却得不到任何的通知。&lt;/p&gt;

&lt;p&gt;在某些情况，这个问题可能会变得更糟糕，工作线程发生了错误但是其自身却无法恢复。比如一个由bug引起的内部错误导致了线程的关闭，那么会导致一个问题，到底应该由谁来重启线程并且保存线程之前的状态呢？表面上看，这个问题是可以解决的，但又会有一个新的意外可能发生，当工作线程正在执行任务的时候，它便不能共享任务队列，而事实上，当一个异常发生后，并逐级上传，最终可能导致整个任务队列的状态全部丢失。所以说即使我们在本地交互也可能存在消息丢失的情况。&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;实现任何一个高并发且高效性能的系统，线程必须将任务有效率的委托给别的线程执行以至不会阻塞，这种任务委托的并发方式在分布式的环境也适用，但是需要引入错误处理和失败通知等机制。失败成为这种领域模型的一部分。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;并发系统适用任务委托机制需要去处理服务故障也就意味需要在发生故障后去恢复服务，但实际情况下，重启服务可能会丢失消息，即使没有发生这种情况，调用者得到的回应也可能因为队列等待，垃圾回收等影响而延迟，所以，在真正的环境中，我们需要设置请求回复的超时时间，就像在网络系统亦或者分布式系统。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;为什么在高并发，分布式系统需要Actor模型？&lt;/h2&gt;

&lt;p&gt;综上所述，通常的编程模型并不适用现代的高并发分布式系统，幸运的是，我们可以不必抛弃我们了解的知识，另外，Actor用很好的方式帮我们克服了这些问题，它让我们以一种更好的模型去实现我们的系统。&lt;/p&gt;

&lt;p&gt;我们重点需求的是以下几个方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用封装，但是不使用锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;构建一种实体能够处理消息，更改状态，发送消息用来推动整个程序运行。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;不必担心程序执行与真实环境的不匹配。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Actor模型能帮我们实现这些目标，以下是具体描述。&lt;/p&gt;

&lt;h3&gt;使用消息机制避免使用锁以防止阻塞&lt;/h3&gt;

&lt;p&gt;不同于方法调用，Actor模型使用消息进行交互。发送消息的方式不会将发送消息方的执行线程转换为具体的任务执行线程。Actor可以不断的发送和接收消息但不会阻塞。因此它可以做更多的工作，比如发送消息和接收消息。&lt;/p&gt;

&lt;p&gt;在面对对象编程上，直到一个方法返回后，才会释放对调用者线程的控制。在这这一方面上，Actor模型跟面对对象模型类似，它对消息做出处理，并在消息处理完成后返回执行。我们可以模拟这种执行模式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/actor-graph.png&quot; alt=&quot;actor graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是这种方式与方法调用方式最大的区别就是没有返回值。通过发送消息，Actor将任务委托给另一Actor执行。就想我们之前说的堆栈调用一样，加入你需要一个返回值，那么发送Actor需要阻塞或者与具体执行任务的Actor在同一个线程中。另外，接收Actor以消息的方式返回结果。&lt;/p&gt;

&lt;p&gt;第二个关键的变化是继续保持封装。Actor对消息处理就就跟调用方法一样，但是不同的是，Actor在多线程的情况下能保证自身内部的状态和变量不会被破坏，Actor的执行独立于发送消息的Actor，并且同一个Actor在同一个时刻只处理一个消息。每个Actor有序的处理接收的消息，所以一个Actor系统中多个Actor可以并发的处理自己的消息，充分的利用多核CPU。因为一个Actor同一时刻最多处理一个消息，所以它不需要同步机制保障变量的一致性。所以说它并不需要锁：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/serialized-timeline-invariants.png&quot; alt=&quot;serialized timeline invariants&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总而言之，Actor执行的时候会发生以下行为：&lt;/p&gt;

&lt;p&gt;1.Actor将消息加入到消息队列的尾部。
2.假如一个Actor并未被调度执行，则将其标记为可执行。
3.一个（对外部不可见）调度器对Actor的执行进行调度。
4.Actor从消息队列头部选择一个消息进行处理。
5.Actor在处理过程中修改自身的状态，并发送消息给其他的Actor。
6.Actor&lt;/p&gt;

&lt;p&gt;为了实现这些行为，Actor必须有以下特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;邮箱（作为一个消息队列）&lt;/li&gt;
&lt;li&gt;行为（作为Actor的内部状态，处理消息逻辑）&lt;/li&gt;
&lt;li&gt;消息（请求Actor的数据，可看成方法调用时的参数数据）&lt;/li&gt;
&lt;li&gt;执行环境（比如线程池，调度器，消息分发机制等）&lt;/li&gt;
&lt;li&gt;位置信息（用于后续可能会发生的行为）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;消息会被添加到Actor的信箱中，Actor的行为可以看成Actor是如何对消息做出回应的（比如发送更多消息或者修改自身状态）。执行环境提供一组线程池，用于执行Actor的这些行为操作。&lt;/p&gt;

&lt;p&gt;Actor是一个非常简单的模型而且它可以解决先前提到的问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;继续使用封装，但通过信号机制保障不需传递执行（方法调用需要传递执行线程，但发送消息不需要）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;不需要任何的锁，修改Actor内部的状态只能通过消息，Actor是串行处理消息，可以保障内部状态和变量的正确性。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;因为不会再任何地方使用锁，所以发送者不会被阻塞，成千上万个Actor可以被合理的分配在几十个线程上执行，充分利用了现代CPU的潜力。任务委托这个模式在Actor上非常适用。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Actor的状态是本地的，不可共享的，变化和数据只能通过消息传递。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Actor优雅的处理错误&lt;/h3&gt;

&lt;p&gt;Actor不再使用共享的堆栈调用，所以它要以不同的方式去处理错误。这里有两种错误需要考虑：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;第一种情况是当任务委托后再目标Actor上由于任务本身错误而失败了（典型的如验证错误，比如不存在的用户ID）。在这个情况下，Actor服务本身是正确的，只是相应的任务出错了。服务Actor应该想发送Actor发送消息，已告知错误情况。这里没什么特殊的，错误作为Actor模型的一部分，也可以当做消息。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;第二种情况是当服务本身遇到内部故障时。Akka强制所有Actor被组织成一个树状的层次结构，即创建另一个Actor的Actor成为该新Actor的分级。 这与操作系统将流程组合到树中非常相似。就像进程一样，当一个Actor失败时，它的父actor被通知，并对失败做出反应。此外，如果父actor停止，其所有子Actor也被递归停止。这中形式被称为监督，它是Akka的核心：&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/media/images/2017/07/actor-tree-supervision.png&quot; alt=&quot;actor tree supervision&quot; /&gt;&lt;/p&gt;

&lt;p&gt;监管者可以根据被监管者（子Actor）的失败的错误类型来执行不同的策略，比如重启该Actor或者停止该Actor让其它Actor代替执行任务。一个Actor不会无缘无故的死亡（除非出现死循环之类的情况），而是失败，并可以将失败传递给它的监管者让其做出相应的故障处理策略，当然也可能会被停止（若被停止，也会接收到相应的消息指令）。一个Actor总有监管者就是它的父级Actor。Actor重新启动是不可见的，协作Actor可以帮其代发消息直到目标Actor重启成功。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（五）：Java和Scala中的Future</title>
   <link href="/2017/05/15/learning-akka-5.html"/>
   <updated>2017-05-15T00:00:00+08:00</updated>
   <id>urn:uuid:85cf4b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;随着CPU的核数的增加，异步编程模型在并发领域中的得到了越来越多的应用，由于Scala是一门函数式语言，天然的支持异步编程模型，今天主要来看一下Java和Scala中的Futrue，带你走入异步编程的大门。&lt;/p&gt;

&lt;h2&gt;Future&lt;/h2&gt;

&lt;p&gt;很多同学可能会有疑问，Futrue跟异步编程有什么关系？从Future的表面意思是未来，一个Future对象可以看出一个将来得到的结果，这就和异步执行的概念很像，你只管自己去执行，只要将最终的结果传达给我就行，线程不必一直暂停等待结果，可以在具体异步任务执行的时候去执行其他操作，举个例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/async-work.png&quot; alt=&quot;async work&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们现在在执行做饭这么一个任务，它需要煮饭，烧菜，摆置餐具等操作，如果我们通过异步这种概念去执行这个任务，比如煮饭可能需要比较久的时间，但煮饭这个过程又不需要我们管理，我们可以利用这段时间去烧菜，烧菜过程中也可能有空闲时间，我们可以去摆置餐具，当电饭锅通知我们饭烧好了，菜也烧好了，最后我们就可以开始吃饭了，所以说，上面的“&lt;strong&gt;煮饭 -&gt; 饭&lt;/strong&gt;”，“&lt;strong&gt;烧菜 -&gt; 菜&lt;/strong&gt;”都可以看成一个Future的过程。&lt;/p&gt;

&lt;h3&gt;Java中的Future&lt;/h3&gt;

&lt;p&gt;在Java的早期版本中，我们不能得到线程的执行结果，不管是继承Thread类还是实现Runnable接口，都无法获取线程的执行结果，所以我们只能在线程执行的run方法里去做相应的一些业务逻辑操作，但随着Java5的发布，它为了我们带来了Callable和Future接口，我们可以利用这两个接口的特性来获取线程的执行结果。&lt;/p&gt;

&lt;h4&gt;Callable接口&lt;/h4&gt;

&lt;p&gt;通俗的讲，Callable接口也是一个线程执行类接口，那么它跟Runnable接口有什么区别呢？我们先来看看它们两个的定义：&lt;/p&gt;

&lt;p&gt;1.Callable接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;@FunctionalInterface
public interface Callable&amp;lt;V&amp;gt; {
    /**
     * Computes a result, or throws an exception if unable to do so.
     *
     * @return computed result
     * @throws Exception if unable to compute a result
     */
    V call() throws Exception;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.Runnable接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;@FunctionalInterface
public interface Runnable {
    public abstract void run();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的定义，我们可以看出，两者最大的区别就是对应的执行方法是否有返回值。Callable接口中call方法具有返回值，这便是为什么我们可以通过Callable接口来得到一个线程执行的返回值或者是异常信息。&lt;/p&gt;

&lt;h4&gt;Future接口&lt;/h4&gt;

&lt;p&gt;上面说到既然Callable接口能返回线程执行的结果，那么为什么还需要Future接口呢？因为Callable接口执行的结果只是一个将来的结果值，我们若是需要得到具体的结果就必须利用Future接口，另外Callable接口需要委托ExecutorService的submit提交任务去执行，我们来看看它是如何定义的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt; &amp;lt;T&amp;gt; Future&amp;lt;T&amp;gt; submit(Callable&amp;lt;T&amp;gt; task);

 public &amp;lt;T&amp;gt; Future&amp;lt;T&amp;gt; submit(Callable&amp;lt;T&amp;gt; task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture&amp;lt;T&amp;gt; ftask = newTaskFor(task);
        execute(ftask);
        return ftask;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从submit的方法定义也可以看出它的返回值是一个Future接口类型的值，这里其实是RunnableFuture接口，这是一个很重要的接口，我们来看一下它的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public interface RunnableFuture&amp;lt;V&amp;gt; extends Runnable, Future&amp;lt;V&amp;gt; {
    /**
     * Sets this Future to the result of its computation
     * unless it has been cancelled.
     */
    void run();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个接口分别继承了Runnable和Future接口，而FutureTask又实现了RunnableFuture接口，它们之间的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/future-runnable.png&quot; alt=&quot;future runnable&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RunnableFuture有以下两个特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;继承Runnable接口，还是以run方法作为线程执行入口，其实上面submit方法的具体实现也可以看出，一个Callable的Task再执行的时候会被包装成RunnableFuture，然后以FutureTask作为实现类，执行FutureTask时，还是执行其的run方法，只不过run方法里面的业务逻辑是由我们定义的call方法的内容，当然再执行run方法时，程序会自动将call方法的执行结果帮我们包装起来，对外部表现成一个Future对象。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;继承Future接口，通过实现Future接口中的方法更新或者获取线程的的执行状态，比如其中的cancel(),isDone(),get()等方法。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Future程序示例与结果获取&lt;/h4&gt;

&lt;p&gt;下面是一个简单的Future示例，我们先来看一下代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;ExecutorService es = Executors.newSingleThreadExecutor();
Future f = es.submit(() -&amp;gt; {
        System.out.println(&quot;execute call&quot;);
        Thread.sleep(1000);
        return 5;
    });
try {
    System.out.println(f.isDone()); //检测任务是否完成
    System.out.println(f.get(2000, TimeUnit.MILLISECONDS));
    System.out.println(f.isDone()); //检测任务是否完成
} catch (InterruptedException e) {
    e.printStackTrace();
} catch (ExecutionException e) {
    e.printStackTrace();
} catch (TimeoutException e) {
    e.printStackTrace();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码使用了lambda表达式，有兴趣的同学可以自己去了解下，这里我们首先构建了一个ExecutorService，然后利用submit提交执行Callable接口的任务。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么是Callable接口呢？&lt;/strong&gt; 其实这里我们并没有显示声明Callable接口，这里lambda会帮我们自动进行类型推导，首先submit接受Callable接口或Runnble接口类型作为参数，而这里我们又给定了返回值，所以lambda能自动帮我们推导出内部是一个Callable接口参数。&lt;/p&gt;

&lt;p&gt;到这里我们应该大致清楚了在Java中的得到Future，那么我们又是如何从Future中得到我们想要的值呢？这个结论其实很容易得出，你只需要去跑一下上面的程序即可，在利用get去获取Future中的值时，线程会一直阻塞，直到返回值或者超时，所以Future中的get方法是阻塞，所以虽然利用Future似乎是异步执行任务，但是在某些需求上还是会阻塞的，并不是真正的异步，stackoverflow上有两个讨论说明了这个问题&lt;a href=&quot;http://stackoverflow.com/questions/31092067/method-call-to-future-get-blocks-is-that-really-desirable&quot;&gt;Future.get&lt;/a&gt;，&lt;a href=&quot;http://stackoverflow.com/questions/31092067/method-call-to-future-get-blocks-is-that-really-desirable&quot;&gt;without blocking when task complete&lt;/a&gt;，有兴趣的同学可以去看看。&lt;/p&gt;

&lt;h3&gt;Scala中的Future&lt;/h3&gt;

&lt;p&gt;Scala中的Future相对于Java的Future有什么不同呢？我总结了一下几点：&lt;/p&gt;

&lt;h4&gt;1.创建Future变得很容易&lt;/h4&gt;

&lt;p&gt;异步编程作为函数式语言的一大优势，Scala对于Future的支持也是非常棒的，首先它也提供了Futrue接口，但不同的是我们在构建Future对象是不用像Java一样那么繁琐，并且非常简单，举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;import scala.concurrent._ 
import ExecutionContext.Implicits.global 

val f: Future[String] = Future { &quot;Hello World!&quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是不是非常简单，也大大降低了我们使用Future的难度。&lt;/p&gt;

&lt;h4&gt;2.提供真正异步的Future&lt;/h4&gt;

&lt;p&gt;前面我们也说到，Java中的Future并不是全异步的，当你需要Future里的值的时候，你只能用get去获取它，亦或者不断访问Future的状态，若完成再去取值，但其意义上便不是真正的异步了，它在获取值的时候是一个阻塞的操作，当然也就无法执行其他的操作，直到结果返回。&lt;/p&gt;

&lt;p&gt;但在Scala中，我们无需担心，虽然它也提供了类似Java中获取值的方式，比如：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Future        &lt;/th&gt;
&lt;th style=&quot;text-align:center;&quot;&gt; Java          &lt;/th&gt;
&lt;th style=&quot;text-align:right;&quot;&gt; Scala  &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; 判断任务是否完成 &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; isDone        &lt;/td&gt;
&lt;td style=&quot;text-align:right;&quot;&gt; isCompleted &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; 获取值          &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; get          &lt;/td&gt;
&lt;td style=&quot;text-align:right;&quot;&gt;   value &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;但是我们并不推荐这么做，因为这么做又回到了Java的老路上了，在Scala中我们可以利用Callback来获取它的结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val fut = Future {
    Thread.sleep(1000)
    1 + 1
}

fut onComplete {
    case Success(r) =&amp;gt; println(s&quot;the result is ${r}&quot;)
    case _ =&amp;gt; println(&quot;some Exception&quot;)
}

println(&quot;I am working&quot;)
Thread.sleep(2000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是一个简单的例子，Future在执行完任务后会进行回调，这里使用了onComplete，也可以注册多个回调函数，但不推荐那么做，因为你不能保证这些回调函数的执行顺序，其他的一些回调函数基本都是基于onComplete的，有兴趣的同学可以去阅读一下Future的源码。&lt;/p&gt;

&lt;p&gt;我们先来看一下它的运行结果:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;I am working
the result is 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从结果中我们可以分析得出，我们在利用Callback方式来获取Future结果的时候并不会阻塞，而只是当Future完成后会自动调用onComplete，我们只需要根据它的结果再做处理即可，而其他互不依赖的操作可以继续执行不会阻塞。&lt;/p&gt;

&lt;h4&gt;3.强大的Future组合&lt;/h4&gt;

&lt;p&gt;前面我们讲的较多的都是单个Future的情况，但是在真正实际应用时往往会遇到多个Future的情况，那么在Scala中是如何处理这种情况的呢？&lt;/p&gt;

&lt;p&gt;Scala中的有多种方式来组合Future,那我们就来看看这些方式吧。&lt;/p&gt;

&lt;h5&gt;1.flatMap&lt;/h5&gt;

&lt;p&gt;我们可以利用flatMap来组合多个Future，不多说，先上代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val fut1 = Future {
  println(&quot;enter task1&quot;)
  Thread.sleep(2000)
  1 + 1
}

val fut2 = Future {
  println(&quot;enter task2&quot;)
  Thread.sleep(1000)
  2 + 2
}

fut1.flatMap { v1 =&amp;gt;
  fut2.map { v2 =&amp;gt;
    println(s&quot;the result is ${v1 + v2}&quot;)
  }
}
Thread.sleep(2500)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;利用flatMap确实能组合Future，但代码的阅读性实在是有点差，你能想象5个甚至10个map层层套着么，所以我们并不推荐这么做，但是我们需要了解这种方式，其他简洁的方式可能最终转化成的版本也许就是这样的。&lt;/p&gt;

&lt;h5&gt;2.for yield表达式&lt;/h5&gt;

&lt;p&gt;我们只是把上面关于flatMap的代码替换一下，看下面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;for {
  v1 &amp;lt;- fut1
  v2 &amp;lt;- fut2
} yield println(s&quot;the result is ${v1 + v2}&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看上去是不是比之前的方式简洁多了，这也是我们在面对Future组合时推荐的方式，当然不得不说for yield表达式是一种语法糖，它最终还是会被翻译成我们常见的方法，比如flatMap，map，filter等，感兴趣的可以参考它的官方文档。&lt;a href=&quot;http://docs.scala-lang.org/tutorials/FAQ/yield.html&quot;&gt;for yield表达式&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;3.scala-async&lt;/h5&gt;

&lt;p&gt;另外我们可以用scala-async来组装Futrue语句块，示例如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;import scala.async.Async.{async, await}

val v1 = async {
  await(fut1) + await(fut2)
}

v1 foreach {
  case r =&amp;gt; println(s&quot;the result is ${v1}&quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种方式与for yield表达式有啥区别呢？其实主要有两点：
- 表达语意更加清晰，不需要用为中间值命名
- 不需要&lt;code&gt;&amp;lt;-&lt;/code&gt;等表达式，可减少一定的代码量&lt;/p&gt;

&lt;p&gt;scala-async相关的具体信息可以参考它的项目主页。&lt;a href=&quot;https://github.com/scala/async&quot;&gt;scala-async&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;总的来说Scala中的Future确实强大，在实现真正异步的情况下，为我们提供许多方便而又简洁的操作模式，其实比如还有Future.reduce()，Future.traverse(),Future.sequence()等方法，这些方法的具体功能和具体使用这里就不讲了，但相关的示例代码都会在我的示例工程里，有兴趣的同学可以去跑跑加深理解。&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_04&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;这篇文章主要讲解了JVM生态上两大语言Java和Scala在异步编程上的一些表现，这里主要是Future机制，在清楚明白它的概念后，我们才能写出更好的程序，虽然本篇文章没有涉及到Akka相关的内容，但是Akka本身是用Scala写的，而且大量使用了Scala中的Future，相信通过对Future的学习，对Akka的理解会有一定的帮助。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（四）：Akka中的共享内存模型</title>
   <link href="/2017/05/01/learning-akka-4.html"/>
   <updated>2017-05-01T00:00:00+08:00</updated>
   <id>urn:uuid:8ecf4b63-e920-3d54-8ca7-fbvbdc2a2fad</id>
   <content type="html">&lt;p&gt;通过前几篇的学习，相信大家对Akka应该有所了解了，都说解决并发哪家强，JVM上面找Akka，那么Akka到底在解决并发问题上帮我们做了什么呢？&lt;/p&gt;

&lt;h2&gt;共享内存&lt;/h2&gt;

&lt;p&gt;众所周知，在处理并发问题上面，最核心的一部分就是如何处理共享内存，很多时候我们都需要花费很多时间和精力在共享内存上，那么在学习Akka对共享内存是如何管理之前，我们先来看看Java中是怎么处理这个问题的。&lt;/p&gt;

&lt;h3&gt;Java共享内存&lt;/h3&gt;

&lt;p&gt;相信对Java并发有所了解的同学都应该知道在Java5推出JSR 133后，Java对内存管理有了更高标准的规范了，这使我们开发并发程序也有更好的标准了，不会有一些模糊的定义导致的无法确定的错误。&lt;/p&gt;

&lt;p&gt;首先来看看一下Java内存模型的简单构图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/java-memory.png&quot; alt=&quot;Java Memory&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从图中我们可以看到我们线程都有自己的一个工作内存，这就好比高速缓存，它是对主内存部分数据的拷贝，线程对自己工作内存的操作速度远远快于对主内存的操作，但这也往往会引起共享变量不一致的问题，比如以下一个场景：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;int a = 0;
public void setA() {
  a = a + 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面是一个很简单的例子，a是一个全局变量，然后我们有一个方法去修改这个值，每次增加一，假如我们用100个线程去运行这段代码，那a最终的结果会是多少呢？
100？显然不一定，它可能是80，90，或者其他数，这就造成共享变量不一致的问题，那么为什么会导致这个问题呢，就是我们上面所说的，线程去修改a的时候可能就只是修改了自己工作内存中a的副本，但并没有将a的值及时的刷新到主内存中，这便会导致其他线程可能读到未被修改a的值，最终出现变量不一致问题。&lt;/p&gt;

&lt;p&gt;那么Java中是怎么处理这种问题，如何保证共享变量的一致性的呢？&lt;/p&gt;

&lt;h4&gt;同步机制&lt;/h4&gt;

&lt;p&gt;大体上Java中有3类同步机制，但它们所解决的问题并不相同，我们先来看一看这三种机制：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;final关键词&lt;/li&gt;
&lt;li&gt;volatile关键词&lt;/li&gt;
&lt;li&gt;synchronized关键词（这里代表了所有类似监视锁的机制）&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;1.final关键词&lt;/h5&gt;

&lt;p&gt;写过Java程序的同学对这个关键词应该再熟悉不过了，其基本含义就是&lt;strong&gt;不可变&lt;/strong&gt;，不可变变量，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;final int a = 10;
final String b = &quot;hello&quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不可变的含义在于当你对这些变量或者对象赋初值后，不能再重新去赋值，但对于对象来说，我们不能修改的是它的引用，但是对象内的内容还是可以修改的。下面是一个简单的例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;final User u = new User(1,&quot;a&quot;);
u.id = 2; //可以修改
u = new User(2,&quot;b&quot;); //不可修改
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以在利用final关键词用来保证共享变量的一致性时一定要了解清楚自己的需求，选择合适的方法，另外final变量必须在定义或者构建对象的时候进行初始化，不然会报错。&lt;/p&gt;

&lt;h4&gt;2.volatile关键词&lt;/h4&gt;

&lt;p&gt;很多同学在遇到共享变量不一致的问题后，都会说我在声明变量前加一个volatile就好了，但事实真是这样嘛？答案显然不是。那我们来看看volatile到底为我们做了什么。&lt;/p&gt;

&lt;p&gt;前面我们说过每个线程都有自己的工作内存，很多时候线程去修改一个变量的值只是修改了自己工作内存中副本的值，这便会导致主内存的值并不是最新的，其他线程读取到的变量便会出现问题。volatile帮我们解决了这个问题，它有两个特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;线程每次都会去主内存中读取变量&lt;/li&gt;
&lt;li&gt;线程每次修改变量后的值都会及时更新到主内存中去&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;volatile int a = 0;
public void setA() {
  a = a + 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在线程在执行这段代码时，都会强制去主内存中读取变量的值，修改后也会马上更新到主内存中去，但是这真的能解决共享变量不一致的问题嘛，其实不然，比如我们有这么一个场景：两个线程同时读取了主内存中变量最新的值，这是我们两个线程都去执行修改操作，最后结果会是什么呢？这里就留给大家自己去思考了，其实也很简单的。&lt;/p&gt;

&lt;p&gt;那么volatile在什么场景下能保证线程安全，按照官方来说，有以下两个条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对变量的写操作不依赖于当前值&lt;/li&gt;
&lt;li&gt;该变量没有包含在具有其他变量的不变式中&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;多的方面这里我就不展开了，推荐两篇我觉得写的还不错的文章：&lt;a href=&quot;http://www.cnblogs.com/paddix/p/5428507.html&quot;&gt;volatile的使用及其原理&lt;/a&gt;&lt;a href=&quot;http://blog.csdn.net/vking_wang/article/details/9982709&quot;&gt;volatile的适用场景&lt;/a&gt;&lt;/p&gt;

&lt;h4&gt;3.synchronized关键词&lt;/h4&gt;

&lt;p&gt;很多同学在学习Java并发过程中最先接触的就是synchronized关键词了，它确实能解决我们上述的并发问题，那它到时如何帮我们保证共享变量的一致性的呢？&lt;/p&gt;

&lt;p&gt;简而言之的说，线程在访问请求用synchronized关键词修饰的方法，代码块都会要求获得一个监视器锁，当线程获得了监视器锁后，它才有权限去执行相应的方法或代码块，并在执行结束后释放监视器锁，这便能保证共享内存的一致性了，因为本文主要是讲Akka的共享内存，过多的篇幅就不展开了，这里推荐一篇解析synchronized原理很不错的文章，有兴趣的同学可以去看看：&lt;a href=&quot;http://www.cnblogs.com/paddix/p/5367116.html&quot;&gt;Synchronized及其实现原理&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Akka共享内存&lt;/h3&gt;

&lt;p&gt;Akka中的共享内存是基于Actor模型的，Actor模型提倡的是：&lt;strong&gt;通过通讯来实现共享内存，而不是用共享内存来实现通讯&lt;/strong&gt;，这点是跟Java解决共享内存最大的区别，举个例子：
在Java中我们要去操作共享内存中数据时，每个线程都需要不断的获取共享内存的监视器锁，然后将操作后的数据暴露给其他线程访问使用，用共享内存来实现各个线程之间的通讯，而在Akka中我们可以将共享可变的变量作为一个Actor内部的状态，利用Actor模型本身串行处理消息的机制来保证变量的一致性。&lt;/p&gt;

&lt;p&gt;当然要使用Akka中的机制也必须满足一下两条原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;消息的发送必须先于消息的接收&lt;/li&gt;
&lt;li&gt;同一个Actor对一条消息的处理先于下一条消息处理&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;第二个原则很好理解，就是上面我们说的Actor内部是串行处理消息，那我们来看看第一个原则，为什么要保证消息的发送先于消息的接收，是为了防止我们在创建消息的时候发生了不确定的错误，接收者将可能接收到不正确的消息，导致发生奇怪的异常，主要表现为消息对象未初始化完整时，若没有这条规则保证，Actor收到的消息便会不完整。&lt;/p&gt;

&lt;p&gt;通过前面的学习我们知道Actor是一种比线程更轻量级，抽象程度更高的一种结构，它帮我们规避了我们自己去操作线程，那么Akka底层到底是怎么帮我们去保证共享内存的一致性的呢？&lt;/p&gt;

&lt;p&gt;一个Actor它可能会有很多线程同时向它发送消息，之前我们也说到Actor本身是串行处理的消息的，那它是如何保障这种机制的呢？&lt;/p&gt;

&lt;h4&gt;Mailbox&lt;/h4&gt;

&lt;p&gt;Mailbox在Actor模型是一个很重要的概念，我们都知道向一个Actor发送的消息首先都会被存储到它所对应的Mailbox中，那么我们先来看看MailBox的定义结构(本文所引用的代码都在akka.dispatch.Mailbox.scala中，有兴趣的同学也可以去研究一下）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;private[akka] abstract class Mailbox(val messageQueue: MessageQueue)
  extends ForkJoinTask[Unit] with SystemMessageQueue with Runnable {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很清晰Mailbox内部维护了一个messageQueue这样的消息队列，并继承了Scala自身定义的ForkJoinTask任务执行类和我们很熟悉的Runnable接口，由此可以看出，Mailbox底层还是利用Java中的线程进行处理的。那么我们先来看看它的run方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;override final def run(): Unit = {
    try {
      if (!isClosed) { //Volatile read, needed here
        processAllSystemMessages() //First, deal with any system messages
        processMailbox() //Then deal with messages
      }
    } finally {
      setAsIdle() //Volatile write, needed here
      dispatcher.registerForExecution(this, false, false)
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了配合理解，我们这里先来看一下定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@inline
  final def currentStatus: Mailbox.Status = Unsafe.instance.getIntVolatile(this, AbstractMailbox.mailboxStatusOffset)

@inline
  final def isClosed: Boolean = currentStatus == Closed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里我们可以看出Mailbox本身会维护一个状态Mailbox.Status，是一个Int变量,而且是可变的，并且用到volatile来保证了它的可见性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@volatile
  protected var _statusDoNotCallMeDirectly: Status = _ //0 by default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们在回去看上面的代码，run方法的执行过程，首先它会去读取MailBox此时的状态，因为是一个Volatile read，所以能保证读取到的是最新的值，然后它会先处理任何的系统消息，这部分不需要我们太过关心，之后便是执行我们发送的消息，这里我们需要详细看一下processMailbox()的实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
@tailrec private final def processMailbox(
    left:       Int  = java.lang.Math.max(dispatcher.throughput, 1),
    deadlineNs: Long = if (dispatcher.isThroughputDeadlineTimeDefined == true) System.nanoTime + dispatcher.throughputDeadlineTime.toNanos else 0L): Unit =
    if (shouldProcessMessage) {
      val next = dequeue()  //去出下一条消息
      if (next ne null) {
        if (Mailbox.debug) println(actor.self + &quot; processing message &quot; + next)
        actor invoke next
        if (Thread.interrupted())
          throw new InterruptedException(&quot;Interrupted while processing actor messages&quot;)
        processAllSystemMessages()
        if ((left &amp;gt; 1) &amp;amp;&amp;amp; ((dispatcher.isThroughputDeadlineTimeDefined == false) || (System.nanoTime - deadlineNs) &amp;lt; 0))
          processMailbox(left - 1, deadlineNs) //递归处理下一条消息
      }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上述代码中我们可以清晰的看到，当满足消息处理的情况下就会进行消息处理，从消息队列列取出下一条消息就是上面的&lt;code&gt;dequeue()&lt;/code&gt;,然后将消息发给具体的Actor进行处理，接下去又是处理系统消息，然后判断是否还有满足情况需要下一条消息，若有则再次进行处理，可以看成一个递归操作,&lt;code&gt;@tailrec&lt;/code&gt;也说明了这一点，它表示的是让编译器进行尾递归优化。&lt;/p&gt;

&lt;p&gt;现在我们来看一下一条消息从发送到最终处理在Akka中到底是怎么执行的，下面的内容是我通过阅读Akka源码加自身理解得出的，这里先画了一张流程图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/05/actor-process.png&quot; alt=&quot;Actor process&quot; /&gt;&lt;/p&gt;

&lt;p&gt;消息的大致流程我都在图中给出，还有一些细节，必须序列化消息，获取状态等就没有具体说明了，有兴趣的同学可以自己去阅读以下Akka的源码，个人觉得Akka的源码阅读性还是很好的，比如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;基本没有方法超过20行&lt;/li&gt;
&lt;li&gt;不会有过多的注释，但关键部分会给出，更能加深自己的理解&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;当然也有一些困扰，我们在不了解各个类，接口之间的关系时，阅读体验就会变得很糟糕，当然我用IDEA很快就解决了这个问题。&lt;/p&gt;

&lt;p&gt;我们这里来看看关键的部分：&lt;strong&gt;Actor是如何保证串行处理消息的？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上图中有一根判定，是否已有线程在执行任务？我们来看看这个判定的具体逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@tailrec
  final def setAsScheduled(): Boolean = {  //是否有线程正在调度执行该MailBox的任务
    val s = currentStatus
    /*
     * Only try to add Scheduled bit if pure Open/Suspended, not Closed or with
     * Scheduled bit already set.
     */
    if ((s &amp;amp; shouldScheduleMask) != Open) false
    else updateStatus(s, s | Scheduled) || setAsScheduled()
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从注释和代码的逻辑上我们可以看出当已有线程在执行返回false，若没有则去更改状态为以调度，直到被其他线程抢占或者更改成功，其中updateStatus()是线程安全的，我们可以看一下它的实现,是一个CAS操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;@inline
  protected final def updateStatus(oldStatus: Status, newStatus: Status): Boolean =
    Unsafe.instance.compareAndSwapInt(this, AbstractMailbox.mailboxStatusOffset, oldStatus, newStatus)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里我们应该可以大致清楚Actor内部是如何保证共享内存的一致性了，Actor接收消息是多线程的，但处理消息是单线程的，利用MailBox中的Status来保障这一机制。&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;通过上面的内容我们可以总结出以下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Akka并不是说用了什么特殊魔法来保证并发的，底层使用的还是Java和JVM的同步机制&lt;/li&gt;
&lt;li&gt;Akka并没有使用任何的锁机制，这就避免了死锁的可能性&lt;/li&gt;
&lt;li&gt;Akka并发执行的处理并没有使用线程切换，不仅提高了线程的使用效率，也大大减少了线程切换消耗&lt;/li&gt;
&lt;li&gt;Akka为我们提供了更高层次的并发抽象模型，让我们不必关心底层的实现，只需着重实现业务逻辑就行，遵循它的规范，让框架帮我们处理一切难点&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Akka系列（三）：监管与容错</title>
   <link href="/2017/04/15/learning-akka-3.html"/>
   <updated>2017-04-15T00:00:00+08:00</updated>
   <id>urn:uuid:85cf4b63-e930-3d54-8ca7-fbvbdc2a2fad</id>
   <content type="html">&lt;p&gt;Akka作为一种成熟的生产环境并发解决方案，必须拥有一套完善的错误异常处理机制，本文主要讲讲Akka中的监管和容错。&lt;/p&gt;

&lt;h2&gt;监管&lt;/h2&gt;

&lt;p&gt;看过我上篇文章的同学应该对Actor系统的工作流程有了一定的了解&lt;a href=&quot;http://www.godpan.me/blog/akka-2/&quot;&gt;Akka系列（二）：Akka中的Actor系统&lt;/a&gt;，它的很重要的概念就是分而治之，既然我们把任务分配给Actor去执行，那么我们必须去监管相应的Actor，当Actor出现了失败，比如系统环境错误，各种异常，能根据我们制定的相应监管策略进行错误恢复，就是后面我们会说到的容错。&lt;/p&gt;

&lt;h3&gt;监管者&lt;/h3&gt;

&lt;p&gt;既然有监管这一事件，那必然存在着&lt;strong&gt;监管者&lt;/strong&gt;这么一个角色，那么在ActorSystem中是如何确定这种角色的呢？&lt;/p&gt;

&lt;p&gt;我们先来看下ActorSystem中的顶级监管者：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/04/actor-syatem-guardian.png&quot; alt=&quot;Actor系统顶级监管者&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个actor系统在其创建过程中至少要启动三个actor，如上图所示，下面来说说这三个Actor的功能：&lt;/p&gt;

&lt;h4&gt;1.&lt;code&gt;/&lt;/code&gt;： 根监管者&lt;/h4&gt;

&lt;p&gt;顾名思义，它是一个老大，它监管着ActorSystem中所有的顶级Actor，顶级Actor有以下几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/user&lt;/code&gt;： 是所有由用户创建的顶级actor的监管者；用ActorSystem.actorOf创建的actor在其下。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/system&lt;/code&gt;： 是所有由系统创建的顶级actor的监管者，如日志监听器，或由配置指定在actor系统启动时自动部署的actor。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/deadLetters&lt;/code&gt;： 是死信actor，所有发往已经终止或不存在的actor的消息会被重定向到这里。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/temp&lt;/code&gt;：是所有系统创建的短时actor的监管者，例如那些在ActorRef.ask的实现中用到的actor。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/remote&lt;/code&gt;： 是一个人造虚拟路径，用来存放所有其监管者是远程actor引用的actor。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 跟我们平常打交道最多的就是&lt;code&gt;/user&lt;/code&gt;，它是我们在程序中用ActorSystem.actorOf创建的actor的监管者，下面的容错我们重点关心的就是它下面的失败处理，其他几种顶级Actor具体功能定义已经给出，有兴趣的也可以去了解一下。&lt;/p&gt;

&lt;p&gt; 根监管者监管着所有顶级Actor，对它们的各种失败情况进行处理，一般来说如果错误要上升到根监管者，整个系统就会停止。&lt;/p&gt;

&lt;h4&gt;2.&lt;code&gt;/user&lt;/code&gt;： 顶级actor监管者&lt;/h4&gt;

&lt;p&gt;上面已经讲过&lt;code&gt;/user&lt;/code&gt;是所有由用户创建的顶级actor的监管者，即用ActorSystem.actorOf创建的actor，我们可以自己制定相应的监管策略，但由于它是actor系统启动时就产生的，所以我们需要在相应的配置文件里配置，具体的配置可以参考这里&lt;a href=&quot;http://doc.akka.io/docs/akka/current/general/configuration.html&quot;&gt;Akka配置&lt;/a&gt;&lt;/p&gt;

&lt;h4&gt;3.&lt;code&gt;/system&lt;/code&gt;： 系统监管者&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;/system&lt;/code&gt;所有由系统创建的顶级actor的监管者,比如Akka中的日志监听器，因为在Akka中日志本身也是用Actor实现的，&lt;code&gt;/system&lt;/code&gt;的监管策略如下：对收到的除&lt;code&gt;ActorInitializationException&lt;/code&gt;和&lt;code&gt;ActorKilledException&lt;/code&gt;之外的所有&lt;code&gt;Exception&lt;/code&gt;无限地执行重启，当然这也会终止其所有子actor。所有其他Throwable被上升到根监管者，然后整个actor系统将会关闭。&lt;/p&gt;

&lt;p&gt;用户创建的普通actor的监管：&lt;/p&gt;

&lt;p&gt;上一篇文章介绍了Actor系统的组织结构，它是一种树形结构，其实这种结构对actor的监管是非常有利的，Akka实现的是一种叫“父监管”的形式，每一个被创建的actor都由其父亲所监管，这种限制使得actor的监管结构隐式符合其树形结构，所以我们可以得出一个结论：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;一个被创建的Actor肯定是一个被监管者，也可能是一个监管者，它监管着它的子级Actor&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3&gt;监管策略&lt;/h3&gt;

&lt;p&gt;上面我们对ActorSystem中的监管角色有了一定的了解，那么到底是如何制定相应的监管策略呢？Akka中有以下4种策略：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;恢复下属，保持下属当前积累的内部状态&lt;/li&gt;
&lt;li&gt;重启下属，清除下属的内部状态&lt;/li&gt;
&lt;li&gt;永久地停止下属&lt;/li&gt;
&lt;li&gt;升级失败（沿监管树向上传递失败），由此失败自己&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这其实很好理解，下面是一个简单例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt; override val supervisorStrategy =
    OneForOneStrategy(maxNrOfRetries = 10, withinTimeRange = 1 minute) {
      case _: ArithmeticException =&amp;gt; Resume  //恢复
      case _: NullPointerException =&amp;gt; Restart //重启
      case _: IllegalArgumentException =&amp;gt; Stop //停止
      case _: Exception =&amp;gt; Escalate  //向上级传递
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以根据异常的不同使用不同监管策略，在后面我会具体给出一个示例程序帮助大家理解。我们在实现自己的策略时，需要复写Actor中的&lt;code&gt;supervisorStrategy&lt;/code&gt;，因为Actor的默认监管策略如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;  final val defaultDecider: Decider = {
    case _: ActorInitializationException ⇒ Stop
    case _: ActorKilledException         ⇒ Stop
    case _: DeathPactException           ⇒ Stop
    case _: Exception                    ⇒ Restart
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt; 它对除了它指定的异常进行停止，其他异常都是对下属进行重启。&lt;/p&gt;

&lt;p&gt; Akka中有两种类型的监管策略：&lt;code&gt;OneForOneStrategy&lt;/code&gt;和&lt;code&gt;AllForOneStrategy&lt;/code&gt;，它们的主要区别在于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;OneForOneStrategy&lt;/code&gt;： 该策略只会应用到发生故障的子actor上。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AllForOneStrategy&lt;/code&gt;： 该策略会应用到所有的子actor上。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 我们一般都使用&lt;code&gt;OneForOneStrategy&lt;/code&gt;来进行制定相关监管策略，当然你也可以根据具体需求选择合适的策略。另外我们可以给我们的策略配置相应参数，比如上面maxNrOfRetries，withinTimeRange等，这里的含义是每分钟最多进行10次重启，若超出这个界限相应的Actor将会被停止，当然你也可以使用策略的默认配置，具体配置信息可以参考源码。&lt;/p&gt;

&lt;h3&gt;监管容错示例&lt;/h3&gt;

&lt;p&gt;本示例主要演示Actor在发生错误时，它的监管者会根据相应的监管策略进行不同的处理。&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_03&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;因为这个例子比较简单，这里我直接贴上相应代码，后面根据具体的测试用例来解释各种监管策略所进行的响应：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class Supervisor extends Actor {
  //监管下属，根据下属抛出的异常进行相应的处理
  override val supervisorStrategy =
    OneForOneStrategy(maxNrOfRetries = 10, withinTimeRange = 1 minute) {
      case _: ArithmeticException =&amp;gt; Resume
      case _: NullPointerException =&amp;gt; Restart
      case _: IllegalArgumentException =&amp;gt; Stop
      case _: Exception =&amp;gt; Escalate
    }
  var childIndex = 0 //用于标示下属Actor的序号

  def receive = {
    case p: Props =&amp;gt;
      childIndex += 1
      //返回一个Child Actor的引用，所以Supervisor Actor是Child Actor的监管者
      sender() ! context.actorOf(p,s&quot;child${childIndex}&quot;)
  }
}

class Child extends Actor {
  val log = Logging(context.system, this)
  var state = 0
  def receive = {
    case ex: Exception =&amp;gt; throw ex //抛出相应的异常
    case x: Int =&amp;gt; state = x //改变自身状态
    case s: Command if s.content == &quot;get&quot; =&amp;gt;
      log.info(s&quot;the ${s.self} state is ${state}&quot;)
      sender() ! state //返回自身状态
  }
}

case class Command(  //相应命令
    content: String,
    self: String
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们来看看具体的测试用例：
首先我们先构建一个测试环境：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class GuardianSpec(_system: ActorSystem)
    extends TestKit(_system)
    with WordSpecLike
    with Matchers
    with ImplicitSender {

  def this() = this(ActorSystem(&quot;GuardianSpec&quot;))

  &quot;A supervisor&quot; must {

    &quot;apply the chosen strategy for its child&quot; in {
        code here...
        val supervisor = system.actorOf(Props[Supervisor], &quot;supervisor&quot;) //创建一个监管者
        supervisor ! Props[Child]
        val child = expectMsgType[ActorRef] // 从 TestKit 的 testActor 中获取回应
    } 
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.TestOne：正常运行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;child ! 50 // 将状态设为 50
child ! Command(&quot;get&quot;,child.path.name)
expectMsg(50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常运行，测试通过。&lt;/p&gt;

&lt;p&gt;2.TestTwo：抛出ArithmeticException&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;child ! new ArithmeticException // crash it
child ! Command(&quot;get&quot;,child.path.name)
expectMsg(50)     
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;大家猜这时候测试会通过吗？答案是通过，原因是根据我们制定的监管策略，监管者在面对子级Actor抛出&lt;code&gt;ArithmeticException&lt;/code&gt;异常时，它会去恢复相应出异常的Actor，并保持该Actor的状态，所以此时Actor的状态值还是50，测试通过。&lt;/p&gt;

&lt;p&gt;3.TestThree：抛出NullPointerException&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;child ! new NullPointerException // crash it harder
child ! &quot;get&quot;
expectMsg(50)   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种情况下测试还会通过吗？答案是不通过，原因是根据我们制定的监管策略，监管者在面对子级Actor抛出&lt;code&gt;NullPointerException&lt;/code&gt;异常时，它会去重启相应出异常的Actor，其状态会被清除，所以此时Actor的状态值应该是0，测试不通过。&lt;/p&gt;

&lt;p&gt;4.TestFour：抛出IllegalArgumentException&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;supervisor ! Props[Child] // create new child
val child2 = expectMsgType[ActorRef]
child2 ! 100 // 将状态设为 100
watch(child) // have testActor watch “child”
child ! new IllegalArgumentException // break it
expectMsgPF() {
  case Terminated(`child`) =&amp;gt; (println(&quot;the child stop&quot;))
}
child2 ! Command(&quot;get&quot;,child2.path.name)
expectMsg(100)   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里首先我们又创建了一个Child Actor为child2，并将它的状态置为100，这里我们监控前面创建的child1，然后给其发送一个&lt;code&gt;IllegalArgumentException&lt;/code&gt;的消息，让其抛出该异常，测试结果:
&lt;code&gt;
the child stop
测试通过
&lt;/code&gt;
从结果中我们可以看出，child在抛出&lt;code&gt;IllegalArgumentException&lt;/code&gt;后，会被其监管着停止，但监管者下的其他Actor还是正常工作。&lt;/p&gt;

&lt;p&gt;5.TestFive：抛出一个自定义异常&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt; watch(child2)
 child2 ! Command(&quot;get&quot;,child2.path.name) // verify it is alive
 expectMsg(100)
 supervisor ! Props[Child] // create new child
 val child3 = expectMsgType[ActorRef]
 child2 ! new Exception(&quot;CRASH&quot;) // escalate failure
 expectMsgPF() {
    case t @ Terminated(`child2`) if t.existenceConfirmed =&amp;gt; (
       println(&quot;the child2 stop&quot;)
    )
}
child3 ! Command(&quot;get&quot;,child3.path.name)
expectMsg(0)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里首先我们又创建了一个Child Actor为child3,这里我们监控前面创建的child2,然后给其发送一个&lt;code&gt;Exception(&quot;CRASH&quot;)&lt;/code&gt;的消息，让其抛出该异常,测试结果:
&lt;code&gt;
the child2 stop
测试不通过
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;很多人可能会疑惑为什么TestFour可以通过，这里就通不过不了呢？因为这里错误Actor抛出的异常其监管者无法处理，只能将失败上溯传递，而顶级actor的缺省策略是对所有的Exception情况（ActorInitializationException和ActorKilledException例外）进行重启. 由于缺省的重启指令会停止所有的子actor，所以我们这里的child3也会被停止。导致测试不通过。当然这里你也可以复写默认的重启方法，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;override def preRestart(cause: Throwable, msg: Option[Any]) {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样重启相应Actor时就不会停止其子级下的所有Actor了。&lt;/p&gt;

&lt;p&gt;本文主要介绍了Actor系统中的监管和容错，这一部分内容在Akka中也是很重要的，它与Actor的树形组织结构巧妙结合，本文大量参考了Akka官方文档的相应章节，有兴趣的同学可以点击这里&lt;a href=&quot;http://doc.akka.io/docs/akka/2.5/scala/fault-tolerance.html&quot;&gt;Akka docs&lt;/a&gt;。也可以下载我的示例程序，里面包含了一个官方的提供的容错示例。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（二）：Akka中的Actor系统</title>
   <link href="/2017/04/02/learning-akka-2.html"/>
   <updated>2017-04-02T00:00:00+08:00</updated>
   <id>urn:uuid:85cc4b63-e930-3454-8ca7-fbdsdc2a2fad</id>
   <content type="html">&lt;p&gt;Actor模型作为Akka中最核心的概念，所以Actor在Akka中的组织结构也至关重要，本文主要介绍Akka中Actor系统。&lt;/p&gt;

&lt;h2&gt;Actor系统&lt;/h2&gt;

&lt;p&gt;Actor作为一种封装状态和行为的对象，总是需要一个系统去统一的组织和管理它们，在Akka中即为ActorSystem，其实这非常容易理解，好比一个公司，每个员工都可以看成一个Actor，它们有自己的职位和职责，但是我们需要把员工集合起来，统一进行管理和分配任务，所以我们需要一个相应的系统进行管理，好比这里的ActorSystem对Actor进行管理一样。&lt;/p&gt;

&lt;h3&gt;ActorSystem的主要功能&lt;/h3&gt;

&lt;p&gt;ActorSystem主要有以下三个功能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;管理调度服务&lt;/li&gt;
&lt;li&gt;配置相关参数&lt;/li&gt;
&lt;li&gt;日志功能&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;1.管理调度服务&lt;/h4&gt;

&lt;p&gt;ActorSystem的的精髓在于将任务分拆，直到一个任务小到可以被完整处理，然后将其委托给Actor进行处理，所以ActorSystem最核心的一个功能就是管理和调度整个系统的运行，好比一个公司的管理者，他需要制定整个公司的发展计划，还需要将工作分配给相应的工作人员去完成，保障整个公司的正确运转，其实这里也体现了软件设计中的分而治之，Actor中的核心思想也是这样。&lt;/p&gt;

&lt;p&gt;ActorSystem模型例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/04/actor-system-example.png&quot; alt=&quot;ActorSystem模型例子&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是一个简单的开发协作的过程，我觉得这个例子应该可以清晰的表达Akka中Actor的组织结构，当然不仅于此。主要有以下几个特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Akka中Actor的组织是一种树形结构&lt;/li&gt;
&lt;li&gt;每个Actor都有父级，有可能有子级当然也可能没有&lt;/li&gt;
&lt;li&gt;父级Actor给其子级Actor分配资源，任务，并管理其的生命状态（监管和监控）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Actor系统往往有成千上万个Actor，使用树形机构来组织管理Actor是非常适合的。&lt;/p&gt;

&lt;p&gt;而且Akka天生就是分布式，你可以向一个远程的Actor发送消息，但你需要知道这个Actor的具体位置在哪，这时候你就会发现，树形结构对于确定一个Actor的路径来说是非常有利（比如Linux的文件存储），所以我觉得Actor用树形结构组织可以说是再完美不过了。&lt;/p&gt;

&lt;h4&gt;2.根据配置创建环境&lt;/h4&gt;

&lt;p&gt;一个完善的ActorSystem必须有相关的配置信息，比如使用的日志管理，不同环境打印的日志级别，拦截器，邮箱等等，Akka使用Typesafe配置库，这是一个非常强大的配置库，后续我也准备写一篇后续文章，大家尽请期待哈。&lt;/p&gt;

&lt;p&gt;下面用一个简单的例子来说明一下ActorSystem会根据配置文件内容去生成相应的Actor系统环境：&lt;/p&gt;

&lt;p&gt;1.首先我们按照默认配置打印一下系统的日志级别，搭建Akka环境请看我上一篇文章：&lt;a href=&quot;http://www.godpan.me/blog/akka-1/&quot;&gt;Akka系列（一）：Akka简介与Actor模型&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val actorSystem = ActorSystem(&quot;robot-system&quot;)
println(s&quot;the ActorSystem logLevel is ${actorSystem.settings.LogLevel}&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;the ActorSystem logLevel is INFO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出ActorSystem默认的日志输出级别是&lt;code&gt;INFO&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;2.现在我们在application.conf里配置日志的输出级别：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;akka {

# Log level used by the configured loggers (see &quot;loggers&quot;) as soon
# as they have been started; before that, see &quot;stdout-loglevel&quot;
# Options: OFF, ERROR, WARNING, INFO, DEBUG
loglevel = &quot;DEBUG&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[DEBUG] [03/26/2017 12:07:12.434] [main] [EventStream(akka://robot-system)] logger log1-Logging$DefaultLogger started
[DEBUG] [03/26/2017 12:07:12.436] [main] [EventStream(akka://robot-system)] Default Loggers started
the ActorSystem logLevel is DEBUG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以发现我们ActorSystem的日志输出级别已经变成了&lt;code&gt;DEBUG&lt;/code&gt;。
 
这里主要是演示ActorSystem可以根据配置文件的内容去加载相应的环境，并应用到整个ActorSystem中，这对于我们配置ActorSystem环境来说是非常方便的。
 &lt;/p&gt;

&lt;h4&gt;3.日志功能&lt;/h4&gt;

&lt;p&gt;有很多人可能会疑惑，日志不应该只是记录程序运行状态和排除错误的嘛，怎么在Akka中会变得至关重要，Akka拥有高容错机制，这无疑需要完善的日志记录才能使Actor出错后能及时做出相应的恢复策略，比如Akka中的持久化，具体相应的一些作用我可能会在后续写相应章节的时候提到。&lt;/p&gt;

&lt;h3&gt;Actor引用，路径和地址&lt;/h3&gt;

&lt;p&gt;有了上面的知识，这里了解Actor引用，路径和地址就容易多了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;什么时Actor引用?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Actor引用是ActorRef的子类，每个Actor有唯一的ActorRef，Actor引用可以看成是Actor的代理，与Actor打交道都需要通过Actor引用，Actor引用可以帮对应Actor发送消息，也可以接收消息，向Actor发送消息其实是将消息发送到Actor对应的引用上，再由它将消息投寄到具体Actor的信箱中，所以ActorRef在整个Actor系统是一个非常重要的角色。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何获得Actor引用？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;直接创建Actor&lt;/li&gt;
&lt;li&gt;查找已经存在的Actor&lt;/li&gt;
&lt;/ul&gt;


&lt;h6&gt;1.获得ActorRef&lt;/h6&gt;

&lt;p&gt;看我上一篇文章的同学对这种方式获得Actor引用应该是比较了解，这里我会具体演示一下获得ActorRef的几种方式：&lt;/p&gt;

&lt;p&gt;假定现在由这么一个场景：老板嗅到了市场上的一个商机，准备开启一个新项目，他将要求传达给了经理，经理根据相应的需求，来安排适合的的员工进行工作。&lt;/p&gt;

&lt;p&gt;这个例子很简单，现在我们来模拟一下这个场景：&lt;/p&gt;

&lt;p&gt;1.首先我们来创建一些消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;trait Message {
  val content: String
}
case class Business(content: String) extends Message {}
case class Meeting(content: String) extends Message {}
case class Confirm(content: String, actorPath: ActorPath) extends Message {}
case class DoAction(content: String) extends Message {}
case class Done(content: String) extends Message {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.我们来创建一家公司，这里就是ActorSystem的化身：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val actorSystem = ActorSystem(&quot;company-system&quot;) //首先我们创建一家公司
//创建Actor得到ActorRef的一种方式，利用ActorSystem.actorOf
val bossActor = actorSystem.actorOf(Props[BossActor], &quot;boss&quot;) //公司有一个Boss
bossActor ! Business(&quot;Fitness industry has great prospects&quot;) //从市场上观察到健身行业将会有很大的前景
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.这里我们会创建几种角色，比如上面Boss，这里我们还有Manager，Worker，让我们来看看吧：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class BossActor extends Actor {
  val log = Logging(context.system, this)
  implicit val askTimeout = Timeout(5 seconds)
  import context.dispatcher
  var taskCount = 0
  def receive: Receive = {
    case b: Business =&amp;gt;
      log.info(&quot;I must to do some thing,go,go,go!&quot;)
      println(self.path.address)
      //创建Actor得到ActorRef的另一种方式，利用ActorContext.actorOf
      val managerActors = (1 to 3).map(i =&amp;gt;
        context.actorOf(Props[ManagerActor], s&quot;manager${i}&quot;)) //这里我们召唤3个主管
      //告诉他们开会商量大计划
      managerActors foreach {
        _ ? Meeting(&quot;Meeting to discuss big plans&quot;) map {
          case c: Confirm =&amp;gt;
            //为什么这里可以知道父级Actor的信息？
            //熟悉树结构的同学应该知道每个节点有且只有一个父节点（根节点除外）
            log.info(c.actorPath.parent.toString)
            //根据Actor路径查找已经存在的Actor获得ActorRef
            //这里c.actorPath是绝对路径,你也可以根据相对路径得到相应的ActorRef
            val manager = context.actorSelection(c.actorPath)
            manager ! DoAction(&quot;Do thing&quot;)
        }
      }
    case d: Done =&amp;gt; {
      taskCount += 1
      if (taskCount == 3) {
        log.info(&quot;the project is done, we will earn much money&quot;)
        context.system.terminate()
      }
    }
  }
}
class ManagerActor extends Actor {
  val log = Logging(context.system, this)
  def receive: Receive = {
    case m: Meeting =&amp;gt;
      sender() ! Confirm(&quot;I have receive command&quot;, self.path)
    case d: DoAction =&amp;gt;
      val workerActor = context.actorOf(Props[WorkerActor], &quot;worker&quot;)
      workerActor forward d
  }
}

class WorkerActor extends Actor {
  val log = Logging(context.system, this)
  def receive: Receive = {
    case d: DoAction =&amp;gt;
      log.info(&quot;I have receive task&quot;)
      sender() ! Done(&quot;I hava done work&quot;)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;光看这段代码可能不那么容易理解，这里我会画一个流程图帮助你理解这段程序：&lt;/p&gt;

&lt;p&gt;程序流程图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/04/company-system-example.png&quot; alt=&quot;程序流程图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看了上面的流程图对程序应该有所了解了，过多的解释我这里就不讲解了，可以看注释，或者下载源代码自己去跑一跑。&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_02&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里主要是有两个知识点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建Actor获得ActorRef的两种方式&lt;/li&gt;
&lt;li&gt;根据Actor路径获得ActorRef&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;前一个知识点应该比较清晰了，具体来说说第二个。&lt;/p&gt;

&lt;h6&gt;2.Actor路径与地址&lt;/h6&gt;

&lt;p&gt;熟悉类Unix系统的同学应该对路径这个概念很熟悉了。ActorSystem中的路径也很类似，每个ActorSystem都有一个根守护者，用&lt;code&gt;/&lt;/code&gt;表示,在根守护者下有一个名user的Actor，它是所有system.actorOf()创建的父Actor，所以我们程序中bossActor的路径为：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/user/boss&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;地址顾名思义是Actor所在的位置，为什么要有地址这一个概念，这就是Akka强大的理念了，Akka中所有的东西都是被设计为在分布式环境下工作的，所以我们可以向任意位置的Actor发送消息（前提你得知道它在哪），这时候地址的作用就显现出来来，首先我们可以根据地址找到Actor在什么位置，再根据路径找到具体的Actor，比如我们示例程序中bossActor，它的完整位置是&lt;/p&gt;

&lt;p&gt;&lt;code&gt;akka://company-system/user/boss&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;可以发现它的地址是&lt;/p&gt;

&lt;p&gt;&lt;code&gt;akka://company-system&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其中akka代表纯本地的，Akka中默认远程Actor的位置一般用akka.tcp或者akka.udp开头，当然你也可以使用第三方插件，Akka的远程调用我也会专门写一篇文章。&lt;/p&gt;

&lt;p&gt;总的来说这一篇文章主要是讲解了ActorSystem的基础结构，相关配置，以及Actor引用，路径和地址等比较基础的知识点，这其实对理解整个Actor系统是如何运行的是很有帮助的，博主也是写了好久，争取写的通俗容易理解一点，希望能得到大家的支持，下一篇准备写一下Actor的监管和监控以及它的生命周期。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（一）：Akka简介与Actor模型</title>
   <link href="/2017/03/18/learning-akka-1.html"/>
   <updated>2017-03-18T00:00:00+08:00</updated>
   <id>urn:uuid:85cc4b63-e9f0-4454-8ca7-fbdsdc2a2fad</id>
   <content type="html">&lt;p&gt;Akka是一个构建在JVM上，基于Actor模型的的并发框架，为构建伸缩性强，有弹性的响应式并发应用提高更好的平台。本文主要是个人对Akka的学习和应用中的一些理解。&lt;/p&gt;

&lt;h2&gt;Actor模型&lt;/h2&gt;

&lt;p&gt;Akka的核心就是Actor，所以不得不说Actor，Actor模型我通俗的举个例子，假定现实中的两个人，他们只知道对方的地址，他们想要交流，给对方传递信息，但是又没有手机，电话，网络之类的其他途径，所以他们之间只能用信件传递消息，很像现实中的的邮政系统，你要寄一封信，只需根据地址把信投寄到相应的信箱中，具体它是如何帮你处理送达的，你就不需要了解了，你也有可能收到收信人的回复，这相当于消息反馈。上述例子中的信件就相当于Actor中的消息，Actor与Actor之间只能通过消息通信。当然Actor模型比这要复杂的多，这里主要是简洁的阐述一下Actor模型的概念。&lt;/p&gt;

&lt;h3&gt;Akka中Actors模型&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;对并发模型进行了更高的抽象&lt;/li&gt;
&lt;li&gt;异步、非阻塞、高性能的事件驱动编程模型&lt;/li&gt;
&lt;li&gt;轻量级事件处理（1GB内存可容纳百万级别个Actor）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;为什么Actor模型是一种处理并发问题的解决方案？&lt;/p&gt;

&lt;p&gt;一开始我也不怎么理解，脑子里的一贯思维是处理并发问题就是如何保证共享数据的一致性和正确性，为什么会有保持共享数据正确性这个问题呢？无非是我们的程序是多线程的，多个线程对同一个数据进行修改，若不加同步条件，势必会造成数据污染。那么我们是不是可以转换一下思维，用单线程去处理相应的请求，但是又有人会问了，若是用单线程处理，那系统的性能又如何保证。Actor模型的出现解决了这个问题。&lt;/p&gt;

&lt;p&gt;Actor模型概图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/03/actor-model.png&quot; alt=&quot;Actor模型&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图中我们可以看到，Actor与Actor之前只能用消息进行通信，当某一个Actor给另外一个Actor发消息，消息是有顺序的，你只需要将消息投寄的相应的邮箱，至于对方Actor怎么处理你的消息你并不知道，当然你也可等待它的回复。&lt;/p&gt;

&lt;p&gt;JVM中的Actor有以下几个特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个Actor都有对应一个邮箱&lt;/li&gt;
&lt;li&gt;Actor是串行处理消息的&lt;/li&gt;
&lt;li&gt;Actor中的消息是不可变的&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;其实只从上面一些描述来看，并不能看出Actor在处理并发问题上的有什么优势。&lt;/p&gt;

&lt;p&gt;但我总结了两点：&lt;em&gt;简化并发编程&lt;/em&gt;，&lt;em&gt;提升程序性能&lt;/em&gt;&lt;/p&gt;

&lt;h5&gt;1.简化并发编程：&lt;/h5&gt;

&lt;p&gt;我们一开始说过并发导致最大的问题就是对共享数据的操作，我们在面对并发问题时多采用的是
用锁去保证共享数据的一致性，但这同样也会带来其他相关问题，比如要去考虑锁的粒度（对方法，程序块等），锁的形式（读锁，写锁等）等问题，这些问题对并发程序来说是至关重要的，但一个初写并发程序的程序员来说，往往不能掌控的很好，这无疑给程序员在编程上提高了复杂性，而且还不容易掌控，但使用Actor就不导致这些问题，首先Actor的消息特性就觉得了在与Actor通信上不会有共享数据的困扰，另外在Actor内部是串行处理消息的，同样不会对Actor内的数据造成污染，用Actor编写并发程序无疑大大降低了编码的复杂度。&lt;/p&gt;

&lt;h5&gt;2.提升程序性能：&lt;/h5&gt;

&lt;p&gt;我们之前说过既然用单线程处理，那如何保证程序的性能？首先Actor是非常轻量级的，你可以再程序中创建许多个Actor，而且Actor是异步的，那么如何利用它的这个特性呢，我们要做的就是把相应的并发事件尽可能的分割成一个个小的事件，让每个Actor去处理相应的小事件,充分去利用它异步的特点，来提升程序的性能。&lt;/p&gt;

&lt;p&gt;其实Scala中原生的Actor并不能完成很多事，不是一套完整的并发解决方案，不适合用于生产环境，比如错误恢复，状态持久化等，所以在较新版本的Scala类库中，Akka包已经取代了原生的Actor。&lt;/p&gt;

&lt;h2&gt;Akka&lt;/h2&gt;

&lt;p&gt;那下面我们来简单说说Akka吧，Akka作为一套成熟的并发解决方案，已经被业界大量采用，尤其是在金融，游戏等领域，Akka中的容错机制，持久化，远程调用，日志等都是很重要的模块，这些内容都会在这个系列的后续文章里一一讲解。下面就以一个入门Akka程序来结束本篇文章吧。现在我们假设有一个家居机器人，我们只需要给它发送消息它便会帮我们处理相应的事情，现在我们用程序来模拟这个场景：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_01&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;本示例使用Scala语言，构建工具为SBT，IDE为IntelliJ IDEA.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;1.首先创建一个基于SBT的Scala工程&lt;/p&gt;

&lt;p&gt;&lt;code&gt;build.sbt&lt;/code&gt;配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;name := &quot;Example_01&quot;

version := &quot;1.0&quot;

scalaVersion := &quot;2.11.8&quot;

val akkaVersion   = &quot;2.4.16&quot;

libraryDependencies +=
  &quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % akkaVersion
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.我们来定义一些消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;trait Action{
  val message: String
  val time: Int
}

case class TurnOnLight(time: Int) extends Action {   // 开灯消息
  val message = &quot;Turn on the living room light&quot;
}

case class BoilWater(time: Int) extends Action {   // 烧水消息
  val message = &quot;Burn a pot of water&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.我们利用Actor来实现一个模拟机器人：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class RobotActor extends Actor {
  val log = Logging(context.system, this)
  def receive: Receive = { //机器人接受指令
    case t: TurnOnLight =&amp;gt; log.info(s&quot;${t.message} after ${t.time} hour&quot;)
    case b: BoilWater =&amp;gt; log.info(s&quot;${b.message} after ${b.time} hour&quot;)
    case _ =&amp;gt; log.info(&quot;I can not handle this message&quot;)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.我们去测试这个机器人：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object Example_01 extends App {
  val actorSyatem = ActorSystem(&quot;robot-system&quot;) 
  val robotActor = actorSyatem.actorOf(Props(new RobotActor()), &quot;robotActor&quot;) //创建一个机器人
  robotActor ! TurnOnLight(1) //给机器人发送一个开灯命令
  robotActor ! BoilWater(2) //给机器人发送一个烧水命令
  robotActor ! &quot;who are you&quot; //给机器人发送一个任意命令
  actorSyatem terminate ()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.运行结果&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[INFO] [03/19/2017 13:48:05.622] [robot-system-akka.actor.default-dispatcher-4] [akka://robot-system/user/robotActor] Turn on the living room light after 1 hour
[INFO] [03/19/2017 13:48:05.622] [robot-system-akka.actor.default-dispatcher-4] [akka://robot-system/user/robotActor] Burn a pot of water after 2 hour
[INFO] [03/19/2017 13:48:05.622] [robot-system-akka.actor.default-dispatcher-4] [akka://robot-system/user/robotActor] I can not handle this message
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面是一个非常简单的Akka例子，我们首先创建了一个机器人的Actor，然后通过向它发送不同指令，让它根据指令去做相应的事情，大家可以自己尝试去写一写相似的例子。&lt;/p&gt;

&lt;p&gt;这篇就先到这里了，下一篇主要给大家讲讲Akka中Actor的分层结构。&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
