<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>泮</title>
 <link href="/atom.xml" rel="self"/>
 <link href=""/>
 <updated>2018-03-13T16:24:49+08:00</updated>
 <id>/</id>
 <author>
   <name></name>
 </author>

 
 <entry>
   <title>Kafka学习笔记（一） ：为什么需要Kafka？</title>
   <link href="/2018/03/05/learning-kafka-1.html"/>
   <updated>2018-03-05T00:00:00+08:00</updated>
   <id>urn:uuid:85cc4b63-e9f0-4454-8ca7-fbdsdc2a2fad</id>
   <content type="html">&lt;p&gt;我们在学习一个东西的时候，往往只有真正了解它背后的含义，才能一步一步的掌握它，直到运筹帷幄。对于Kafka来说，我也是一个小白，本篇文章我就以一个小白的角度来初探一下Kafka，本篇文章基于官方文档，顺便说一句官方文档真的很重要，且读且珍惜。&lt;/p&gt;

&lt;h2&gt;背景&lt;/h2&gt;

&lt;p&gt;Kafka最早是由LinkedIn公司开发的，作为其自身业务消息处理的基础，后LinkedIn公司将Kafka捐赠给Apache，现在已经成为Apache的一个顶级项目了，Kafka作为一个高吞吐的分布式的消息系统，目前已经被很多公司应用在实际的业务中了，并且与许多数据处理框架相结合，比如Hadoop，Spark等。&lt;/p&gt;

&lt;h3&gt;消息系统&lt;/h3&gt;

&lt;p&gt;在实际的业务需求中，我们需要处理各种各样的消息，比如Page View,日志，请求等，那么一个好的消息系统应该拥有哪些功能呢？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;拥有消息发布和订阅的功能，类似于消息队列或者企业消息传送系统；&lt;/li&gt;
&lt;li&gt;能存储消息流，并具备容错性；&lt;/li&gt;
&lt;li&gt;能够实时的处理消息；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;以上3点是作为一个好的消息系统的最基本的能力。&lt;/p&gt;

&lt;p&gt;那么Kafka为什么会诞生呢？&lt;/p&gt;

&lt;p&gt;其实在我们工作中，相信有很多也接触过消息队列，甚至自己也写过简单的消息系统，它最基本应该拥有发布/订阅的功能，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/03/simple-message-system.png&quot; alt=&quot;simple-message-system&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中消费者A与消费者B都订阅了消息源A和消息源B，这种模式很简单，但是相对来说也有弊端，比如以下两点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;该模式下消费者需要实时去处理消息，因为这里消息源和消费者都不会维护一个消息队列（代价太大），这会导致消费者若是暂时没有能力消费，则会丢失消息，当然也不能消费过去的消息；&lt;/li&gt;
&lt;li&gt;消息源需要维护原本不属于它的工作，比如维护订阅者（消费者）的信息，向多个消费者发送消息，亦或者有些还需要处理消息反馈，这是原本纯粹的消息源就会变得越来越复杂；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;当然这些问题都是可以改进的，比如我们可以在消息源和消费者中间增加一个消息队列，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/03/simple-message-queue-system.png&quot; alt=&quot;simple-message-queue-system&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从图中我们可以看出，现在消息源只需要将消息发送到消息队列中就行，至于其他就将给消息队列去完成，我们可以在消息队列持久化消息，主动推消息给已经订阅了该消息队列的消费者，那么这种模式还有什么缺点吗？&lt;/p&gt;

&lt;p&gt;答案是有，上图只是两个消息队列，我们维护起来并不困难，但是如果有成百上千个呢？那不得gg，其实我们可以发现，消息队列的功能都很类似，无非就是持久化消息，推送消息，给出反馈等功能，结构也非常类似，主要是消息内容，当然如果要通用化，消息结构也要尽可能通用化，与具体平台具体语言无关，比如用JSON格式等，所有我们可以演变出以下的消息系统：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/03/message-system.png&quot; alt=&quot;message-system&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个方式看起来只是把上面的队列合并到了一起，其实并不那么简单，因为这个消息队列集合要具备以下几个功能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;能统一管理所有的消息队列，不是特殊需求不需要开发者自己去维护；&lt;/li&gt;
&lt;li&gt;高效率的存储消息；&lt;/li&gt;
&lt;li&gt;消费者能快速的找到想要消费的消息；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;当然这些只是最基本的功能，还有比如多节点容错，数据备份等，一个好的消息系统需要处理的东西非常多，很庆幸，Kafka帮我们做到了。&lt;/p&gt;

&lt;h3&gt;Kafka&lt;/h3&gt;

&lt;p&gt;在具体了解Kafka的细节前，我们先来看一下它的一些基本概念：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kafka是运行在一个集群上，所以它可以拥有一个或多个服务节点；&lt;/li&gt;
&lt;li&gt;Kafka集群将消息存储在特定的文件中，对外表现为Topics；&lt;/li&gt;
&lt;li&gt;每条消息记录都包含一个key,消息内容以及时间戳；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;从上面几点我们大致可以推测Kafka是一个分布式的消息存储系统，那么它就仅仅这么点功能吗，我们继续看下面。&lt;/p&gt;

&lt;p&gt;Kafka为了拥有更强大的功能，提供了四大核心接口：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Producer API允许了应用可以向Kafka中的topics发布消息；&lt;/li&gt;
&lt;li&gt;Consumer API允许了应用可以订阅Kafka中的topics,并消费消息；&lt;/li&gt;
&lt;li&gt;Streams API允许应用可以作为消息流的处理者，比如可以从topicA中消费消息，处理的结果发布到topicB中；&lt;/li&gt;
&lt;li&gt;Connector API提供Kafka与现有的应用或系统适配功能，比如与数据库连接器可以捕获表结构的变化；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;它们与Kafka集群的关系可以用下图表示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/03/kafka-apis.png&quot; alt=&quot;kafka-apis&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在了解了Kafka的一些基本概念后，我们具体来看看它的一些组成部分。&lt;/p&gt;

&lt;h4&gt;Topics&lt;/h4&gt;

&lt;p&gt;顾名思义Topics是一些主题的集合，更通俗的说Topic就像一个消息队列，生产者可以向其写入消息，消费者可以从中读取消息，一个Topic支持多个生产者或消费者同时订阅它，所以其扩展性很好。Topic又可以由一个或多个partition（分区）组成，比如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/03/log-anatomy.png&quot; alt=&quot;log-anatomy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中每个partition中的消息是有序的，但相互之间的顺序就不能保证了，若Topic有多个partition，生产者的消息可以指定或者由系统根据算法分配到指定分区，若你需要所有消息都是有序的，那么你最好只用一个分区。另外partition支持消息位移读取，消息位移有消费者自身管理，比如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/03/log-consumer.png&quot; alt=&quot;log-consumer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由上图可以看出，不同消费者对同一分区的消息读取互不干扰，消费者可以通过设置消息位移（offset）来控制自己想要获取的数据，比如可以从头读取，最新数据读取，重读读取等功能。&lt;/p&gt;

&lt;p&gt;关于Topic的分区策略以及与消费者间平衡后续文章会继续深入讲解。&lt;/p&gt;

&lt;h4&gt;Distribution&lt;/h4&gt;

&lt;p&gt;上文说到过，Kafka是一个分布式的消息系统，所以当我们配置了多个Kafka Server节点后，它就拥有分布式的能力，比如容错等，partition会被分布在各个Server节点上，同时它们中间又有一个leader，它会处理所有的读写请求，其他followers会复制leader上的数据信息，一旦当leader因为某些故障而无法提供服务后，就会有一个follower被推举出来成为新的leader来处理这些请求。&lt;/p&gt;

&lt;h4&gt;Geo-Replication&lt;/h4&gt;

&lt;p&gt;异地备份是作为主流分布式系统的基础功能，用于集群中数据的备份和恢复，Kafka利用MirrorMaker来实现这个功能，用户只需简单的进行相应配置即可。&lt;/p&gt;

&lt;h4&gt;Producers&lt;/h4&gt;

&lt;p&gt;Producers作为消息的生产者，可以自己指定将消息发布到订阅Topic中的指定分区，策略可以自己指定，比如语义或者结构类似的消息发布在同一分区，当然也可以由系统循环发布在每一个分区上。&lt;/p&gt;

&lt;h4&gt;Consumers&lt;/h4&gt;

&lt;p&gt;Consumers是一群消费者的集合，可以称之为消费者组，是一种更高层次的的抽象，向Topic订阅消费消息的单位是Consumers，当然它其中也可以只有一个消费者（consumer）。下面是关于consumer的两条原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;假如所有消费者都在同一个消费者组中，那么它们将协同消费订阅Topic的部分消息（根据分区与消费者的数量分配），保存负载平衡；&lt;/li&gt;
&lt;li&gt;假如所有消费者都在不同的消费者中，并且订阅了同个Topic，那么它们将可以消费Topic的所有消息；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;下面是一个简单的例子，帮助大家理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/03/consumer-groups.png&quot; alt=&quot;consumer-groups&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图中有两个Server节点，有一个Topic被分为四个分区（P0-P4)分别被分配在两个节点上，另外还有两个消费者组（GA，GB），其中GA有两个消费者实例，GB有两个消费者实例。&lt;/p&gt;

&lt;p&gt;从图中我们可以看出，首先订阅Topic的单位是消费者组，另外我们发现Topic中的消息根据一定规则将消息推送给具体消费者，主要原则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;若消费者数小于partition数，且消费者数为一个，那么它就消费所有消息；&lt;/li&gt;
&lt;li&gt;若消费者数小于partition数，假设消费者数为N，partition数为M，那么每个消费者能消费的分区数为M/N或M/N+1；&lt;/li&gt;
&lt;li&gt;若消费者数等于partition数，那么每个消费者都会均等分配到一个分区的消息；&lt;/li&gt;
&lt;li&gt;若消费者数大于partition数，则将会出现部分消费者得不到消息分区，出现空闲的情况；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说，Kafka会根据消费者组的情况均衡分配消息，比如有消息着实例宕机，亦或者有新的消费者加入等情况。&lt;/p&gt;

&lt;h4&gt;Guarantees&lt;/h4&gt;

&lt;p&gt;kafka作为一个高水平的系统，提供了以下的保证：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;消息的添加是有序的，生产者越早向订阅的Topic发送的消息，会更早的被添加到Topic中，当然它们可能被分配到不同的分区；&lt;/li&gt;
&lt;li&gt;消费者在消费Topic分区中的消息时是有序的；&lt;/li&gt;
&lt;li&gt;对于有N个复制节点的Topic，系统可以最多容忍N-1个节点发生故障，而不丢失任何提交给该Topic的消息丢失；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;相关这些点的细节，我准备再后续文章中再慢慢深入。&lt;/p&gt;

&lt;h3&gt;Kafka as a Messaging System&lt;/h3&gt;

&lt;p&gt;说了这么多，前面也讲了消息系统的演变过程，那么Kafka相比其他的消息系统优势具体在哪里？&lt;/p&gt;

&lt;p&gt;传统的消息系统模型主要有两种：消息队列和发布/订阅。&lt;/p&gt;

&lt;p&gt;1.消息队列&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;表现形式 &lt;/td&gt;
&lt;td&gt; 一组消费者从消息队列中获取消息，消息会被推送给组中的某一个消费者&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;优势 &lt;/td&gt;
&lt;td&gt; 水平扩展，可以将消息数据分开处理&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;劣势 &lt;/td&gt;
&lt;td&gt; 消息队列是不是多用户的，当一条消息记录被一个进程读取后，消息便会丢失&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;2.发布/订阅&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;表现形式 &lt;/td&gt;
&lt;td&gt; 消费会广播发送给所有消费者&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;优势 &lt;/td&gt;
&lt;td&gt; 可以多进程共享消息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;劣势 &lt;/td&gt;
&lt;td&gt; 每个消息都会获得所有消息，无法通过添加消费进程提高处理效率&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;从上面两个表中可以看出两种传统的消息系统模型的优缺点，所以Kafka在前人的肩膀上进行了优化，吸收他们的优点，主要体现在以下两方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过Topic方式来达到消息队列的功能&lt;/li&gt;
&lt;li&gt;通过消费者组这种方式来达到发布/订阅的功能&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Kafka通过结合这两点（这两点的具体描述查看上面章节），完美的解决了它们两者模式的缺点。&lt;/p&gt;

&lt;h3&gt;Kafka as a Storage System&lt;/h3&gt;

&lt;p&gt;存储消息也是消息系统的一大功能，Kafka相对普通的消息队列存储来说，它的表现实在好的太多，首先Kafka支持写入确认，保证消息写入的正确性和连续性，同时Kafka还会对写入磁盘的数据进行复制备份，来实现容错，另外Kafka对磁盘的使用结构是一致的，所以不管你的服务器磁盘数据有多少，它都会执行相同的操作。&lt;/p&gt;

&lt;p&gt;Kafka的存储机制很好的支持消费者可以随意控制自身所需要读取的数据，在很多时候你也可以将Kafka作为一个高性能，低延迟的分布式文件系统。&lt;/p&gt;

&lt;h3&gt;Kafka for Stream Processing&lt;/h3&gt;

&lt;p&gt;Kafka作为一个完美主义代表者，光有普通的读写，存储等功能是不够的，它还提供了实时处理消息流的接口。&lt;/p&gt;

&lt;p&gt;很多时候原始的数据并不是我们想要的，我们想要的是经过处理后的数据结果，比如通过一天的搜索数据得出当天的搜索热点等，&lt;/p&gt;

&lt;p&gt;你可以利用Streams API来实现自己想要的功能，比如从输入Topic中获取数据，然后再发布到具体的输出Topic中。&lt;/p&gt;

&lt;p&gt;Kafka的流处理可以解决诸如处理无序数据、数据的复杂转换等问题。&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;消息传递、存储、流处理这么功能单一来看确实很普通，但如何把它们完美的结合到一起，就是一种优雅的体现，Kafka做到了这一点。&lt;/p&gt;

&lt;p&gt;相比HDFS分布式文件存储系统，虽然它能支持高效存储并且批处理数据，但是它只支持处理过去的历史数据。&lt;/p&gt;

&lt;p&gt;相比普通的消息系统来说，虽然能处理现在至未来的数据，但是它并不没有存储历史的数据。&lt;/p&gt;

&lt;p&gt;Kafka集众家之所长，使整个系统能兼顾各方面的需求，可以用一个词来说，“完美！”。&lt;/p&gt;

&lt;p&gt;本文从消息系统的演变讲起，到Kafka的具体组成，最后到Kafka的三大特性，旨在帮助大家能够大概的了解Kafka是什么的，到底有什么作用，当然这只是一个小白的简单理解，如有写得不对的地方，希望大家能够指出，不胜感激。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MySQL驱动架构设计</title>
   <link href="/2017/12/10/mysql-parse-architecture.html"/>
   <updated>2017-12-10T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbgbds2a4fge</id>
   <content type="html">&lt;p&gt;上一篇文章我们讲了MySQL网络协议分析，包括如何与MySQL进行通信，数据包的格式等内容，今天我主要会讲讲如何设计一个MySQL解析包类库（类似mysql-connector-xxx山寨版)，本篇文章不具备实际使用意义，更多的是一种架构的设计的尝试以及可以帮助大家理解一些相应第三方包的设计，为未来更从容的应对工作中遇到的问题。&lt;/p&gt;

&lt;h2&gt;文章概述&lt;/h2&gt;

&lt;p&gt;我会从最开始的数据库连接到最终的数据获取一系列步骤的讲解，辅助示例代码用Java编写，本文的主要几个方面分别是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据包模型类设计&lt;/li&gt;
&lt;li&gt;数据包解析类设计&lt;/li&gt;
&lt;li&gt;相关网络传输类设计&lt;/li&gt;
&lt;li&gt;相关编码工具类设计&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;数据包模型类设计&lt;/h3&gt;

&lt;p&gt;数据包模型类设计主要是将数据库传输给我们的数据包解析成我们程序中的模型类，好比你实际业务中建立的JavaBean，这些类的结构依赖于上一篇文章中解析的数据包内容，相关细节请参考上篇文章&lt;a href=&quot;http://www.godpan.me/2017/11/10/mysql-protocol.html&quot;&gt;MySQL网络协议分析&lt;/a&gt;,根据具体的数据内容我们可以构建以下模型类：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;EOF（标志类）&lt;/li&gt;
&lt;li&gt;Error（错误类）&lt;/li&gt;
&lt;li&gt;Field（数据列信息类）&lt;/li&gt;
&lt;li&gt;Handshake （初始化类）&lt;/li&gt;
&lt;li&gt;Ok（Ok类）&lt;/li&gt;
&lt;li&gt;Parameter（错误类）&lt;/li&gt;
&lt;li&gt;PSOK（预处理执行OK类）&lt;/li&gt;
&lt;li&gt;ResultSetHeader（查询结果集头部类）&lt;/li&gt;
&lt;li&gt;RowData（具体列数据结构类）&lt;/li&gt;
&lt;li&gt;RowDataBinary（Binary数据结构类）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;相信看过我前篇文章的同学，对上面很多类应该比较熟悉了，比如我们定义一个OK为以下结构：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class OK implements Packet {
    private long affectedRows; //影响行数
    private long insertId; //自增id
    private int serverStatus; //服务器状态
    private String message; //额外信息
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其他一些相关类的结构我这边就不在贴出了，有兴趣的同学可以参考mysql-connector-java包源码，或者看我的&lt;a href=&quot;https://github.com/godpan/java-connection-mysql&quot;&gt;github项目&lt;/a&gt;也行（搬砖有点不好意思...）,这部分内容是怎么解析的基础结构，充分掌握有助于后续的理解。&lt;/p&gt;

&lt;h3&gt;数据包解析类设计&lt;/h3&gt;

&lt;p&gt;假设我们现在已经写好了解析后的数据包模型类，那么我们怎么将最原始的字节数据转换成这些类呢？首先我们分析解析的过程中需要哪些东西。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要知道解析包的类型；&lt;/li&gt;
&lt;li&gt;包的大小；&lt;/li&gt;
&lt;li&gt;包结构字段定义长度，当前解析数据块位置；&lt;/li&gt;
&lt;li&gt;临时Buffer&lt;/li&gt;
&lt;li&gt;解析结果存储&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这些元素是解析主要的需要的主要结构，可能还有一些其他的内容这里就不阐述了，所以我们可以设计下面的解析类：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class Parser {
    private List&amp;lt;Integer&amp;gt; waitFor = new LinkedList&amp;lt;Integer&amp;gt;(); //接下去要解析的包类型
    private int dataIdx = 0; //当前解析数据包数据块的索引
    private ByteBuffer buffer = ByteBuffer.allocate(65536); //临时Buffer
    private int packetSize = -1; //包大小
    private int itemSize = 0; //当前解析数据包数据块的大小
    private Packet packet = null; //解析结果
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的属性都是解析过程需要初始值，中间变量，结果等，除了这些属性外，我们还需要有将Buffer中数据转换为我们需要数据的方法，根据MySQL协议中的编码方式，主要有以下三个方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;private void readNullTerminated(ByteBuffer in) {  //对应NullTerminatedString（Null结尾方式）: 字符串以遇到Null作为结束标志，相应的字节为00。
    ...
}

private void readLengthCodedBinary(ByteBuffer in) { //对应LengthEncodedInteger编码方式，根据第一个字节区分数据所占的字节长度
    ...
}

private void readLengthCodedString(ByteBuffer in) { //对应LengthEncodedString编码方式，字符串的值根据nteger + Value组成，通过计算Integer的值来获取Value的具体的长度。
     ...
}   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有了以上的属性和相应方法后，我们便可以将服务器传来数据包解析成我们想要的数据了。&lt;/p&gt;

&lt;h3&gt;相关网络传输类设计&lt;/h3&gt;

&lt;p&gt;整理的网络传输类其实就是我们常见Connection类，它是程序中与数据库服务器进行交互的最重要的类，我们可以描述一下它有以下的几点功能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.建立数据库连接；&lt;/li&gt;
&lt;li&gt;2.检验用户，登录等；&lt;/li&gt;
&lt;li&gt;3.执行相应的数据库命令，增删改查等；&lt;/li&gt;
&lt;li&gt;4.接收数据库传来的数据包，并利用Parser类进行解析；&lt;/li&gt;
&lt;li&gt;5.关闭数据库连接；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;基于这些需求我们可以构建出如下的Connection类：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;
public class MysqlConnection {
    private Handshake handshake; //握手初始包类
    private final ByteBuffer out = ByteBuffer.allocate(65536);  //发送给服务端的数据Buffer
    private final ByteBuffer in = ByteBuffer.allocate(65536); // 接收的数据Buffer
    private SocketChannel channel; //异步IO传输通道
    private Parser parser = new Parser(); //解析类
    private String host; //数据库服务器host
    private int port; //数据库服务器端口
    private String user; //数据库用户名
    private String password; //数据库密码
    private String database; //连接具体的数据库
    private Selector selector; //注册channel的selector
    private long connectionId = 0L; //连接id
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些属性相应对数据库驱动稍微有所了解的人都非常熟悉，因为平常写程序经常跟他们打交道，有了上面这些属性，我们还需要一些方法，比如连接数据库，执行命令，读取数据，关闭数据库等方法，所以可以定义以下的一些方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;private void connect() { //连接数据库
    ...
}

public void auth () { //校验账户
    ...
}

public void query () { //执行普通查询
    ...
}

public void update () { //执行普通更新
    ...    
}

public void executeQuery () { //执行预处理查询
    ...
}

public void executeUpdate () { //执行预处理更新
    ...
}

public void read () { //读取通道中的数据
    ...
}

private void send () { //向服务器发送数据
    ...
}

public void close() { //关闭数据库
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这都是一些必要且常用的方法，相信很多人在实际开发中都有所使用，有了以上的一些属性和方法后我们就可以搭建出一个Connection类的基本模型，至于其他一些对象，比如数据库连接池，预处理对象都是基于最基础的Connection。&lt;/p&gt;

&lt;h3&gt;相关编码工具类设计&lt;/h3&gt;

&lt;p&gt;其实上面的一些类与方法，已经能组装成一个简单的与数据库交互的驱动，但是我们知道，我们向数据库服务器发送指令的时候，并不是向我们直接在数据库终端写SQL执行那么简单，而是需要根据数据库的相应协议将我们需要执行的SQL翻译成相应的字节流再发送给数据库服务端，所以我们必须有相关的编码工具类，比如Long类型编码，NULL值编码等等，所以我们需要写相应的编码类提高我们对SQL编码的效率，它应该具有以下的功能：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void longEncoded(){ //long类型编码
    ...
}

public static void nullTerminatedStringEncoded() { //nullTerminatedString编码
    ...
}
public static void lengthEncodedStringEncoded() { //lengthEncodedString编码
    ...
}

private static void dateEncoded () { //Date类型编码
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常来说，上面这四种编码方式可以实现大部分场景的SQL编码了，方法的具体实现取决于实际中程序的数据类型和编码协议可参考我的上一篇文章。&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;这篇文章主要讲解了如何去设计一个简单的数据库驱动，它最基本应该具备些什么，各个模块间又是怎么搭配的，这些内容不仅仅让我们了解与数据库通信的步骤，也可以让我们对目前使用的第三方数据库驱动有更深入的了解，最后我会画一张图里梳理了一下所有模块间的联系，帮助大家理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2018/01/mysql-connection.png&quot; alt=&quot;mysql-connection&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MySQL网络协议分析</title>
   <link href="/2017/11/10/mysql-protocol.html"/>
   <updated>2017-11-10T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbgbds2a4fge</id>
   <content type="html">&lt;p&gt;MySQL对大家来说，都应该很熟悉了，从大学里的课程到实际工作中数据的存储查询，很多时候都需要用到数据库，很多人也写过与数据库交互的程序，在Java中你可能一开始会使用原生mysql-connector-java来进行操作，后来你会接触到Hibernate，Mybatis等ORM框架，其实它们底层也是基于mysql-connector-java，但很多时候我们并不清楚程序是怎么跟数据库具体交互的，比如执行一个SQL查询，程序是如何从MySQL中获取数据的呢？今天就让我们来看看最基础的MySQL网络协议分析。&lt;/p&gt;

&lt;h1&gt;引言&lt;/h1&gt;

&lt;p&gt;阅读本文之前你需要对网络协议需要有基本的了解，比如两台机子之间的数据是如何通信的，硬件层可以暂时不需了解，但网络层和传输层的协议要有一定的理解，比如IP数据包，TCP/IP协议，UDP协议等相关概念，有了这些基础，有利于你阅读本文。&lt;/p&gt;

&lt;h1&gt;背景&lt;/h1&gt;

&lt;p&gt;在历史悠久的时代，数据库只作为单机存储，也不怎么需要与程序进行交互的时候的首，它的网络通信并不是那么重要，但随着时代的发展，数据库不再只是单纯的作为一个数据的仓库了，它需要提供与外界的交互，比如远程连接，程序操作数据库等，这时候一份规范的网络通信的协议就非常重要了，比如它是如何校验权限，如何解析SQL语句，如何返回执行结果都需要用到相应的协议，很多时候我们并不需要接触这些内容，因为它太底层了，我们直接使用把它们封装好的第三方包就可以了，为什么还要去学习它的网络协议呢？确实对于一开始学习编程的人来说，这有点操之过急，反而有时候会适得其反，但当你对这一方面有了一定的了解之后，你便会迫不及待得想去探索更深层的奥秘，去了解并学习我们平常用的第三方类库是怎么去实现，明白它的底层原理，甚至对一些莫名其妙的bug也不会再害怕。&lt;/p&gt;

&lt;h1&gt;MySQL连接方式&lt;/h1&gt;

&lt;p&gt;分析协议，我们首先要了解如何与数据库连接，说到MySQL连接方式，大家突然可能有点懵，其实它一直伴随着我们，比如我们第一次装数据库完成后执行的第一次登录，比如你没有设置密码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql -uroot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是最基本的一种数据库连接方式，那么MySQL连接方式到底有几种呢？到MySQL5.7为止，总共有五种，分别是TCP/IP，TLS/SSL，Unix Sockets，Shared Memory，Named pipes，下面我们就来看看这五种的区别：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方式&lt;/th&gt;
&lt;th&gt;默认开启&lt;/th&gt;
&lt;th&gt;支持系统&lt;/th&gt;
&lt;th&gt;只支持本机&lt;/th&gt;
&lt;th&gt;如何开启&lt;/th&gt;
&lt;th&gt;参数配置&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TCP/IP &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 所有系统 &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt;--skip-networking=yes/no. &lt;/td&gt;
&lt;td&gt; --port&lt;br&gt;--bind-address&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TLS/SSL &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 所有系统（基于TCP/IP)之上 &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt;--ssl=yes/no. &lt;/td&gt;
&lt;td&gt; --ssl-* options&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Unix Sockets &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 类Unix系统 &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt; 设置--socket=&amp;lt;empty&gt; 来关闭. &lt;/td&gt;
&lt;td&gt; --socket=socket path&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Shared Memory &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt; Windows系统 &lt;/td&gt;
&lt;td&gt; 是 &lt;/td&gt;
&lt;td&gt;--shared-memory=on/off. &lt;/td&gt;
&lt;td&gt; --shared-memory-base-name=&amp;lt;name&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Named pipes &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt; Windows系统 &lt;/td&gt;
&lt;td&gt; 否 &lt;/td&gt;
&lt;td&gt;--enable-named-pipe=on/off. &lt;/td&gt;
&lt;td&gt;  --socket=&amp;lt;name&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;从上表中我们可以清晰看出每种连接方式的区别，接下里我会具体说明几种连接是怎么操作的，由于我的机子是Mac OS系统，这里只模拟非Windows系统下的三种方式,因为这三种方式都是默认开启的，我们不需要进行任何配置：&lt;/p&gt;

&lt;h2&gt;1.Unix Sockets：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql -uroot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;若你在本机使用这种方式连接MySQL数据库的话，它默认会使用Unix Sockets。&lt;/p&gt;

&lt;h2&gt;2.TCP/IP：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql --protocol=tcp -uroot
mysql -P3306 -h127.0.0.1 -uroot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;连接的时候我们指定连接协议，或者指定相应的IP及端口，我们的连接方式就变成了TCP/IP方式。&lt;/p&gt;

&lt;h2&gt;3.TLS/SSL：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;mysql --protocol=tcp -uroot --ssl=on
mysql -P3306 -h127.0.0.1 -uroot --ssl=on
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上表说过，TLS/SSL是基于TCP/IP的，所以我们只需再指定打开ssl配置即可。&lt;/p&gt;

&lt;p&gt;然后我们可以通过以下语句来查询目前数据库的连接情况：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT DISTINCT connection_type from performance_schema.threads where connection_type is not null
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么我们如何选择连接方式呢？个人总结了以下几个原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;若是你能确定程序和数据库在同一台机子(类Unix系统)上，推荐使用Unix Sockets，因为它效率更高；&lt;/li&gt;
&lt;li&gt;若数据库分布在不同的机子上，且能确保连接安全或者安全性要求不是那么高，推荐使用TCP/IP，反之使用TLS/SSL；&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;MySQL数据包&lt;/h1&gt;

&lt;p&gt;通信中最重要的就是数据，那么程序是如何和MySQL Server进行通信，并交互数据的呢？比如如何验证账户，发送查询语句，返回执行结果等，我先画一个流程图来模拟一下整个过程，帮助大家理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/mysql-process.png&quot; alt=&quot;mysql-process&quot; /&gt;&lt;/p&gt;

&lt;p&gt;整个过程相对来说还是比较清晰的，我们对连接请求和断开请求不需要过分关心，只需要了解这一点就可以了，重要的是其他几点，那么在这几步中，数据是怎么进行交互的呢？&lt;/p&gt;

&lt;p&gt;其实主要就是两步，&lt;strong&gt;Client将执行命令编码成Server要求的格式传输给Server端执行，Server端将执行结果传输给Client端，Client端再根据相应的数据包格式解析获得所需的数据&lt;/strong&gt;。&lt;/p&gt;

&lt;h2&gt;1.基本数据类型&lt;/h2&gt;

&lt;p&gt;虽然网络中的数据是用字节传输的，但它背后的数据源都是有类型的数据，MySQL协议也有基本的数据类型，好比Java中的8种基本数据类型，但MySQL协议中简单的多，它只有两种基本数据类型，分别为Integer(整型)，String(字符串)，下面我们就来看看这两种类型。&lt;/p&gt;

&lt;h3&gt;Integer(整型)&lt;/h3&gt;

&lt;p&gt;首先Integer在MySQL协议中有两种编码方式，分别为FixedLengthInteger和LengthEncodedInteger
,其中前者用于存储无符号定长整数，实际中使用的不多，这里着重讲一下后者。&lt;/p&gt;

&lt;p&gt;使用LengthEncodedInteger编码的整数可能会使用1, 3, 4, 或者9 个字节，具体使用字节取决于数值的大小，下表是不同的数据长度的整数所使用的字节数：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;最小值（包含）&lt;/th&gt;
&lt;th&gt;最大值（不包含）&lt;/th&gt;
&lt;th&gt;存储方式&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt;251&lt;/td&gt;
&lt;td&gt; 1个字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;251 &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 3个字节(0xFC + 2个字节具体数据)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 4个字节(0xFD + 3个字节具体数据)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;64&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 9个字节(0xFE + 8个字节具体数据)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;举个简单的例子，比如1024的编码为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0xFC 0x00 0x04
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中0x代表16进制，实际数据传输中并没有该标识，第一位代表这是一个251~2&lt;sup&gt;16&lt;/sup&gt;之间的数值，所以后面两位为数值具体的值，这里使用的是小端字节序，MySQL默认使用的也是这种编码次序，所以这里1024是0x00 0x04，字节序相关知识可以参考：&lt;a href=&quot;http://www.ruanyifeng.com/blog/2016/11/byte-order.html&quot;&gt;理解字节序&lt;/a&gt;，到这里大家应该对这种编码格式有了一定的了解了，下面我们就来看看String。&lt;/p&gt;

&lt;h3&gt;String(字符串)&lt;/h3&gt;

&lt;p&gt;String的编码格式相对Integer来说会复杂一点，主要有以下几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;FixedLengthString（定长方式）：需先知道String的长度，MySQL中的一个例子就是ERR_Packet包（后续会讲到）就使用了这种编码方式，因为它的长度固定，用5个字节存储所有数据。&lt;/li&gt;
&lt;li&gt;NullTerminatedString（Null结尾方式）: 字符串以遇到Null作为结束标志，相应的字节为00。&lt;/li&gt;
&lt;li&gt;VariableLengthString（动态计算字符串长度方式）: 字符串的长度取决于其他变量计算而定，比如一个字符串由Integer + Value组成，我们通过计算Integer的值来获取Value的具体的长度。&lt;/li&gt;
&lt;li&gt;LengthEncodedString（指定字符串长度方式）： 与VariableLengthString原理相似，是它的一种特殊情况，具体例子就是我上条举的这个例子。&lt;/li&gt;
&lt;li&gt;RestOfPacketString（包末端字符串方式）：一个包末端的字符串，可根据包的总长度金和当前位置得到字符串的长度，实际中并不常用。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说String的编码格式种类相对比较多，不同方式之间的区别也比较大，若要深刻理解还需从实际的例子里去学习，后续文章中我会写几个demo带大家一起去探索。&lt;/p&gt;

&lt;h2&gt;2.基本数据包格式&lt;/h2&gt;

&lt;p&gt;数据包格式也主要分为两种，一种是Server端向Client端发送的数据包格式，另一种则是Client向Server端发送的数据包。&lt;/p&gt;

&lt;h3&gt;Server to Client&lt;/h3&gt;

&lt;p&gt;Server向Client发送的数据包有两个原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个数据包大小不能超过2&lt;sup&gt;24&lt;/sup&gt;字节(16MB);&lt;/li&gt;
&lt;li&gt;每个数据包前都需要加上数据包信息；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;每个包的基本格式：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type &lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;int&lt;3&gt; &lt;/td&gt;
&lt;td&gt;payload_length(包数据长度)&lt;/td&gt;
&lt;td&gt; 具体数据包的内容长度，从出去头部四个字节后开始的内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;int&lt;1&gt; &lt;/td&gt;
&lt;td&gt;sequence_id(包序列id)&lt;/td&gt;
&lt;td&gt; 每个包的序列id，总数据内容大于16MB时需要用，从0开始，依次增加，新的命令执行会重载为0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;string &lt;/td&gt;
&lt;td&gt;payload(具体数据)&lt;/td&gt;
&lt;td&gt; 包中除去头部后的具体数据内容&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;举个列子：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;例子 &lt;/th&gt;
&lt;th&gt;解释&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;01 00 00 00 01&lt;/td&gt;
&lt;td&gt; &lt;li&gt;payload_length: 1&lt;/li&gt; &lt;li&gt;sequence_id: 0x00&lt;/li&gt;&lt;li&gt;payload: 0x01&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;若是数据内容大于或者等于2&lt;sup&gt;24&lt;/sup&gt;-1个字节，将会拆分发送，举个例子，比如发送16 777 215 (2&lt;sup&gt;24&lt;/sup&gt;-1) 字节的内容，则会按一下这种方式发送&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ff ff ff 00 ...
00 00 00 01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个数据包满载，第二个数据包是一个空数据包（一种临界情况）。&lt;/p&gt;

&lt;h3&gt;Client to Server&lt;/h3&gt;

&lt;p&gt;Client向Server端发送的格式相对来说就简单一点了&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type &lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;int&lt;1&gt; &lt;/td&gt;
&lt;td&gt;执行命令&lt;/td&gt;
&lt;td&gt; 执行的操作，比如切换数据库，查询表等操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;string &lt;/td&gt;
&lt;td&gt;参数&lt;/td&gt;
&lt;td&gt; 命令相应的参数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;命令列表（摘抄自胡桃夹子的博客）：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类型值 &lt;/th&gt;
&lt;th&gt;命令&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0x00&lt;/td&gt;
&lt;td&gt;    COM_SLEEP&lt;/td&gt;
&lt;td&gt;   （内部线程状态)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x01&lt;/td&gt;
&lt;td&gt;    COM_QUIT &lt;/td&gt;
&lt;td&gt;   关闭连接&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x02&lt;/td&gt;
&lt;td&gt;    COM_INIT_DB &lt;/td&gt;
&lt;td&gt; 切换数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x03&lt;/td&gt;
&lt;td&gt;    COM_QUERY   &lt;/td&gt;
&lt;td&gt;SQL查询请求&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x04&lt;/td&gt;
&lt;td&gt;   COM_FIELD_LIST&lt;/td&gt;
&lt;td&gt;  获取数据表字段信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x05&lt;/td&gt;
&lt;td&gt;    COM_CREATE_DB &lt;/td&gt;
&lt;td&gt;  创建数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x06&lt;/td&gt;
&lt;td&gt;    COM_DROP_DB&lt;/td&gt;
&lt;td&gt; 删除数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x07&lt;/td&gt;
&lt;td&gt;    COM_REFRESH&lt;/td&gt;
&lt;td&gt; 清除缓存&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x08&lt;/td&gt;
&lt;td&gt;   COM_SHUTDOWN &lt;/td&gt;
&lt;td&gt;   停止服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x09&lt;/td&gt;
&lt;td&gt;    COM_STATISTICS&lt;/td&gt;
&lt;td&gt;  获取服务器统计信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0A&lt;/td&gt;
&lt;td&gt;    COM_PROCESS_INFO&lt;/td&gt;
&lt;td&gt;    获取当前连接的列表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0B&lt;/td&gt;
&lt;td&gt;    COM_CONNECT&lt;/td&gt;
&lt;td&gt; （内部线程状态)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0C&lt;/td&gt;
&lt;td&gt;    COM_PROCESS_KILL&lt;/td&gt;
&lt;td&gt;    中断某个连接&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0D&lt;/td&gt;
&lt;td&gt;    COM_DEBUG&lt;/td&gt;
&lt;td&gt;   保存服务器调试信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0E&lt;/td&gt;
&lt;td&gt;    COM_PING&lt;/td&gt;
&lt;td&gt;    测试连通性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x0F&lt;/td&gt;
&lt;td&gt;    COM_TIME&lt;/td&gt;
&lt;td&gt;    （内部线程状态）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x10&lt;/td&gt;
&lt;td&gt;    COM_DELAYED_INSERT&lt;/td&gt;
&lt;td&gt;  （内部线程状态）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x11&lt;/td&gt;
&lt;td&gt;    COM_CHANGE_USER&lt;/td&gt;
&lt;td&gt; 重新登陆（不断连接）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x12&lt;/td&gt;
&lt;td&gt;    COM_BINLOG_DUMP&lt;/td&gt;
&lt;td&gt; 获取二进制日志信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x13&lt;/td&gt;
&lt;td&gt;    COM_TABLE_DUMP&lt;/td&gt;
&lt;td&gt;  获取数据表结构信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x14&lt;/td&gt;
&lt;td&gt;    COM_CONNECT_OUT&lt;/td&gt;
&lt;td&gt; （内部线程状态)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x15&lt;/td&gt;
&lt;td&gt;    COM_REGISTER_SLAVE&lt;/td&gt;
&lt;td&gt;  从服务器向主服务器进行注册&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x16&lt;/td&gt;
&lt;td&gt;    COM_STMT_PREPARE&lt;/td&gt;
&lt;td&gt;    预处理SQL语句&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x17&lt;/td&gt;
&lt;td&gt;    COM_STMT_EXECUTE&lt;/td&gt;
&lt;td&gt;    执行预处理语句&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x18&lt;/td&gt;
&lt;td&gt;    COM_STMT_SEND_LONG_DATA&lt;/td&gt;
&lt;td&gt; 发送BLOB类型的数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x19&lt;/td&gt;
&lt;td&gt;    COM_STMT_CLOSE&lt;/td&gt;
&lt;td&gt;  销毁预处理语句&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1A&lt;/td&gt;
&lt;td&gt;    COM_STMT_RESET&lt;/td&gt;
&lt;td&gt;  清除预处理语句参数缓存&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1B&lt;/td&gt;
&lt;td&gt;    COM_SET_OPTION&lt;/td&gt;
&lt;td&gt;  设置语句选项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1C&lt;/td&gt;
&lt;td&gt;    COM_STMT_FETCH&lt;/td&gt;
&lt;td&gt;  获取预处理语句的执行结果&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这里距一个常见的的例子，比如切换数据库：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;mysql&quot;&gt;use godpan
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相应的报文格式则为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0x02 0x67 0x6f 0x64 0x70 0x61 0x6e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中0x02代表切换数据库命令，后面的字节则为godpan的16进制表达。&lt;/p&gt;

&lt;h2&gt;数据包类型&lt;/h2&gt;

&lt;p&gt;有了以上的基础，我们基本知道的与MySQL通信之间的方式以及数据格式，那么与其通信间到底有哪几种数据包呢？接下去的内容是建立在MySQL4.1版本以后，之前版本的数据包类型这里不再论述。&lt;/p&gt;

&lt;p&gt;这里主要分为两个阶段，第一个阶段是数据库账户认证阶段，第二个阶段则是执行具体命令阶段，我们先来看看前者。&lt;/p&gt;

&lt;h3&gt;数据库账户认证阶段&lt;/h3&gt;

&lt;p&gt;这个阶段就是我们平常所说的登录，主要步骤如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.Client与Server进行连接&lt;/li&gt;
&lt;li&gt;2.Server向Client发送Handshake packet&lt;/li&gt;
&lt;li&gt;3.Client与Server发送Auth packet&lt;/li&gt;
&lt;li&gt;4.Server向Client发送OK packet或者ERR packet&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这里我们来看一看上面的Handshake packet和Auth packet，OK packet和ERR packet放在另一个阶段写。&lt;/p&gt;

&lt;h4&gt;Handshake packet&lt;/h4&gt;

&lt;p&gt;Handshake packet是由Server向Client发送的初始化包，因为所有从Server向Client端发送的包都是一样的格式，所以前面的四个字节是包头，前三位代表Handshake packet具体内容的数据，另外包序列号为0，很显然这个包内容小于16MB，下面是Handshake packet具体内容的格式：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 协议版本 &lt;/td&gt;
&lt;td&gt;协议版本的版本号，通常为10（0x0A）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; len = strlen (server_version) + 1 &lt;/td&gt;
&lt;td&gt; 数据库版本 &lt;/td&gt;
&lt;td&gt; 使用前面的NullTerminatedString格式编码，长度为数据库版本字符串的长度加上标示结束的的一个字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 1 &lt;/td&gt;
&lt;td&gt; 4 &lt;/td&gt;
&lt;td&gt; 线程ID &lt;/td&gt;
&lt;td&gt;此次连接MySQL Server启动的线程ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 5 &lt;/td&gt;
&lt;td&gt; 8 + 1（0x00表示结束) &lt;/td&gt;
&lt;td&gt; 挑战随机数（第一部分） &lt;/td&gt;
&lt;td&gt;用于后续账户密码验证&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 14 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 协议协商 &lt;/td&gt;
&lt;td&gt; 用于与客户端协商通讯方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 16 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 编码格式 &lt;/td&gt;
&lt;td&gt;标识数据库目前的编码方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 17 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 服务器状态 &lt;/td&gt;
&lt;td&gt;用于表示服务器状态，比如是否是事务模式或者自动提交模式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 19 &lt;/td&gt;
&lt;td&gt; 13 &lt;/td&gt;
&lt;td&gt; 保留字节 &lt;/td&gt;
&lt;td&gt;未来可能会用到，预留字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;len + 32 &lt;/td&gt;
&lt;td&gt; 12 + 1（0x00表示结束) &lt;/td&gt;
&lt;td&gt; 挑战随机数（第二部分） &lt;/td&gt;
&lt;td&gt;用于后续账户密码验证&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;上表就是整个Handshake packet的这个包结构，属性的含义以及规范都有相应的说明，下面是我本机解析的某次连接数据库的Handshake packet包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{protocolVersion=10, serverVersion='5.7.13', threadId=4055, scramble=[49, 97, 80, 3, 35, 118, 45, 15, 5, 118, 9, 11, 124, 93, 93, 5, 31, 47, 111, 109, 0, 0, 0, 0, 0], serverCapabilities=65535, serverLanguage=33, serverStatus=2}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Auth packet&lt;/h4&gt;

&lt;p&gt;Auth packet是由Client向Server发送的认证包，用于验证数据库账户登录，相应内容的格式：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 4 &lt;/td&gt;
&lt;td&gt; 协议协商 &lt;/td&gt;
&lt;td&gt; 用于与服务端协商通讯方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 4 &lt;/td&gt;
&lt;td&gt; 消息最长长度 &lt;/td&gt;
&lt;td&gt; 客户端可以发送或接收的最长长度，0表示不做任何限制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 字符编码 &lt;/td&gt;
&lt;td&gt; 客服端字符编码方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9 &lt;/td&gt;
&lt;td&gt; 23 &lt;/td&gt;
&lt;td&gt; 保留字节 &lt;/td&gt;
&lt;td&gt; 未来可能会用到，预留字节，用0代替&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32 &lt;/td&gt;
&lt;td&gt;不定&lt;/td&gt;
&lt;td&gt; 认证字符串 &lt;/td&gt;
&lt;td&gt; 主要有三部分内容&lt;br&gt; &lt;li&gt;用户名：NullTerminatedString格式编码&lt;/li&gt;&lt;li&gt;加密后的密码：LengthEncodedString格式编码&lt;/li&gt;&lt;li&gt;数据库名称（可选）：NullTerminatedString格式编码&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这部分内容是由客户端自己生成，所以说如果我们如果要写一个程序连接数据库，那么这个包就得按照这个格式，不然服务端将会无法识别。&lt;/p&gt;

&lt;h3&gt;命令执行阶段&lt;/h3&gt;

&lt;p&gt;在我们正确连接数据库后，我们就要执行相应的命令了，比如切换数据库，执行CRUD操作等，这个阶段主要分为两步，Client发送命令（上文已经给出，下面不再讨论），Server端接收命令执行相应的操作，我们主要关心Server端向我们发送数据包，可分为4类和一个最基础的报文结构Data Field：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data Field：包数据的一个基础结构；&lt;/li&gt;
&lt;li&gt;OK包(包括PREPARE_OK)：Server端发送正确处理信息的包，包头标识为0x00；&lt;/li&gt;
&lt;li&gt;Error包： Server端发送错误信息的包，包头标识为0xFF；&lt;/li&gt;
&lt;li&gt;EOF包：用于Server向Client发送结束包，包头标识为0xFE；&lt;/li&gt;
&lt;li&gt;Result Set包：用于Server向Client发送的查询结果包；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Data Field&lt;/h4&gt;

&lt;p&gt;Data Field是Server回应包里的一个核心，主要是数据的一种编码结构，跟我之前讲的LengthEncodedInteger和LengthEncodedString很类似，也主要分为三个部分&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;最小数据长度（包含）&lt;/th&gt;
&lt;th&gt;最大数据长度（不包含）&lt;/th&gt;
&lt;th&gt;数据长度&lt;/th&gt;
&lt;th&gt;格式&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt;251&lt;/td&gt;
&lt;td&gt; 1个字节&lt;/td&gt;
&lt;td&gt;1字节 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;251 &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 2个字节 &lt;/td&gt;
&lt;td&gt; 0xFC + 2个字节数据长度 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;16&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 4个字节 &lt;/td&gt;
&lt;td&gt; 0xFD + 4个字节数据长度 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt; &lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;64&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt; 8个字节 &lt;/td&gt;
&lt;td&gt; 0xFE + 8个字节数据长度 + 具体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NULL &lt;/td&gt;
&lt;td&gt; NULL &lt;/td&gt;
&lt;td&gt; 0个字节 &lt;/td&gt;
&lt;td&gt; 0xFB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;要注意的一点是如果出现0xFB（251）开头说明这个数据对应的是MySQL中的NULL。&lt;/p&gt;

&lt;h4&gt;OK 包&lt;/h4&gt;

&lt;p&gt;普通的OK包（PREPARE_OK包后面会讲到）会在以下几种情况下产生，由Server发送给相应的接收方：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;COM_PING: 连接或者测试数据库&lt;/li&gt;
&lt;li&gt;COM_QUERY： 不需要查询结果集的操作，比如INSERT, UPDATE, or ALTER TABLE&lt;/li&gt;
&lt;li&gt;COM_REFRESH： 数据刷新&lt;/li&gt;
&lt;li&gt;COM_REGISTER_SLAVE： 注册从服务器&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;OK 包的主要结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0x00 代表这是一个OK 包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; rows_len &lt;/td&gt;
&lt;td&gt; 影响行数 &lt;/td&gt;
&lt;td&gt; 相应操作影响的行数，比如一个Update操作的记录是5条，那么这个值就为5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 + rows_len &lt;/td&gt;
&lt;td&gt; id_len &lt;/td&gt;
&lt;td&gt; 自增id &lt;/td&gt;
&lt;td&gt;插入一条记录时，如果是自增id的话，返回的id值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 + rows_len + id_len &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 服务器状态 &lt;/td&gt;
&lt;td&gt;用于表示服务器状态，比如是否是事务模式或者自动提交模式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 + rows_len + id_len &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 警告数 &lt;/td&gt;
&lt;td&gt;上次命令引起的警告数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5 + rows_len + id_len &lt;/td&gt;
&lt;td&gt; msg_len &lt;/td&gt;
&lt;td&gt; 额外信息 &lt;/td&gt;
&lt;td&gt;此次操作的一些额外信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;下面是我本机解析的某次正确连接数据库后的OK packet包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OK{affectedRows=0, insertId=0, serverStatus=2, message='....'}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Error 包&lt;/h4&gt;

&lt;p&gt;顾名思义Error 包就是当出现错误的时候返回的信息，比如账户验证不通过，查询命令不合法，非空字段未指定值等相关操作，Server端都会向Client端发送Error 包。&lt;/p&gt;

&lt;p&gt;Error 包的主要结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0xFF 代表这是一个Error 包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 错误代码 &lt;/td&gt;
&lt;td&gt;该错误的相应错误代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 标识位 &lt;/td&gt;
&lt;td&gt;SQL执行状态标识位，用'#'进行标识&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 5 &lt;/td&gt;
&lt;td&gt; 执行状态 &lt;/td&gt;
&lt;td&gt;SQL的具体执行状态&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9 &lt;/td&gt;
&lt;td&gt; msg_len &lt;/td&gt;
&lt;td&gt; 错误信息 &lt;/td&gt;
&lt;td&gt;具体的错误信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;比如我们现在已经连接了数据库，执行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;use test_database;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是我们数据库中并没有test_database这个数据库，我们将会得到相应的错误信息，下面是我本机解析的Error packet包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error{errno=1046, sqlState='3D000', message='No database selected'}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;EOF Packet&lt;/h4&gt;

&lt;p&gt;EOF Packet是用于标识某个阶段数据结束的标志包，会在一下几种情况中产生：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;结果集中字段信息结束的时候；&lt;/li&gt;
&lt;li&gt;结果集中列信息结束的时候；&lt;/li&gt;
&lt;li&gt;服务器确认停止服务的时候；&lt;/li&gt;
&lt;li&gt;客户端发送COM_SET_OPTION and COM_DEBUG命令后，服务器回应的时候；&lt;/li&gt;
&lt;li&gt;服务器请求使用MySQL4.1版本之前的认证方式的时候；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;EOF 包的主要结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0xFE 代表这是一个EOF 包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 警告数 &lt;/td&gt;
&lt;td&gt;上次命令引起的警告数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 &lt;/td&gt;
&lt;td&gt; 2 &lt;/td&gt;
&lt;td&gt; 服务器状态&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这里要注意的一点，我们上面分析了Data Field的结构，发现它是用0xFE作为长度需要8个字节编码值得标识头，所以我们在判断一个包是否是EOF 包的时候，需要下面两个条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;标识头（第一个字节）为0xFE；&lt;/li&gt;
&lt;li&gt;包的总长度小于9个字节；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Result Set包&lt;/h4&gt;

&lt;p&gt;Result Set包产生于我们每次数据库执行需要返回结果集的时候，Server端发送给我们的包，比如平常的SELECT,SHOW等命令，Result Set包相对比较复杂，主要包含以下五个方面：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内容 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Result Set Header &lt;/td&gt;
&lt;td&gt; 返回数据的列数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Field &lt;/td&gt;
&lt;td&gt; 返回数据的列信息（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF   &lt;/td&gt;
&lt;td&gt; 列结束&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Row Data &lt;/td&gt;
&lt;td&gt; 行数据（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF &lt;/td&gt;
&lt;td&gt; 数据结束&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;我们逐个来分析，首先我们来看Result Set Header。&lt;/p&gt;

&lt;h5&gt;Result Set Header&lt;/h5&gt;

&lt;p&gt;Result Set Header表示返回数据的列数量以及一些额外的信息，其主要结构为：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1-9字节 &lt;/td&gt;
&lt;td&gt; 数据的列数量（LengthEncodedInteger编码格式）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1-9字节 &lt;/td&gt;
&lt;td&gt; 额外信息（LengthEncodedInteger编码格式）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;h5&gt;Field&lt;/h5&gt;

&lt;p&gt;Field表示Result Set中数据列的具体信息，可出现多次，具体次数取决于Result Set Header中数据的列数量，它的主要结构为：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 通常为ASCIIz字符串def&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 数据库名称（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 假如查询指定了表别名，就是表别名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 原始的表名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 假如查询指定了列别名，就是列别名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 原始的列名（Data Field）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 标识位，通常为12，表示接下去的12个字节是具体的field内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; field的编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; field的长度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; field的类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; field的标识&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; field值的的小数点精度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; 预留字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 可选元素，如果存在，则表示该field的默认值&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;其中field的类型与标识具体定义和对应变量含义可参考这篇文章：&lt;a href=&quot;http://hutaow.com/blog/2013/11/06/mysql-protocol-analysis/#428-com_shutdown&quot;&gt;MySQL协议分析&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;EOF 包&lt;/h5&gt;

&lt;p&gt;这里的EOF包是标识这列信息的结束，具体结构信息参考上面的EOF包解释。&lt;/p&gt;

&lt;h5&gt;Row Data&lt;/h5&gt;

&lt;p&gt;Row Data含着的是我们需要获取的数据，一个Result Set包里面包含着多个Row Data结构(得到的数据可能多行)，每个Row Data中包含着多个字段值，它们之间没有间隔，比如我们现在查询到的数据为（id: 1, name: godpan) 那么Row Data内容为（1，godpan),这两个值是连在一起的，对应的值都用LengthEncodedString编码。&lt;/p&gt;

&lt;h5&gt;EOF 包&lt;/h5&gt;

&lt;p&gt;等待Row Data发送完之后，Server最后会向Client端发送一个EOF包，标识所有的行数据已经发送完毕。&lt;/p&gt;

&lt;h4&gt;PREPARE_OK包&lt;/h4&gt;

&lt;p&gt;PREPARE_OK包产生在Client端向Server发送预处理SQL语句，Server进行正确回应的时候，大家写写Java的时候肯定用过PreparedStatement，这里PreparedStatement的功能就是进行SQL的预处理，预处理的优点比较多，比如效率高，防SQL注入等，有兴趣的同学可以自己去学习下。下面是PREPARE_OK包的结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 0x00（标识是一个OK包）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; statement_handler_id（预处理语句id）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; number of columns in result set（结果集中列的数量）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; number of parameters in query（查询语句中参数的数量）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 0x00 (填充值)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 &lt;/td&gt;
&lt;td&gt; 警告数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;比如我现在执执行下面的语句：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;PreparedStatement ps = connection.prepareStatement(&quot;SELECT * FROM `godpan_fans` where id=?&quot;);
ps.setInteger(1, 1);
ps.executeQuery();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;得到下面的PREPARE_OK包，仅供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PSOK{statementId=1, columns=5, parameters=1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果上面的columns大于0，以及parameters大于0，则将有额外的两个包传输，分别是columns的信息以及parameters的信息，对应信息结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内容 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Field &lt;/td&gt;
&lt;td&gt; columns信息（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF   &lt;/td&gt;
&lt;td&gt; columns信息结束&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Field &lt;/td&gt;
&lt;td&gt; parameters（多个）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EOF &lt;/td&gt;
&lt;td&gt; parameters结束&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;到此整个PREPARE_OK包发送完毕。&lt;/p&gt;

&lt;h4&gt;Row Data Binary&lt;/h4&gt;

&lt;p&gt;这个包跟上面提到的Row Data包有什么差别呢？主要有两点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;用不同的方式定义NULL；&lt;/li&gt;
&lt;li&gt;数据编码不再单纯的使用LengthEncodedString，而是根据数据类型的不同进行相应的编码；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;后面我会分别解释这两点，我们先来看看它的结构：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;相对包内容的位置 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; 包头标识 &lt;/td&gt;
&lt;td&gt;0x00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; (col_count+7+2)/8 &lt;/td&gt;
&lt;td&gt; Null Bit Map &lt;/td&gt;
&lt;td&gt; 前两位为预留字节，主要用于区别与其他的几种包（OK，ERROR，EOF），在MySQL 5之后这两个字节都为0X00，其中col_count为列的数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;(col_count+7+2)/8 + 1 &lt;/td&gt;
&lt;td&gt; n &lt;/td&gt;
&lt;td&gt; column values &lt;/td&gt;
&lt;td&gt; 具体的列值，重复多次，根据值类型编码&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;现在我们来看一下它的两个特点，首先我们来看它是如何来定义NULL的，首先我们看到他的结构中有一个Null Bit Map，除去两个标识位，真正用于标识数据信息的就是(col_count+7)/8位字节，这里我先给出结论，后面再给大家具体分析：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数个数 &lt;/th&gt;
&lt;th&gt;长度（字节）&lt;/th&gt;
&lt;th&gt;具体值范围&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1-8 &lt;/td&gt;
&lt;td&gt; 1 &lt;/td&gt;
&lt;td&gt; -1, 2&lt;sup&gt;n&lt;/sup&gt;组合 &lt;/td&gt;
&lt;td&gt; 1 = 2&lt;sup&gt;0&lt;/sup&gt;表示第一个参数为NULL，3 = 2&lt;sup&gt;0&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt;表示第一个和第二参数为NULL...&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;上面给出了标识NULL的基本算法，原则是哪个参数（次序为n)为NULL，则Null Bit Map相应的值加上2&lt;sup&gt;n&lt;/sup&gt;,8个参数为一个周期，以此类推。&lt;/p&gt;

&lt;p&gt;接着我们来看一下第二点，是如何用具体值类型来对相应的值进行编码的，这里主要分为三类，基本数据类型，时间类型，字符串类型；&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;基本数据类型：比如TINYINT使用一个字节编码，FLOAT使用四个字节，DOUBLE使用8个字节等；&lt;/li&gt;
&lt;li&gt;时间类型：使用类似LengthEncodedString的编码方式编码，具体可参考&lt;a href=&quot;https://dev.mysql.com/doc/dev/mysql-server/latest/PAGE_PROTOCOL.html&quot;&gt;MySQL_PROTOCOL&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;字符串类：不属于上面两类的都属于字符串类型，使用普通的LengthEncodedString；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Execute包&lt;/h4&gt;

&lt;p&gt;Execute包顾名思义是一个执行包，它是由Client端发送到Server端的，但它和普通的命令又有点不同，它主要是用来执行预处理语句，并会携带相应参数，具体结构如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;长度 &lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; COM_EXECUTE（标识是一个Execute包）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 预处理语句id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 游标类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 &lt;/td&gt;
&lt;td&gt; 预留字节&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0 &lt;/td&gt;
&lt;td&gt; 接下去的内容只有在有参数的情况下&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;(param_count+7)/8 &lt;/td&gt;
&lt;td&gt; null_bit_map（描述参数中NULL的情况）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 &lt;/td&gt;
&lt;td&gt; 参数绑定情况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n*2 &lt;/td&gt;
&lt;td&gt; 参数类型（依次存储）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;n &lt;/td&gt;
&lt;td&gt; 参数具体值（非NULL)（依次存储，使用Row Data Binary方式编码）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;Execute包从Client端发送到Server端后可能会得到以下几个结果：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OK包&lt;/li&gt;
&lt;li&gt;ERROR包&lt;/li&gt;
&lt;li&gt;Result Set包（可能多个）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;我们需要根据包的不同类型来进行不同的处理。&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;本篇文章主要讲述了MySQL的连接方式，通信过程及协议，以及传输包的基本格式和相关传输包的类型，内容相对来说，比较多也比较复杂，我也是将近三周才写完，但总体按照我自学的思路走，不会太绕，有些点可能需要细心思考下，写的有误的地方也希望大家能指正，希望对大家有所帮助，后面可能会写几个实例和大家一起学习。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Java IO之NIO</title>
   <link href="/2017/11/05/java-nio.html"/>
   <updated>2017-11-05T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;上篇说了最基础的五种IO模型，相信大家对IO相关的概念应该有了一定的了解，这篇文章主要讲讲基于多路复用IO的Java NIO。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;Java诞生至今，有好多种IO模型，从最早的Java IO到后来的Java NIO以及最新的Java AIO，每种IO模型都有它自己的特点，详情请看我的上篇文章&lt;a href=&quot;&quot;&gt;Java IO初探&lt;/a&gt;，而其中的的Java NIO应用非常广泛，尤其是在高并发领域，比如我们常见的Netty，Mina等框架，都是基于它实现的，相信大家都有所了解，下面让我们来看看Java NIO的具体架构。&lt;/p&gt;

&lt;h3&gt;Java NIO架构&lt;/h3&gt;

&lt;p&gt;其实Java NIO模型相对来说也还是比较简单的，它的核心主要有三个，分别是：Selector、Channel和Buffer,我们先来看看它们之间的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/java-nio.png&quot; alt=&quot;java-nio&quot; /&gt;&lt;/p&gt;

&lt;p&gt;它们之间的关系很清晰，一个线程对应着一个Selector，一个Selector对应着多个Channel，一个Channel对应着一个Buffer，当然这只是通常的做法，一个Channel也可以对应多个Selector，一个Channel对应着多个Buffer。&lt;/p&gt;

&lt;h4&gt;Selector&lt;/h4&gt;

&lt;p&gt;个人认为Selector是Java NIO的最大特点，之前我们说过，传统的Java IO在面对大量IO请求的时候有心无力，因为每个维护每一个IO请求都需要一个线程，这带来的问题就是，系统资源被极度消耗，吞吐量直线下降，引起系统相关问题，那么Java NIO是如何解决这个问题的呢？答案就是Selector，简单来说它对应着多路IO复用中的监管角色，它负责统一管理IO请求，监听相应的IO事件，并通知对应的线程进行处理，这种模式下就无需为每个IO请求单独分配一个线程，另外也减少线程大量阻塞，资源利用率下降的情况，所以说Selector是Java NIO的精髓，在Java中我们可以这么写：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;// 打开服务器套接字通道
ServerSocketChannel ssc = ServerSocketChannel.open();
// 服务器配置为非阻塞
ssc.configureBlocking(false);
// 进行服务的绑定
ssc.bind(new InetSocketAddress(&quot;localhost&quot;, 8001));

// 通过open()方法找到Selector
Selector selector = Selector.open();
// 注册到selector，等待连接
ssc.register(selector, SelectionKey.OP_ACCEPT);
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Channel&lt;/h4&gt;

&lt;p&gt;Channel本意是通道的意思，简单来说，它在Java NIO中表现的就是一个数据通道，但是这个通道有一个特点，那就是它是双向的，也就是说，我们可以从通道里接收数据，也可以向通道里写数据，不用像Java BIO那样，读数据和写数据需要不同的数据通道，比如最常见的Inputstream和Outputstream，但是它们都是单向的，Channel作为一种全新的设计，它帮助系统以相对小的代价来保持IO请求数据传输的处理，但是它并不真正存放数据，它总是结合着缓存区（Buffer）一起使用，另外Channel主要有以下四种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;FileChannel：读写文件时使用的通道&lt;/li&gt;
&lt;li&gt;DatagramChannel：传输UDP连接数据时的通道,与Java IO中的DatagramSocket对应&lt;/li&gt;
&lt;li&gt;SocketChannel：传输TCP连接数据时的通道，与Java IO中的Socket对应&lt;/li&gt;
&lt;li&gt;ServerSocketChannel: 监听套接词连接时的通道，与Java IO中的ServerSocket对应&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;当然其中最重要以及最常用的就是SocketChannel和ServerSocketChannel，也是Java NIO的精髓，ServerSocketChannel可以设置成非阻塞模式，然后结合Selector就可以实现多路复用IO，使用一个线程管理多个Socket连接，具体使用可以参数上面的代码。&lt;/p&gt;

&lt;h4&gt;Buffer&lt;/h4&gt;

&lt;p&gt;顾名思义，Buffer的含义是缓冲区，它在Java NIO中的主要作用就是作为数据的缓冲区域，Buffer对应着某一个Channel，从Channel中读取数据或者向Channel中写数据，Buffer与数组很类似，但是它提供了更多的特性，方便我们对Buffer中的数据进行操作，后面我也会主要分析它的三个属性capacity，position和limit，我们先来看一下Buffer分配时的类别（这里不是指Buffer的具体数据类型）即Direct Buffer和Heap Buffer，那么为什么要有这两种类别的Buffer呢？我们先来看看它们的特性：&lt;/p&gt;

&lt;p&gt;Direct Buffer：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;直接分配在系统内存中；&lt;/li&gt;
&lt;li&gt;不需要花费将数据库从内存拷贝到Java内存中的成本；&lt;/li&gt;
&lt;li&gt;虽然Direct Buffer是直接分配中系统内存中的，但当它被重复利用时，只有真正需要数据的那一页数据会被装载到真是的内存中，其它的还存在在虚拟内存中，不会造成实际内存的资源浪费；&lt;/li&gt;
&lt;li&gt;可以结合特定的机器码，一次可以有顺序的读取多字节单元；&lt;/li&gt;
&lt;li&gt;因为直接分配在系统内存中，所以它不受Java GC管理，不会自动回收；&lt;/li&gt;
&lt;li&gt;创建以及销毁的成本比较高；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Heap Buffer：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分配在Java Heap，受Java GC管理生命周期，不需要额外维护；&lt;/li&gt;
&lt;li&gt;创建成本相对较低；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;根据它们的特性，我们可以大致总结出它们的适用场景：&lt;/p&gt;

&lt;p&gt;如果这个Buffer可以重复利用，而且你也想多个字节操作，亦或者你对性能要求很高，可以选择使用Direct Buffer，但其编码相对来说会比较复杂，需要注意的点也更多，反之则用Heap Buffer，Buffer的相应创建方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;//创建Heap Buffer
ByteBuffer heapBuffer = ByteBuffer.allocate(1024);

//创建Direct Buffer
ByteBuffer directBuffer = ByteBuffer.allocateDirect(1024);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们来看看它的三个属性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Capacity：顾名思义它的含义是容量，代表着Buffer的最大容量，与数组的Size很类似，初始化不可更改，除非你改变的Buffer的结构；&lt;/li&gt;
&lt;li&gt;Limit：顾名思义它的含义是界限，代表着Buffer的目前可使用的最大限制，写模式下，一般Limit等于Capacity，读模式下需要你自己控制它的值结合position读取想要的数据；&lt;/li&gt;
&lt;li&gt;Position：顾名思义它的含义是位置，代表着Buffer目前操作的位置，通俗来说，就是你下次对Buffer进行操作的起始位置；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;接下来我会用一个图解的列子帮助大家理解,现在我们假设有一个容量为10的Buffer，我们先往里面写入一定字节的数据，然后再根据编码规则从其中读取我们需要的数据：&lt;/p&gt;

&lt;p&gt;1.初始Buffer：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;ByteBuffer buffer = ByteBuffer.allocate(10);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/init-buffer.png&quot; alt=&quot;init-buffer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.向Buffer中写入两个字节：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;buffer.put(&quot;my&quot;.getBytes());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/write-buffer-1.png&quot; alt=&quot;write-buffer-1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.再Buffer中写入四个字节：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;buffer.put(&quot;blog&quot;.getBytes());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/write-buffer-2.png&quot; alt=&quot;write-buffer-2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4.现在我们需要从Buffer中获取数据，首先我们先将写模式转换为读模式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;  buffer.flip();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看看flip()方法到底做了什么事？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public final Buffer flip() {
    limit = position;
    position = 0;
    mark = -1;
    return this;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从源码中可以看出，flip方法根据Buffer目前的相应属性来修改对应的属性，所以flip()方法之后，Buffer目前的状态：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/read-buffer.png&quot; alt=&quot;read-buffer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5.接着我们从Buffer中读取数据&lt;/p&gt;

&lt;p&gt;从Buffer中读取数据有多种方式，比如get(),get(byte [])等，相关的具体方法使用可以参考Buffer的官方API文档，这里我们用最简单的get()来获取数据:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;  byte a = buffer.get();
  byte b = buffer.get();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时Buffer的状态如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/11/read-buffer-2.png&quot; alt=&quot;read-buffer-2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以按照这种方式读取完我们所需数据，最终调用clear()方法将Buffer置为初始状态。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;这篇文章主要讲解了Java NIO中重要的三个组成部分，在实际使用过程也是比较重要的，掌握它们之间的关系，可以让你对Java NIO的整个架构更加熟悉，理解相对来说也会更加深刻，并分析了这种模式是如何与多路复用IO模型的映射，了解Java NIO在高并发场景下优势的原因。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Java IO初探</title>
   <link href="/2017/10/21/java-io.html"/>
   <updated>2017-10-21T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;Java IO对大多数Java程序员来说是熟悉又陌生，熟悉的是感觉到处都有它的身影，小到简单的读取文件，大到各种服务器的应用，陌生的是Java IO背后到底是一个怎样的机制，今天就让我们去了解一下这位老朋友吧。本文不讲解Java IO如何具体使用，有这方面需求的同学可以自己查下。&lt;/p&gt;

&lt;h3&gt;IO模型&lt;/h3&gt;

&lt;p&gt;要说IO，就不得不说IO模型，IO模型大家都有所了解，同步异步，阻塞非阻塞什么的，总的来说IO模型可分为以下五种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;阻塞IO&lt;/li&gt;
&lt;li&gt;非阻塞IO&lt;/li&gt;
&lt;li&gt;多路复用IO&lt;/li&gt;
&lt;li&gt;信号驱动IO&lt;/li&gt;
&lt;li&gt;异步IO&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;那么这几种IO都有什么区别呢？下面我们一一来看，每种模型我都会举一个适当的例子助于理解：&lt;/p&gt;

&lt;h4&gt;1.阻塞IO&lt;/h4&gt;

&lt;p&gt;阻塞IO相信大家都最熟悉了，线程发起一个IO请求，直到有结果返回，否则则一直阻塞等待，比如我们平常常见的阻塞数据库操作，网络IO等。&lt;/p&gt;

&lt;p&gt;小明阻塞IO吃饭：&lt;/p&gt;

&lt;p&gt;五年前一天周末，小明和朋友一起去商场的外婆家吃饭，到店后发现排队的人超多，所以他就领了一个号码，然后他和朋友就坐在旁边等候，一直等着服务员叫他们的号，也不能做其他事，过了一个多小时终于轮到他们了，然后他们进店点菜，又得等待上菜，最后他们吃饭总共花了两个小时；&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;等待座位吃饭：一直阻塞，直到有座位&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;没什么说的，反正就是一直等，反应到程序中就是一直阻塞，而一个IO请求需要一个线程，可想而知当有大量的IO请求，线程的创建和销毁，线程间的切换，线程所占用的资源等等要耗费多少时间和资源，系统的性能会有多差。&lt;/p&gt;

&lt;h4&gt;2.非阻塞IO&lt;/h4&gt;

&lt;p&gt;非阻塞IO和阻塞IO的最大区别就在于线程发起一个IO请求,不会一直堵塞直到有数据，而是不断的检查是否已有数据，若有数据则读取数据。&lt;/p&gt;

&lt;p&gt;小明非阻塞IO吃饭：&lt;/p&gt;

&lt;p&gt;有了第一次的教训，小明学乖了，他在拿到后不再傻傻的等着，而是去外婆家旁边逛了逛，每过3分钟他就会回来，然后跑到前台去询问服务员轮到他了吗？不幸的是，排队的人超多，直到过了半个多小时后才轮到他进店吃饭，期间他大概问了十几次，他们进店点菜，又得等待上菜，最后他们吃饭总共花了两个小时，基本也没做啥其他事；&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后询问是否轮到他：非阻塞，非询问期间可以做点别的事,但也不做了啥大事&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说非阻塞IO的非阻塞主要体现在不需要一直等待到有数据，当然读数据那部分操作还是阻塞的，另外这种非阻塞模式需要用户线程自己不断询问检查，其实效率也不是太高，实际编程中运用的也不多。&lt;/p&gt;

&lt;h4&gt;3.多路复用IO&lt;/h4&gt;

&lt;p&gt;既然上面我们说到非阻塞IO的缺点，那么有没有什么方式改进呢？答案是当然有，那就是多路复用IO，我理解的它的特点就是复用，首先它也是一种非阻塞IO的模型，只不过上面说到轮询的方式用了不同的方式处理了，当一个线程发起IO请求，系统会将它注册到一个单独管理IO请求的一个线程，之后该IO的相关操作的通知状态都有这个管理IO请求的线程处理，Java 1.4发布的NIO就是这种模式，我们可以大致来看一下它的流程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;// 打开服务器套接字通道
ServerSocketChannel ssc = ServerSocketChannel.open();
// 服务器配置为非阻塞
ssc.configureBlocking(false);
// 进行服务的绑定
ssc.bind(new InetSocketAddress(&quot;localhost&quot;, 8008));
// 这里的selector就相当于单独管理IO请求的线程
Selector selector = Selector.open();
// 注册到selector，等待连接
ssc.register(selector, SelectionKey.OP_ACCEPT);

while (true) {
    selector.select();  //为IO请求去轮询状态
    Set&amp;lt;SelectionKey&amp;gt; keys = selector.selectedKeys(); //多个IO请求的状态
    Iterator&amp;lt;SelectionKey&amp;gt; keyIterator = keys.iterator();
    while (keyIterator.hasNext()) { //依次处理IO请求
        SelectionKey key = keyIterator.next();
        doThing(key)
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出Java NIO的模式就是多路复用IO模型的应用。&lt;/p&gt;

&lt;p&gt;小明多路复用IO吃饭：&lt;/p&gt;

&lt;p&gt;随着生意越来越好，外婆家发现好多顾客都堵在门口等待吃饭，等待区都站不下来人了，，思来想去，外婆家准备请一个人专门来维护顾客的排队请求，这样顾客取号后，就不用堵在门口了，我们叫他小A，小明这次取号后，将自己的相关信息告诉小A，并从小A那里获得了一个GPS（用于小A能快速找到小明，假设有了GPS后，小A能秒速找到小明），然后小明就跟朋友们开心的去逛商场，看看MM，买买衣服，而小A则不断的观察店里的情况，当有空座位出现的时候，他便会按照相关信息找到具体的顾客，将其带回进行用餐，但他们进店点菜，还得等待上菜，最后他们吃饭总共花了两个小时，但是他们不再需要排队等位，而是去做一些其他的事。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后委托给小A，小A观察到有空位后带回小明：非阻塞，领号后可以安心去做自己的事，不用担心错过&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;多路复用IO可以看成普通非阻塞IO的升级版，也是目前Java编程中用到比较多的IO模型，它的优势在于可以处理大量的IO请求，用一个线程管理所有的IO请求，无需像阻塞IO和非阻塞IO一样，每个IO需要一个线程处理，提升了系统的吞吐量。&lt;/p&gt;

&lt;h4&gt;4.信号驱动IO&lt;/h4&gt;

&lt;p&gt;信号驱动IO相对于以上几种模型最大的特点就是它支持内核信号通知，线程在发起一个IO请求后，会注册一个信号函数，然后内核在确认数据可读了，便会给相应的线程发送通知，让其进行具体IO读写操作。&lt;/p&gt;

&lt;p&gt;小明信号驱动IO吃饭：&lt;/p&gt;

&lt;p&gt;又了一段时间，外婆家通过使用复用IO模式缓解了排队拥挤的情况，但是觉得还要请一个人专门维护队列，感觉不划算，那么有没有一种更好的方式呢？经过一天的苦思冥想，外婆家的经理又想出一个好办法，让每个顾客在领完号后，关注一下外婆家的公众号，然后顾客就可以去做别的事了，定时或者当排队信息发生改变时给顾客发送通知，告知他现在的排队序号或者轮到他吃饭了，顾客可以根据相应的信息做相应的行为，比如快轮到了就开始往店里走（实际程序中并不一定有这种状态，这里只是大概模拟），或者轮到自己了然后进店吃饭，他们仍然不用排队等位，而是去做一些其他的事。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;领号后关注公众号，注册关系：非阻塞，领号后可以安心去做自己的事，不用担心错过&lt;/li&gt;
&lt;li&gt;等待上菜：一直阻塞，直到有菜（假设菜上齐了再吃）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;就实际来说，信号驱动IO用的并不多，因为信号驱动IO底层是使用SIGIO信号，所以它主要使用在UDP协议上，因为UDP产生SIGIO信号的时候只有两种可能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.要么数据到达&lt;/li&gt;
&lt;li&gt;2.发生错误&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;但相对TCP来说，产生SIGIO信号的地方太多了，比如请求连接，确认，断开，错误等等，所以我们很难根据SIGIO信号判断到底发生了什么。&lt;/p&gt;

&lt;h4&gt;5.异步IO&lt;/h4&gt;

&lt;p&gt;以上四种IO其实都还是同步IO，因为它们在读写数据时都是阻塞的，异步IO相较于它们最大的特点是它读写数据的时候也是非阻塞的，用户线程在发起一个IO请求的时候，除了给内核线程传递具体的IO请求外，还会给其传递数据缓冲区，回调函数通知等内容，然后用户线程就继续执行，等到内核线程发起相应通知的时候，说明数据已经准备就绪，用户线程直接使用即可，无需再阻塞从内核拷贝数据到用户线程。&lt;/p&gt;

&lt;p&gt;小明异步IO吃饭：&lt;/p&gt;

&lt;p&gt;有过了一段时间，小明又想吃外婆家了，但是这个周末他并不想出门，他突然在网上看到新闻说外婆家竟然可以叫外卖，小明高兴坏了，他马上打电话给外婆家，告诉它自己想要吃哪些菜（相当于IO请求所需要的数据），然后将自己的联系号码（相当于回调通知）和住址（相当于数据缓冲区）也告诉它，然后就挂掉电话，开心的做去打游戏了，过了半个小时后，手机响起，告知外卖已经到了，小明开门取外卖就可以直接开吃了。整个过程小明直到吃饭都没有等待阻塞。&lt;/p&gt;

&lt;p&gt;关键部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;叫外卖并提供相应的信息：非阻塞，打完电话后做自己的事&lt;/li&gt;
&lt;li&gt;通知外卖到了：直接开门取外卖直接开吃，非阻塞&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;我们可以看出，异步IO才是真正的异步，因为它连数据拷贝这个过程都是非阻塞的，用户线程根本不用关心数据的读写等操作，只需等待内核线程通知后，直接处理数据即可，当然异步IO需要系统内核支持，比如Linux中的AIO和Windows中的IOCP，但是也可以通过多线程跟阻塞I/O模拟异步IO，比如可以在多路复用IO模型上进行相应的改变，另外也有现有的实现，比如异步I/O的库：libeio&lt;/p&gt;

&lt;p&gt;最后用一张图总体概括一下Java IO（图片来自美团技术博客）：&lt;/p&gt;

&lt;p&gt;Java IO概图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/10/java-io.jpg&quot; alt=&quot;java-io&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;多路复用IO在Linux中的实现&lt;/h3&gt;

&lt;p&gt;因为后续会讲到Java NIO，所以我们需要了解操作系统是如何支持多路复用IO的，Linux中支持支持三种多路IO复用机制，分别是select、poll和epoll，本来这里我想自己写的，但查阅了相应的一些资料后，发现自己的水平还是不够，这里我不准备班门弄斧了，因为我找到了很多写的比较好的文章，这里就给大家列一下，仅供参考：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/tennysonsky/article/details/45745887&quot;&gt;Linux系统编程——I/O多路复用select、poll、epoll的区别使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.jianshu.com/p/dfd940e7fca2&quot;&gt;聊聊IO多路复用之select、poll、epoll详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/32163005&quot;&gt;IO 多路复用是什么意思？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;这篇文章主要讲了最基础的IO模型，不过我认为最基础的往往是最重要的，只有理解了基础的原理，才能对基于它们实现的类库或者工具有更加深刻的认识，下一篇文章将会主要讲一下基于多路复用IO的Java NIO，敬请期待。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MySQL几个简单SQL的优化</title>
   <link href="/2017/10/13/mysql-sql-optimize.html"/>
   <updated>2017-10-13T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;最近在做项目的时候，遇到了一些大数据量的操作，有大批量的CRUD的操作，一开始的实现的方案经过性能测试，发现性能并不是很好，然后开始审查代码，对相关可以提升性能的操作进行了优化，这里分享给大家。&lt;/p&gt;

&lt;h3&gt;原则&lt;/h3&gt;

&lt;p&gt;首先我这里不讲索引相关的内容以及数据库相应参数的优化，这里假设你对索引已经有了相关的了解了，我总结了下我这次的优化，主要两个原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一些特定的场景，尽量用批处理处理数据，比如批量添加数据，批量修改数据；&lt;/li&gt;
&lt;li&gt;结合业务尽量减少SQL的执行次数和查询不必要的数据；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;场景实践&lt;/h3&gt;

&lt;p&gt;为模拟运行场景，我这里建了一个表，并往里面添加了300w条数据，表结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;CREATE TABLE `tb_big_data` (
 `id` int(11) NOT NULL AUTO_INCREMENT,
 `weixin_id` varchar(64) NOT NULL,
 `openid` varchar(64) NOT NULL,
 `status` int(3) NOT NULL,
 `gmt_create` datetime NOT NULL,
 `gmt_modified` datetime NOT NULL,
 PRIMARY KEY (`id`),
 KEY `weixin_id_gmt_create_openid` (`weixin_id`,`gmt_create`,`openid`)
) ENGINE=InnoDB AUTO_INCREMENT DEFAULT CHARSET=utf8
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;1.分页查询小优化&lt;/h4&gt;

&lt;p&gt;分页查询老生常谈，网上各种优化方法都很多，这里就不提及了，这里只是分享一个小技巧：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何在使用最普通的limit的时候提高性能？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;假设我们现在有一条这样的SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` where weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-10 00:00:00' order by id asc limit 800000, 100;

执行时间：100 rows in set (1.53 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假如我们现在不能进行其他优化，比如传入最小id，分表查询等策略，以及不进行SQL预热，怎么提高这条SQL的速度呢？
其实很简单我们只需要一个in操作即可：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` t1 where t1.id in ( 
    SELECT tt.id FROM ( 
        SELECT id FROM `tb_big_data` t2 where weixin_id = 'gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-10 00:00:00' order by t2.id asc limit 800100, 100
        ) as tt);

执行时间：100 rows in set (1.17 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出只需稍加修改，SQL的效率可以提高30%~40%，而且在单条数据记录越大的情况下效果越好，当然这不是最好的分页方法，这只是一个小技巧；&lt;/p&gt;

&lt;h4&gt;2.减少SQL查询&lt;/h4&gt;

&lt;p&gt;现在有一个需求我们现在有一个用户的列表（用户的唯一标识为openid）然后我们需要判断用户在当天是否有过相应的记录；&lt;/p&gt;

&lt;p&gt;这是问题其实很简单，我们首先一想到的操作就是循环这个列表一个一个判断，很简单也很好实现，但是真正测试的时候发现性能却很差，尤其在数据量大的情况下，倍数级增长，这里有有网络数据传输消耗的时间和SQL本身的执行时间；&lt;/p&gt;

&lt;p&gt;假设我们现在执行一条以下的SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid='2n6bvynihm5bzgyx';

执行时间：1 row in set (0.95 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在如果我们执行100次，不敢想象会是什么情况，庆幸自己发现了这个问题，因为在数据量少的情况下，这个问题表现的并不是那么严重，其实我们稍加改变就能以另一种高效的方式解决这个问题：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;SELECT * FROM `tb_big_data` WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid in ('2n6bvynihm5bzgyx','1stbvdnl63de2q37','3z8552gxzfi3wy27'...);

执行时间：100 row in set (1.05 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现了没有，还是用in，而且执行时间几乎与单条查询的时间一样，可见只是单一这一部分处理就可以提升了很大的性能。&lt;/p&gt;

&lt;h4&gt;3.特定场景使用SQL的批处理&lt;/h4&gt;

&lt;p&gt;这个跟上一点有一个相似点，那就是减少SQL执行，上面只是查询而已，而当出现大批量的CUD的操作时，执行每条SQL，数据库都会进行事务处理，这将会消耗大量的时间，而且极端情况下会引起大批量SQL等待无法执行，导致业务出错，正是因为这些原因，我们在一些适当的情况下可以使用批处理来解决这个问题。&lt;/p&gt;

&lt;h5&gt;（1）批量插入&lt;/h5&gt;

&lt;p&gt;批量插入比较简单，也比较常用，这里就给一下基本语法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;INSERT INTO table_name (field1,filed2,...) values (value11,value12,...),(value21,value22,...),...
&lt;/code&gt;&lt;/pre&gt;

&lt;h5&gt;（2）批量更新&lt;/h5&gt;

&lt;p&gt;我先举个简单的例子，我们现在来根据一些条件来更新数据，具体SQL如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;update `tb_big_data` set status = 2 WHERE weixin_id ='gh_266a30a8a1f6' and gmt_create &amp;gt; '2017-10-13 00:00:00' and openid = '2n6bvynihm5bzgyx';

Query OK, 1 row affected (2.28 sec)
Rows matched: 1  Changed: 1  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很惊讶，我们只是更新了一条记录，而且更新条件上是有复合索引的，没想到速度还那么慢，可以想象如果我们批量更新数据，那得耗时多少；&lt;/p&gt;

&lt;p&gt;但是我们看一下另一条SQL：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;update `tb_big_data` set status = 1 WHERE id = 900098;

Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的id值为之前条件筛选出来的记录的id，是不是很惊讶，怎么这条SQL执行的时间几乎不需要什么时间，所以我们可以利用这个特点和批量查询简化批量更新，虽然这种方式不能让性能到最优，但是也能提升很大了，我进行了一个测试，根据相应条件批量更新100条数据：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方式&lt;/th&gt;
&lt;th&gt;直接批量更新&lt;/th&gt;
&lt;th&gt;先批量查主键再批量更新&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;耗时 &lt;/td&gt;
&lt;td&gt; 289.12s &lt;/td&gt;
&lt;td&gt; 1.342s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;可以看出这种方式相对对于普通方式来说，性能提升巨大，具体执行的时候我们也可以将这些SQL放在一个事务提交，减少数据库事务次数，但只这是一种在代码层面上的优化；&lt;/p&gt;

&lt;p&gt;另外我们可以利用MySQL提供的特殊语法进行批量更新，具体语法为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;#语法
INSERT INTO table_name (id,field1,field2,...) VALUES  (id1,value11,value12,...),(id1,value11,value12,...),... on duplicate key update  field = VAULES(field);

#使用例子

INSERT INTO `tb_big_data` (id,weixin_id,openid,gmt_create,status) values  (1,'gh_266a30a8a1f6','w9q8fmodytjgppsr','2017-10-13 12:00:00',3),(2,'gh_266a30a8a1f6','bu1flmch4i8eegzf','2017-10-13 12:00:00',3) on duplicate key update status = VAULES(status);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过测试这种方式在数据量小的情况下与上述方式效率差不多，但是随着数据量越来越大，性能也越来越好，缺点的话主要传输的数据量很大，不需要更新的字段也需要传输。&lt;/p&gt;

&lt;p&gt;另外也不推荐大量数据的批量更新，一次不要超过1000条为好。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;总的来说，SQL优化是一门细心的学问，需要不断去尝试，测试，找到最优方式，另外还有一点就是要结合实际情况，综合考虑选择合适的方式。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Asyncdb（一）：写一个纯函数式的Mysql异步驱动</title>
   <link href="/2017/10/04/mysql-driver-info.html"/>
   <updated>2017-10-04T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;之前的Akka系列博客接下去可能并不会经常更新了，但是后续看到一些好的点或者大家对哪些还是比较感兴趣还会继续写几篇，这里先跟大家说明一下。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;写一个纯函数式的Mysql异步驱动&lt;/strong&gt;这个构思是公司的一个大佬提的，这将会是一个开源项目，我也很有幸能够参与其中，尝试写一个自己真正意义上的开源项目，其实很多人会有疑惑，为什么我们要做一个数据库驱动，就目前JVM生态上，已经有了比较成熟的产品，我们还能做出一个怎样的数据库驱动呢？&lt;/p&gt;

&lt;p&gt;首先我们明确了一点，绝不做重复造轮子的事，做这个项目一定要有意义，即使未来可能实用性兼容性等方面不是很擅长，我们也要表达出新的设计理念，能给数据库驱动注入一股新的活力。&lt;/p&gt;

&lt;p&gt;我们在确定这个项目的时候，也对目前JVM生态中的数据库驱动进行了一定的总结，仅供参考：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;项目&lt;/th&gt;
&lt;th&gt;mysql-async&lt;/th&gt;
&lt;th&gt;HikariCP + mysql-connector/j&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;编程模型 &lt;/td&gt;
&lt;td&gt; 异步 &lt;/td&gt;
&lt;td&gt; 同步&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;网络IO &lt;/td&gt;
&lt;td&gt; NIO &lt;/td&gt;
&lt;td&gt; BIO&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;链接池 &lt;/td&gt;
&lt;td&gt; 异步实现 &lt;/td&gt;
&lt;td&gt; 同步实现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;过载防护 &lt;/td&gt;
&lt;td&gt; 通过调节队列长度实现 &lt;/td&gt;
&lt;td&gt; 需要额外实现 （例如指定线程池任务队列长度）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;可伸缩性 &lt;/td&gt;
&lt;td&gt; 只需要设置合理连接数(例如几十个) &lt;/td&gt;
&lt;td&gt; 需要测试最佳线程数和链接数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;线程数 &lt;/td&gt;
&lt;td&gt; 少 &lt;/td&gt;
&lt;td&gt; 多&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;具体相关测试及说明可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/04/mysql-async-1/&quot;&gt;MySQL 异步驱动浅析 （一）：性能分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;相信写过Java工程的同学都应该知道mysql-connector-java，但应该很多人对其的实现和相关架构设计应该不是很了解，正如我们上面对其相关功能测试，发现它的某些方面表现并不是很好，比如使用了BIO，请求时需要大量的线程等等。&lt;/p&gt;

&lt;p&gt;相信你们也注意到了mysql-async，但是应该大多数人都不是很熟悉，它也是一个基于Netty，使用Scala编写的，完全异步的数据库驱动，同时支持PostgreSQL和MySQL，其项目地址&lt;a href=&quot;https://github.com/mauricio/postgresql-async&quot;&gt;postgresql-async&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;其实我们公司项目底层用的数据库驱动也是基于mysql-async的，不过因为实际使用中遇到了一些问题，，具体相关问题分析可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/05/mysql-async-2/&quot;&gt;MySQL 异步驱动浅析 （二）：缺点分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;虽然我们使用的mysql-async内部版本对上述的许多问题都进行了修复，具体信息可以看我们写的相关系列文章&lt;a href=&quot;https://scala.cool/2017/07/mysql-async-3/&quot;&gt;MySQL 异步驱动浅析 （三）：连接池改进方案&lt;/a&gt;，但是整个项目变得混乱，架构设计也不是很完美，所以我们最终决定自己实现一个纯函数式的Mysql异步驱动，我们叫它：&lt;strong&gt;asyncdb&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;目标&lt;/h3&gt;

&lt;p&gt;那么我们到底要做一个怎样的驱动呢？我们提了以下几个主要方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.构建于cats-effect(纯函数式的关键)&lt;/li&gt;
&lt;li&gt;2.合理的数据库包解析框架&lt;/li&gt;
&lt;li&gt;3.支持简单的流处理(可选)&lt;/li&gt;
&lt;li&gt;4.基于Java NIO2，绝不阻塞&lt;/li&gt;
&lt;li&gt;5.提供对应Java8的接口&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说，除了第一点大家可能比较陌生，其他几点大家都应该能大致了解,但是第一点才是我们这个项目最重要的一点，也是用来解决我们之前遇到问题的关键，后续我会写几篇文章对于这一点进行的相关介绍，如果有兴趣的同学可以自己了解一下：&lt;a href=&quot;https://github.com/typelevel/cats-effect&quot;&gt;cats-effect&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;关注 Asyncdb&lt;/h3&gt;

&lt;p&gt;如果你对我们的项目也有兴趣，欢迎你们star我们的项目，项目地址:&lt;a href=&quot;https://github.com/asyncdb/asyncdb&quot;&gt;asyncdb&lt;/a&gt;,我们将会从头开始，你可以一步一步了解我们的架构设计和具体的实现方法，当然你有好的想法或者相关问题，也欢迎给我们提issue。&lt;/p&gt;

&lt;h3&gt;进阶学习&lt;/h3&gt;

&lt;p&gt;若是你对数据库驱动非常有兴趣，也想探究里面的奥秘，这里我提一些相应的建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.熟悉了解Java NIO，并熟练使用它&lt;/li&gt;
&lt;li&gt;2.学习MySQL数据库网络传输包协议&lt;/li&gt;
&lt;li&gt;3.掌握函数式语言中的Monad表达式，理解其的含义和使用场景&lt;/li&gt;
&lt;li&gt;4.学习Scala相关的函数库比如：&lt;a href=&quot;https://github.com/typelevel/cats&quot;&gt;cats&lt;/a&gt;,&lt;a href=&quot;https://github.com/milessabin/shapeless&quot;&gt;shapeless&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.学习IO-Monad(cats-effect)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;最后也希望大家能参与其中，帮助我们不断的完善它，共同成长！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（十）：Akka集群之Akka Cluster</title>
   <link href="/2017/09/05/learning-akka-10.html"/>
   <updated>2017-09-05T00:00:00+08:00</updated>
   <id>urn:uuid:8d2f2b63-g930-3d54-8ca7-fbvbds2a4fge</id>
   <content type="html">&lt;p&gt;上一篇文章我们讲了Akka Remote，理解了Akka中的远程通信，其实Akka Cluster可以看成Akka Remote的扩展，由原来的两点变成由多点组成的通信网络，这种模式相信大家都很了解，就是集群，它的优势主要有两点：系统伸缩性高，容错性更好。&lt;/p&gt;

&lt;h3&gt;集群概念&lt;/h3&gt;

&lt;p&gt;很多人很容易把分布式和集群的概念搞错，包括我也是，我一开始也以为它们两个是一样的概念，只是叫法不同而已，但其实不然，虽然它们在实际场景中都是部署在不同的机器上，但它们所提供的功能并不是一样的。举个简单的例子来看看它们之间的不同：&lt;/p&gt;

&lt;p&gt;为了保持整个系列连续性，我又以抽奖为基础举一个例子：&lt;/p&gt;

&lt;p&gt;假定我们现在抽奖流程包括，抽奖分配奖品和用户根据链接领取指定奖品，用户先抽奖然后获取奖品链接，点击链接填写相应信息领取奖品。&lt;/p&gt;

&lt;h4&gt;1.分布式：&lt;/h4&gt;

&lt;p&gt;我们现在把抽奖分配奖品和用户根据链接领取指定奖品分别部署在两台机器上，突然有一天很不幸，抽奖活动进行到一半，抽奖分配奖品那台机子所在的区域停电了，很显然，后续的用户参与抽奖就不能进行了，因为我们只有一台抽奖分配奖品的机子，但由于我们将领取奖品的业务部署在另一台机器上，所以前面那些中奖的用户还是可以正常的领取奖品，具体相关定义可参考《分布式系统概念与设计》中对分布式系统的定义。&lt;/p&gt;

&lt;h4&gt;2.集群：&lt;/h4&gt;

&lt;p&gt;现在我们还是有两台机器，但是我们在两个机器上都部署了抽奖分配奖品和用户根据链接领取指定奖品的业务逻辑，突然有一天，有一台所在的区域停电了，但这时我们并担心，因为另一台服务器还是可以正常的运行处理用户的所有请求。&lt;/p&gt;

&lt;p&gt;它们的各自特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分布式：是指在多台不同的服务器中部署不同的服务模块，通过远程调用协同工作，对外提供服务；&lt;/li&gt;
&lt;li&gt;集群：是指在多台不同的服务器中部署相同应用或服务模块，构成一个集群，通过负载均衡设备对外提供服务；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;总的来说： 分布式是以分离任务缩短时间来提高效率，而集群是在单位时间内处理更多的任务来提高效率。&lt;/p&gt;

&lt;h3&gt;Akka Cluster&lt;/h3&gt;

&lt;p&gt;在前面的文章Akka Actor的工作方式，我们可以将一个任务分解成一个个小任务，然后分配给它的子Actor执行，其实这就可以看成一个小的分布式系统，那么在Akka中，集群又是一种怎样的概念呢？&lt;/p&gt;

&lt;p&gt;其实往简单里说，就是一些相同的ActorSystem的组合，它们具有着相同的功能，我们需要执行的任务可以随机的分配到目前可用的ActorSystem上，这点跟Nginx的负载均衡很类似，根据算法和配置将请求转发给运行正常的服务器去，Akka集群的表现形式也是这样，当然它背后的理论基础是基于gossip协议的，目前很多分布式的数据库的数据同步都采用这个协议，有兴趣的同学可以自己去研究研究，只是我也是一知半解，这里就不写了，怕误导了大家。&lt;/p&gt;

&lt;p&gt;下面我来讲讲Akka Cluster中比较重要的几个概念：&lt;/p&gt;

&lt;h4&gt;Seed Nodes&lt;/h4&gt;

&lt;p&gt;Seed Nodes可以看过是种子节点或者原始节点，它的一个主要作用用于可以自动接收新加入集群的节点的信息，并与之通信，使用方式可以用配置文件或者运行时指定，推荐使用配置文件方式，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.seed-nodes = [
  &quot;akka.tcp://ClusterSystem@host1:2552&quot;,
  &quot;akka.tcp://ClusterSystem@host2:2552&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;seed-nodes列表中的第一个节点会集群启动的时候初始化，而其他节点则是在有需要时再初始化。&lt;/p&gt;

&lt;p&gt;当然你也可以不指定seed nodes，但你可以需要手动或者在程序中写相关逻辑让相应的节点加入集群，具体使用方式可参考官方文档。&lt;/p&gt;

&lt;h4&gt;Cluster Events&lt;/h4&gt;

&lt;p&gt;Cluster Events字面意思是集群事件，那么这是什么意思呢？其实它代表着是一个节点的各种状态和操作，举个例子，假设你在打一局王者5v5的游戏，那么你可以把十个人看成一个集群，我们每个人都是一个节点，我们的任何操作和状态都能被整个系统捕获到，比如A杀了B、A超神了，A离开了游戏，A重新连接了游戏等等，这些状态和操作在Cluster Events中就相当于节点之于集群，那么它具体是怎么使用的呢？&lt;/p&gt;

&lt;p&gt;首先我们必须将节点注册到集群中，或者说节点订阅了某个集群，我们可以这么做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;cluster.subscribe(self, classOf[MemberEvent], classOf[UnreachableMember])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体代码相关的使用我会再下面写一个demo例子，来说明是如何具体使用它们的。&lt;/p&gt;

&lt;p&gt;从上面的代码我们可以看到有一个MemberEvent的概念，这个其实就是每个成员所可能拥有的events，那么一个成员在它的生命周期中有以下的events&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ClusterEvent.MemberJoined - 新的节点加入集群，此时的状态是Joining；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberUp - 新的节点加入集群，此时的状态是Up；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberExited - 节点正在离开集群，此时的状态是Exiting；&lt;/li&gt;
&lt;li&gt;ClusterEvent.MemberRemoved - 节点已经离开集群，此时的状态是Removed；&lt;/li&gt;
&lt;li&gt;ClusterEvent.UnreachableMember - 节点被标记为不可触达；&lt;/li&gt;
&lt;li&gt;ClusterEvent.ReachableMember - 节点被标记为可触达；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;状态说明：
- Joining: 加入集群的瞬间状态
- Up: 正常服务状态
- Leaving / Exiting: 正常移出中状态
- Down: 被标记为停机（不再是集群决策的一部分）
- Removed: 已从集群中移除&lt;/p&gt;

&lt;h4&gt;Roles&lt;/h4&gt;

&lt;p&gt;虽然上面说到集群中的各个节点的功能是一样的，其实并不一定，比如我们将分布式和集群融合到一起，集群中的一部分节点负责接收请求，一部分用于计算，一部分用于数据存储等等，所以Akka Cluster提供了一种Roles的概念，用来表示该节点的功能特性，我们可以在配置文件中指定,比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.cluster.roles = request
akka.cluster.roles = compute
akka.cluster.roles = store
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;ClusterClient&lt;/h4&gt;

&lt;p&gt;ClusterClient是一个集群客户端，主要用于集群外部系统与集群通信，使用它非常方便，我们只需要将集群中的任意指定一个节点作为集群客户端，然后将其注册为一个该集群的接待员，最后我们就可以在外部系统直接与之通信了，使用ClusterClient需要做相应的配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka.extensions = [&quot;akka.cluster.client.ClusterClientReceptionist&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假设我们现在我一个接待的Actor，叫做frontend,我们就可以这样做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;sacla&quot;&gt;val frontend = system.actorOf(Props[TransformationFrontend], name = &quot;frontend&quot;)
ClusterClientReceptionist(system).registerService(frontend)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Akka Cluster例子&lt;/h3&gt;

&lt;p&gt;上面讲了集群概念和Akka Cluster中相对重要的概念，下面我们就来写一个Akka Cluster的demo，&lt;/p&gt;

&lt;p&gt;demo需求：&lt;/p&gt;

&lt;p&gt;线假设需要执行一些相同任务，频率为2s一个，现在我们需要将这些任务分配给Akka集群中的不同节点去执行，这里使用ClusterClient作为集群与外部的通信接口。&lt;/p&gt;

&lt;p&gt;首先我们先来定义一些命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
package sample.cluster.transformation

final case class TransformationJob(text: String) // 任务内容
final case class TransformationResult(text: String) // 执行任务结果
final case class JobFailed(reason: String, job: TransformationJob) //任务失败相应原因
case object BackendRegistration // 后台具体执行任务节点注册事件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们实现具体执行任务逻辑的后台节点：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationBackend extends Actor {

  val cluster = Cluster(context.system)

  override def preStart(): Unit = cluster.subscribe(self, classOf[MemberEvent])  //在启动Actor时将该节点订阅到集群中
  override def postStop(): Unit = cluster.unsubscribe(self)

  def receive = {
    case TransformationJob(text) =&amp;gt; { // 接收任务请求
      val result = text.toUpperCase // 任务执行得到结果（将字符串转换为大写）
      sender() ! TransformationResult(text.toUpperCase) // 向发送者返回结果
    }
    case state: CurrentClusterState =&amp;gt;
      state.members.filter(_.status == MemberStatus.Up) foreach register // 根据节点状态向集群客户端注册
    case MemberUp(m) =&amp;gt; register(m)  // 将刚处于Up状态的节点向集群客户端注册
  }

  def register(member: Member): Unit = {   //将节点注册到集群客户端
    context.actorSelection(RootActorPath(member.address) / &quot;user&quot; / &quot;frontend&quot;) !
      BackendRegistration
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;相应节点的配置文件信息，我这里就不贴了，请从相应的源码demo里获取。&lt;/em&gt;&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;接着我们来实现集群客户端：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
class TransformationFrontend extends Actor {

  var backends = IndexedSeq.empty[ActorRef] //任务后台节点列表
  var jobCounter = 0

  def receive = {
    case job: TransformationJob if backends.isEmpty =&amp;gt;  //目前暂无执行任务节点可用
      sender() ! JobFailed(&quot;Service unavailable, try again later&quot;, job)

    case job: TransformationJob =&amp;gt; //执行相应任务
      jobCounter += 1
      implicit val timeout = Timeout(5 seconds)
      val backend = backends(jobCounter % backends.size) //根据相应算法选择执行任务的节点
      println(s&quot;the backend is ${backend} and the job is ${job}&quot;)
      val result  = (backend ? job)
        .map(x =&amp;gt; x.asInstanceOf[TransformationResult])  // 后台节点处理得到结果
      result pipeTo sender  //向外部系统发送执行结果

    case BackendRegistration if !backends.contains(sender()) =&amp;gt;  // 添加新的后台任务节点
      context watch sender() //监控相应的任务节点
      backends = backends :+ sender()

    case Terminated(a) =&amp;gt;
      backends = backends.filterNot(_ == a)  // 移除已经终止运行的节点
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt; 最后我们实现与集群客户端交互的逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class ClientJobTransformationSendingActor extends Actor {

  val initialContacts = Set(
    ActorPath.fromString(&quot;akka.tcp://ClusterSystem@127.0.0.1:2551/system/receptionist&quot;))
  val settings = ClusterClientSettings(context.system)
    .withInitialContacts(initialContacts)

  val c = context.system.actorOf(ClusterClient.props(settings), &quot;demo-client&quot;)


  def receive = {
    case TransformationResult(result) =&amp;gt; {
      println(s&quot;Client response and the result is ${result}&quot;)
    }
    case Send(counter) =&amp;gt; {
        val job = TransformationJob(&quot;hello-&quot; + counter)
        implicit val timeout = Timeout(5 seconds)
        val result = Patterns.ask(c,ClusterClient.Send(&quot;/user/frontend&quot;, job, localAffinity = true), timeout)
        result.onComplete {
          case Success(transformationResult) =&amp;gt; {
            self ! transformationResult
          }
          case Failure(t) =&amp;gt; println(&quot;An error has occured: &quot; + t.getMessage)
        }
      }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们开始运行这个domo：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object DemoClient {
  def main(args : Array[String]) {

    TransformationFrontendApp.main(Seq(&quot;2551&quot;).toArray)  //启动集群客户端
    TransformationBackendApp.main(Seq(&quot;8001&quot;).toArray)   //启动三个后台节点
    TransformationBackendApp.main(Seq(&quot;8002&quot;).toArray)
    TransformationBackendApp.main(Seq(&quot;8003&quot;).toArray)

    val system = ActorSystem(&quot;OTHERSYSTEM&quot;)
    val clientJobTransformationSendingActor =
      system.actorOf(Props[ClientJobTransformationSendingActor],
        name = &quot;clientJobTransformationSendingActor&quot;)

    val counter = new AtomicInteger
    import system.dispatcher
    system.scheduler.schedule(2.seconds, 2.seconds) {   //定时发送任务
      clientJobTransformationSendingActor ! Send(counter.incrementAndGet())
    }
    StdIn.readLine()
    system.terminate()
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/09/akka-cluster.png&quot; alt=&quot;akka-cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从结果可以看到，我们将任务根据算法分配给不同的后台节点进行执行，最终返回结果。&lt;/p&gt;

&lt;h3&gt;本文目的&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;掌握集群基本概念&lt;/li&gt;
&lt;li&gt;了解学习Akka cluster的工作方式和主要角色&lt;/li&gt;
&lt;li&gt;尝试自己写一个Akka cluster的相关例子&lt;/li&gt;
&lt;li&gt;下一步进阶了解Akka cluster的背后原理&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;本文的demo例子已上传github：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_07&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（九）：Akka分布式之Akka Remote</title>
   <link href="/2017/08/10/learning-akka-9.html"/>
   <updated>2017-08-10T00:00:00+08:00</updated>
   <id>urn:uuid:8d4f2b63-e930-3d54-8ca7-fbvbds2a4fgd</id>
   <content type="html">&lt;p&gt;Akka作为一个天生用于构建分布式应用的工具，当然提供了用于分布式组件即Akka Remote，那么我们就来看看如何用Akka Remote以及Akka Serialization来构建分布式应用。&lt;/p&gt;

&lt;h3&gt;背景&lt;/h3&gt;

&lt;p&gt;很多同学在程序的开发中都会遇到一个问题，当业务需求变得越来越复杂，单机服务器已经不足以承载相应的请求的时候，我们都会考虑将服务部署到不同的服务器上，但服务器之间可能需要相互调用，那么系统必须拥有相互通信的接口，用于相应的数据交互，这时候一个好的远程调用方案是一个绝对的利器，主流的远程通信有以下几种选择：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RPC（Remote Procedure Call Protocol）&lt;/li&gt;
&lt;li&gt;Web Service&lt;/li&gt;
&lt;li&gt;JMS（Java Messaging Service）&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这几种方式都是被采用比较广泛的通信方案，有兴趣的同学可以自己去了解一下，这里我会讲一下Java中的RPC即RMI （Remote Method Invocation）和JMS。&lt;/p&gt;

&lt;h3&gt;JAVA远程调用&lt;/h3&gt;

&lt;p&gt;RMI和JMS相信很多写过Java程序的同学都知道，是Java程序用来远程通信的主要方式，那么RMI和JMS又有什么区别呢？&lt;/p&gt;

&lt;h4&gt;1.RMI&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;同步通信：在使用RMI调用远程方法时，线程会持续等待直到结果返回，所以它是一个同步阻塞操作；&lt;/li&gt;
&lt;li&gt;强耦合：请求的系统中需要使用的RMI服务进行接口声明，返回的数据类型有一定的约束；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;实现相对简单，方法调用形式通俗易理解，接口声明服务功能清晰。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;只局限支持JVM平台；&lt;/li&gt;
&lt;li&gt;对无法兼容Java语言的其他语言也不适用；&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;2.JMS&lt;/h4&gt;

&lt;h5&gt;i.特征：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;异步通信：JMS发送消息进行通信，在通信过程中，线程不会被阻塞，不必等待请求回应，所以是一个异步操作；&lt;/li&gt;
&lt;li&gt;松耦合：不需要接口声明，返回的数据类型可以是各种各样，比如JSON，XML等；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;ii.通信方式：&lt;/h5&gt;

&lt;p&gt;（1）点对点消息传送模型&lt;/p&gt;

&lt;p&gt;顾名思义，点对点可以理解为两个服务器的定点通信，发送者和接收者都能明确知道对方是谁，大致模型如下：
&lt;img src=&quot;/media/images/2017/08/jms-point-to-point.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（2）发布/订阅消息传递模型&lt;/p&gt;

&lt;p&gt;点对点模型有些场景并不是很适用，比如有一台主服务器，它产生一条消息需要让所有的从服务器都能收到，若采用点对点模型的话，那主服务器需要循环发送消息，后续若有新的从服务器增加，还要改主服务器的配置，这样就会导致不必要的麻烦，那么发布/订阅模型是怎么样的呢？其实这种模式跟设计模式中的观察者模式很相似，相信很多同学都很熟悉，它最大的特点就是较松耦合，易扩展等特点，所以发布/订阅模型的大致结构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/jms-topic.png&quot; alt=&quot;jms-point-to-point&quot; /&gt;&lt;/p&gt;

&lt;h5&gt;iii.优点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;由于使用异步通信，不需要线程暂停等待，性能相对较高。&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;iiii.缺点：&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;技术实现相对复杂，并需要维护相关的消息队列；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;更通俗的说：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RMI可以看成是用打电话的方式进行信息交流，而JMS更像是发短信。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总的来说两种方式没有孰优孰劣，我们也不用比较到底哪种方式比较好，存在即合理，更重要的是哪种选择可能更适合你的系统。&lt;/p&gt;

&lt;h3&gt;RMI Example&lt;/h3&gt;

&lt;p&gt;这里我写一个RMI的例子，一方面来看一下它的使用方式，另一方面用于和后续的Akka Remote做一些比较：&lt;/p&gt;

&lt;p&gt;首先我们来编写相应的传输对象和通信接口：&lt;/p&gt;

&lt;p&gt;1.JoinRmiEvt：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class JoinRmiEvt implements Remote , Serializable{
    private static final long serialVersionUID = 1L;
    private Long id;
    private String name;

    public JoinRmiEvt(Long id, String name) {
        this.id = id;
        this.name = name;
    }

    public Long getId() {
        return id;
    }

    public void setId(Long id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.RemoteRmi:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public interface RemoteRmi extends Remote {
    public void sendNoReturn(String message) throws RemoteException, InterruptedException;
    public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在服务端对该接口进行实现：&lt;/p&gt;

&lt;p&gt;3.RemoteRmiImpl:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRmiImpl extends UnicastRemoteObject implements RemoteRmi {

    private static final long serialVersionUID = 1L;

    public  RemoteRmiImpl() throws RemoteException {};

    @Override
    public void sendNoReturn(String message) throws RemoteException, InterruptedException {
        Thread.sleep(2000);
        //throw new RemoteException(); 
    }

    @Override
    public String sendHasReturn(JoinRmiEvt joinRmiEvt) throws RemoteException {
      if (joinRmiEvt.getId() &amp;gt;= 0)
          return new StringBuilder(&quot;the&quot;).append(joinRmiEvt.getName()).append(&quot;has join&quot;).toString();
      else return null;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接着我们在Server端绑定相应端口并发布服务，然后启动：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRMIServer {
    public static void main(String[] args) throws RemoteException, AlreadyBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the RemoteRMIServer is Starting ...&quot;);
        RemoteRmiImpl remoteRmi = new RemoteRmiImpl();
        System.out.println(&quot;Binding server implementation to registry&quot;);
        LocateRegistry.createRegistry(2553);
        Naming.bind(&quot;rmi://127.0.0.1:2553/remote_rmi&quot;,remoteRmi);
        System.out.println(&quot;the RemoteRMIServer is Started&quot;);
        Thread.sleep(10000000);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面我们在Client端调用Server端的服务：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;public class RemoteRmiClient {
    public static void main(String[] args) throws RemoteException, NotBoundException, MalformedURLException, InterruptedException {
        System.out.println(&quot;the client has started&quot;);
        String url = &quot;rmi://127.0.0.1:2553/remote_rmi&quot;;
        RemoteRmi remoteRmi = (RemoteRmi) Naming.lookup(url);
        System.out.println(&quot;the client has running&quot;);
        remoteRmi.sendNoReturn(&quot;send no return&quot;);
        System.out.println(remoteRmi.sendHasReturn(new JoinRmiEvt(1L,&quot;godpan&quot;)));
        System.out.println(&quot;the client has end&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/java-rmi-result.png&quot; alt=&quot;java-rmi-result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Java Rmi调用是一个阻塞的过程，这会导致一个问题，假如服务端的服务奔溃了，会导致客户端没有反应；&lt;/li&gt;
&lt;li&gt;Java Rmi使用的是Java默认的序列化方式,性能并不是很好，而且并不提供支持使用其他序列化的接口，在一些性能要求高的系统会有一定的瓶颈；&lt;/li&gt;
&lt;li&gt;在Rmi中使用的相应的接口和对象必须实现相应的接口，必须制定抛出相应的Exception，导致代码看起来异常的繁琐；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Remote&lt;/h3&gt;

&lt;p&gt;上面讲到JAVA中远程通信的方式，但我们之前说过Akka也是基于JVM平台的，那么它的通信方式又有什么不同呢？&lt;/p&gt;

&lt;p&gt;在我看来，Akka的远程通信方式更像是RMI和JMS的结合，但更偏向于JMS的方式，为什么这么说呢，我们先来看一个示例:&lt;/p&gt;

&lt;p&gt;我们先来创建一个远程的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;class RemoteActor extends Actor {
  def receive = {
    case msg: String =&amp;gt;
      println(s&quot;RemoteActor received message '$msg'&quot;)
      sender ! &quot;Hello from the RemoteActor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们在远程服务器上启动这个Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么现在我们假如有一个系统需要向这个Actor发送消息应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们需要类似RMI发布自己的服务一样，我们需要为其他系统调用远程Actor提供消息通信的接口，在Akka中，设置非常简单，不需要代码侵入，只需简单的在配置文件里配置即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;akka {
  actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
  }
  remote {
    enabled-transports = [&quot;akka.remote.netty.tcp&quot;]
    netty.tcp {
      hostname = $localIp  //比如127.0.0.1
      port = $port //比如2552
    }
    log-sent-messages = on
    log-received-messages = on
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们只需配置相应的驱动，传输方式，ip，端口等属性就可简单完成Akka Remote的配置。&lt;/p&gt;

&lt;p&gt;当然本地服务器也需要配置这些信息，因为Akka之间是需要相互通信的，当然配置除了hostname有一定的区别外，其他配置信息可一致，本例子是在同一台机器上，所以这里hostname是相同的。&lt;/p&gt;

&lt;p&gt;这时候我们就可以在本地的服务器向这个Actor发送消息了，首先我们可以创建一个本地的Actor：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object Init
case object SendNoReturn

class LocalActor extends Actor{

  val path = ConfigFactory.defaultApplication().getString(&quot;remote.actor.name.test&quot;)
  implicit val timeout = Timeout(4.seconds)
  val remoteActor = context.actorSelection(path)

  def receive: Receive = {
    case Init =&amp;gt; &quot;init local actor&quot;
    case SendNoReturn =&amp;gt; remoteActor ! &quot;hello remote actor&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;remote.actor.name.test&lt;/code&gt;的值为：“akka.tcp://RemoteDemoSystem@127.0.0.1:4444/user/RemoteActor”，另外我们可以看到我们使用了&lt;code&gt;context.actorSelection(path)&lt;/code&gt;来获取的是一个ActorSelection对象，若是需要获得ActorRef，我们可以调用它的resolveOne(),它返回的是是一个Future[ActorRef],这里是不是很熟悉，因为它跟本地获取Actor方式是一样的，因为Akka中Actor是位置透明的，获取本地Actor和远程Actor是一样的。&lt;/p&gt;

&lt;p&gt;最后我们首先启动远程Actor的系统：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object RemoteDemo extends App  {
  val system = ActorSystem(&quot;RemoteDemoSystem&quot;)
  val remoteActor = system.actorOf(Props[RemoteActor], name = &quot;RemoteActor&quot;)
  remoteActor ! &quot;The RemoteActor is alive&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们在本地系统中启动这个LocalActor，并向它发送消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;object LocalDemo extends App {

  implicit val system = ActorSystem(&quot;LocalDemoSystem&quot;)
  val localActor = system.actorOf(Props[LocalActor], name = &quot;LocalActor&quot;)

  localActor ! Init
  localActor ! SendNoReturn
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到RemoteActor收到了一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-no-return.png&quot; alt=&quot;send-no-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从以上的步骤和结果看出可以看出，Akka的远程通信跟JMS的点对点模式似乎更相似一点，但是它有不需要我们维护消息队列，而是使用Actor自身的邮箱，另外我们利用context.actorSelection获取的ActorRef，可以看成远程Actor的副本，这个又和RMI相关概念类似，所以说Akka远程通信的形式上像是RMI和JMS的结合,当然底层还是通过TCP、UDP等相关网络协议进行数据传输的，从配置文件的相应内容便可以看出。&lt;/p&gt;

&lt;p&gt;上述例子演示的是sendNoReturn的模式，那么假如我们需要远程Actor给我们一个回复应该怎么做呢？&lt;/p&gt;

&lt;p&gt;首先我们创建一个消息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;case object SendHasReturn

 def receive: Receive = {
    case SendHasReturn =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(&quot;hello remote actor&quot;)
      } yield r
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们重新运行LocalActor并像RemoteActor发送一条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-has-return.png&quot; alt=&quot;send-has-return&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到LocalActor在发送消息后并收到了RemoteActor返回来的消息，另外我们这里设置了超时时间，若在规定的时间内没有得到反馈，程序就会报错。&lt;/p&gt;

&lt;h3&gt;Akka Serialization&lt;/h3&gt;

&lt;p&gt;其实这一部分本可以单独拿出来写，但是相信序列化这块大家都应该有所了解了，所以就不准备讲太多序列化的知识了，怕班门弄斧，主要讲讲Akka中的序列化。&lt;/p&gt;

&lt;p&gt;继续上面的例子，假如我们这时向RemoteActor发送一个自定义的对象，比如一个case class对象，但是我们这是是在网络中传输这个消息，那么怎么保证这个对象类型和值呢，在同一个JVM系统中我们不需要担心这个，因为对象就在堆中，我们只要传递相应的地址即可就行，但是在不同的环境中，我们并不能这么做，我们在网络中只能传输字节数据，所以我们必须将对象做特殊的处理，在传输的时候转化成特定的由一连串字节组成的数据，而且我们又可以根据这些数据恢复成一个相应的对象，这便是序列化。&lt;/p&gt;

&lt;p&gt;我们先定义一个参与的case class, 并修改一下上面发送消息的语句:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case object SendSerialization
case class JoinEvt(
    id: Long,
    name: String
)
def receive: Receive = {
    case SendSerialization =&amp;gt;
      for {
        r &amp;lt;- remoteActor.ask(JoinEvt(1L,&quot;godpan&quot;))
      } yield println(r)
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时我们重新启动RemoteActor和LocalActor所在的系统，发送这条消息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/send-serialization.png&quot; alt=&quot;send-serialization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有同学可能会觉得奇怪，我们明明没有对JoinEvt进行过任何序列化的标识和处理，为什么程序还能运行成功呢？&lt;/p&gt;

&lt;p&gt;其实不然，只不过是有人替我们默认做了，不用说，肯定是贴心的Akka，它为我们提供了一个默认的序列化策略，那就是我们熟悉又纠结的java.io.Serializable，沉浸在它的易使用性上，又对它的性能深恶痛绝，尤其是当有大量对象需要传输的分布式系统，如果是小系统，当我没说，毕竟存在即合理。&lt;/p&gt;

&lt;p&gt;又有同学说，既然Akka是一个天生分布式组件，为什么还用低效的java.io.Serializable，你问我我也不知道，可能当时的作者偷了偷懒，当然Akka现在可能觉醒了，首先它支持第三方的序列化工具，当然如果你有特殊需求，你也可以自己实现一个，而且在最新的文档中说明，在Akka 2.5x之后Akka内核消息全面废弃java.io.Serializable，用户自定义的消息暂时还是支持使用java.io.Serializable的，但是不推荐用，因为它是低效的，容易被攻击，所以在这里我也推荐大家再Akka中尽量不要在使用了java.io.Serializable。&lt;/p&gt;

&lt;p&gt;那么在Akka中我们如何使用第三方的序列化工具呢？&lt;/p&gt;

&lt;p&gt;这里我推荐一个在Java社区已经久负盛名的序列化工具：kryo，有兴趣的同学可以去了解一下：&lt;a href=&quot;https://github.com/EsotericSoftware/kryo&quot;&gt;kryo&lt;/a&gt;,而且它也提供Akka使用的相关包，这里我们就使用它作为示例：&lt;/p&gt;

&lt;p&gt;这里我贴上整个项目的build.sbt, kryo的相关依赖也在里面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;
import sbt._
import sbt.Keys._

lazy val AllLibraryDependencies =
  Seq(
    &quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.5.3&quot;,
    &quot;com.typesafe.akka&quot; %% &quot;akka-remote&quot; % &quot;2.5.3&quot;,
    &quot;com.twitter&quot; %% &quot;chill-akka&quot; % &quot;0.8.4&quot;
  )

lazy val commonSettings = Seq(
  name := &quot;AkkaRemoting&quot;,
  version := &quot;1.0&quot;,
  scalaVersion := &quot;2.11.11&quot;,
  libraryDependencies := AllLibraryDependencies
)

lazy val remote = (project in file(&quot;remote&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )

lazy val local = (project in file(&quot;local&quot;))
  .settings(commonSettings: _*)
  .settings(
    // other settings
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们只需将application.conf中的actor配置替换成以下的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;actor {
    provider = &quot;akka.remote.RemoteActorRefProvider&quot;
    serializers {
      kryo = &quot;com.twitter.chill.akka.AkkaSerializer&quot;
    }
    serialization-bindings {
      &quot;java.io.Serializable&quot; = none
      &quot;scala.Product&quot; = kryo
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实其中的&quot;java.io.Serializable&quot; = none可以省略，因为若是有其他序列化的策略则会替换掉默认的java.io.Serializable的策略，这里只是为了更加仔细的说明。&lt;/p&gt;

&lt;p&gt;至此我们就可以使用kryo了，整个过程是不是很easy，迫不及待开始写demo了，那就快快开始吧。&lt;/p&gt;

&lt;p&gt;从运行结果和代码上分析可得：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Akka Remote使用内置的序列化工具，并支持配置指定的序列化方式，可以按需配置；&lt;/li&gt;
&lt;li&gt;Akka Remote使用的过程是一个异步非阻塞的过程，客户端能尽量减少对服务端的依赖；&lt;/li&gt;
&lt;li&gt;Akka Remote的代码实现相对Java Rmi实现来说简单的多，非常简洁；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;整个例子的相关的源码已经上传到akka-demo中：&lt;a href=&quot;https://github.com/godpan/akka-demo/tree/master/Example_06&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akka系列（八）：Akka persistence设计理念之CQRS</title>
   <link href="/2017/07/29/learning-akka-8.html"/>
   <updated>2017-07-29T00:00:00+08:00</updated>
   <id>urn:uuid:8dcf2b63-e930-3d54-8ca7-fbvbdc2a4fgd</id>
   <content type="html">&lt;p&gt;这一篇文章主要是讲解Akka persistence的核心设计理念，也是CQRS（Command Query Responsibility Segregation）架构设计的典型应用，就让我们来看看为什么Akka persistence会采用CQRS架构设计。&lt;/p&gt;

&lt;h3&gt;CQRS&lt;/h3&gt;

&lt;p&gt;很多时候我们在处理高并发的业务需求的时候，往往能把应用层的代码优化的很好，比如缓存，限流，均衡负载等，但是很难避免的一个问题就是数据的持久化，以致数据库的性能很可能就是系统性能的瓶颈，我前面的那篇文章也讲到，如果我们用数据库去保证记录的CRUD，在并发高的情况下，让数据库执行这么多的事务操作，会让很多数据库操作超时，连接池不够用的情况，导致大量请求失败，系统的错误率上升和负载性能下降。&lt;/p&gt;

&lt;p&gt;既然这样，那我们可不可借鉴一下读写分离的思想呢？假使写操作和同操作分离，甚至是对不同数据表，数据库操作，那么我们就可以大大降低数据库的瓶颈，使整个系统的性能大大提升。那么CQRS到底是做了什么呢？&lt;/p&gt;

&lt;p&gt;我们先来看看普通的方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/acid.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看出，我们对数据的请求都是通过相应的接口直接对数据库进行操作，这在并发大的时候肯定会对数据库造成很大的压力，虽然架构简单，但在面对并发高的情况下力不从心。&lt;/p&gt;

&lt;p&gt;那么CQRS的方式有什么不同呢？我们也来看看它的执行方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs.png&quot; alt=&quot;acid&quot; /&gt;&lt;/p&gt;

&lt;p&gt;乍得一看，似乎跟普通的方式没什么不同啊，不就多了一个事件和存储DB么，其实不然，小小的改动便是核心理念的转换，首先我们可以看到在CQRS架构中会多出一个Event，那它到底代表着什么含义呢？其实看过上篇文章的同学很容易理解，Event是我们系统根据请求处理得出的一个领域模型，比如一个修改余额操作事件，当然这个Event中只会保存关键性的数据。&lt;/p&gt;

&lt;p&gt;很多同学又有疑问了，这不跟普通的读写分离很像么，难道还隐藏着什么秘密？那我们就来比较一下几种方式的不同之处：&lt;/p&gt;

&lt;h5&gt;1.单数据库模式&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;写操作会产生互斥锁，导致性能降低；&lt;/li&gt;
&lt;li&gt;即使使用乐观锁，但是在大量写操作的情况下也会大量失败；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;2.读写分离&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;读写分离通过物理服务器增加，负荷增加；&lt;/li&gt;
&lt;li&gt;读写分离更适用于读操作大于写操作的场景；&lt;/li&gt;
&lt;li&gt;读写分离在面对大量写操作的情况下还是很吃力；&lt;/li&gt;
&lt;/ul&gt;


&lt;h5&gt;3.CQRS&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;普通数据的持久化和Event持久化可以使用同一台数据库；&lt;/li&gt;
&lt;li&gt;利用架构设计可以使读和写操作尽可能的分离；&lt;/li&gt;
&lt;li&gt;能支撑大量写的操作情况；&lt;/li&gt;
&lt;li&gt;可以支持数据异步持久，确保数据最终一致性；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;从三种方式各自的特点可以看出，单数据库模式的在大量读写的情况下有很大的性能瓶颈，但简单的读写分离在面对大量写操作的时候也还是力不从心，比如最常见的库存修改查询场景：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/common-action.png&quot; alt=&quot;common-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以发现在这种模式下写数据库的压力还会很大，而且还有数据同步，数据延迟等问题。&lt;/p&gt;

&lt;p&gt;那么我们用CQRS架构设计会是怎么样呢：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-action.png&quot; alt=&quot;cqrs-action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先我们可以业务模型进行分离，对不同的查询进行分离，另外避免不了的同一区间数据段进行异步持久化，在保证数据一致性的情况下提升系统的吞吐量。这种设计我们很少会遇到事务竞争，另外还可以使用内存数据库（当然如果是内存操作那就最快）来提升数据的写入。（以上的数据库都可为分布式数据库，不担心单机宕机）&lt;/p&gt;

&lt;p&gt;那么CRQS机制是怎么保证数据的一致性的呢？&lt;/p&gt;

&lt;p&gt;从上图中我们可以看出，一个写操作我们会在系统进行初步处理后生成一个领域事件，比如a用户购买了xx商品1件，b用户购买了xx商品2件等，按照普通的方式我们肯定是直接将订单操作，库存修改操作一并放在一个事务内去操作数据库，性能可想而知，而用CQRS的方式后，首先系统在持久化相应的领域事件后和修改内存中的库存（这个处理非常迅速）后便可马上向用户做出反应，真正的具体信息持久可以异步进行，当然若是当在具体信息持久化的过程中出错了怎么办，系统能恢复正确的数据么，当然可以，因为我们的领域事件事件已经持久化成功了，在系统恢复的时候，我们可以根据领域事件来恢复真正的数据，当然为了防止恢复数据是造成数据丢失，数据重复等问题我们需要制定相应的原则，比如给领域事件分配相应id等。&lt;/p&gt;

&lt;p&gt;使用CQRS会带来性能上的提升，当然它也有它的弊端：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使系统变得更复杂，做一些额外的设计；&lt;/li&gt;
&lt;li&gt;CQRS保证的是最终一致性，有可能只适用于特定的业务场景；&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Akka Persistence 中CQRS的应用&lt;/h3&gt;

&lt;p&gt;通过上面的讲解，相信大家对CQRS已经有了一定的了解，下面我们就来看看它在Akka Persistence中的具体应用，这里我就结合上一篇文章抽奖的例子，比如其中的LotteryCmd便是一个写操作命令，系统经过相应的处理后得到相应的领域事件，比如其中LuckyEvent，然后我们将LuckyEvent进行持久化，并修改内存中抽奖的余额，返回相应的结果，这里我们就可以同时将结果反馈给用户，并对结果进行异步持久化，流程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/2017/08/cqrs-example.png&quot; alt=&quot;cqrs-example&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出，Akka Persistence的原理完全是基于CQRS的架构设计的，另外Persistence Actor还会保存一个内存状态，相当于一个in memory数据库，可以用来提供关键数据的存储和查询，比如前面说到的库存，余额等数据，这部分的设计取决于具体的业务场景。&lt;/p&gt;

&lt;p&gt;阅读Akka Persistence相关源码，其的核心就在于PersistentActor接口中的几个持久方法，比如其中的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;scala&quot;&gt;def persist[A](event: A)(handler: A ⇒ Unit): Unit

def persistAll[A](events: immutable.Seq[A])(handler: A ⇒ Unit): Unit 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等方法，它们都有两个参数，一个是持久化的事件，一个是持久化后的后续处理逻辑，我们可以在后续handler中修改Actor内部状态，向外部发送消息等操作,这里的模式就是基于CQRS架构的，修改状态有事件驱动，另外Akka还可以在系统出错时，利用相应的事件恢复Actor的状态。&lt;/p&gt;

&lt;h3&gt;总结&lt;/h3&gt;

&lt;p&gt;总的来说，CQRS架构是一种不同于以往的CRUD的架构，所以你在享受它带来的高性能的同时可能会遇到一些奇怪的问题，当然这些都是可以解决的，重要的是思维上的改变，比如事件驱动，领域模型等概念，不过相信当你理解并掌握它之后，你便会爱上它的。&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
